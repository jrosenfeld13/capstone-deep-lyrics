{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.data_collection.multimodal_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Lyrics Generator - ULMFiT\n",
    "\n",
    "## Set up instructions\n",
    "\n",
    "### Create VM Instance\n",
    "\n",
    "- Go to cloud.google.com, and create a new VM instance\n",
    "- Disk size: 100GB or more\n",
    "- CPUs + Memory: 2vCPUs, 7.5 GB Memory\n",
    "- GPU: K80 (cheaper, less power) or P100 (2.5x more expensive, more power)\n",
    "- Enable http, https traffic\n",
    "- Boot: Deep learning pytorch instance\n",
    "\n",
    "### Network configuration\n",
    "\n",
    "In Google cloud platform:\n",
    "\n",
    "- Go to Networking -> VPC Network, External IP addresses\n",
    "- Select your VM instance and change the external address type from Ephemeral to Static\n",
    "- Go to Networking -> VPC Network, Firewall Rules\n",
    "- Add a new Rule, called Jupyter, ip ranges 0.0.0.0/0, protocols and ports tcp:8888, apply to all targets\n",
    "\n",
    "### VM + Jupyter Setup\n",
    "\n",
    "- SSH to VM\n",
    "- Enlist into Github repo\n",
    "- Run src/setup.sh\n",
    "- Run jupyter notebook\n",
    "- Open a google cloud shell\n",
    "- Run gcloud init and answer the questions\n",
    "- To set up a tunnel and run jupyter locally, run ```gcloud compute --project \"<your project>\" ssh --zone \"<your zone>\" \"<your instance name>\" -- -L 8888:localhost:8888```\n",
    "- Open jupyter notebook in your local computer and have fun\n",
    "\n",
    "### Notebook first run\n",
    "Here are some steps to run the first time you use the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokens\n",
    "To create the model's tokens with the correct train-test split, run ```src/data_collection/lm_data_lyrics.py -o path/to/save```. \n",
    "We recommend saving in data/models/{MODEL_NAME}. Alternatively, run the magic command below and replace the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train.\n",
      "Numericalizing valid.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/data_collection/lm_data_lyrics.py -o ../data/models/3.4-ULMFiT-MM-108k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Audio Features\n",
    "\n",
    "To create the model's audio features with the same train-test split as the language models, run `src/data/lm_data_audio.py -o path/to/save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/data_collection/lm_data_audio.py -o ../data/interim/msd-aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model_name = '3.3-ULMFiT-108k'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')\n",
    "\n",
    "\n",
    "model_name = '3.4-ULMFiT-MM-108k'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)\n",
    "\n",
    "print(data_lm.train_ds.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = copy(data_lm.train_ds)\n",
    "valid_text = copy(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-train.csv')\n",
    "df_valid = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_duration'] = np.log(df_train['duration'])\n",
    "df_train['song_hot'] = np.where(df_train['song_hotttnesss'] == 0,\n",
    "                                np.mean(df_train['song_hotttnesss']),\n",
    "                                df_train['song_hotttnesss'])\n",
    "df_train.loc[df_train['song_hot'].isnull(), 'song_hot'] = np.mean(df_train['song_hotttnesss'])\n",
    "df_train_features = df_train[['log_duration', 'loudness', 'song_hot', 'tempo']]\n",
    "\n",
    "df_valid['log_duration'] = np.log(df_valid['duration'])\n",
    "df_valid['song_hot'] = np.where(df_valid['song_hotttnesss'] == 0,\n",
    "                                np.mean(df_valid['song_hotttnesss']),\n",
    "                                df_valid['song_hotttnesss'])\n",
    "df_valid.loc[df_valid['song_hot'].isnull(), 'song_hot'] = np.mean(df_valid['song_hotttnesss'])\n",
    "df_valid_features = df_valid[['log_duration', 'loudness', 'song_hot', 'tempo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "df_train_tfm = ss.fit_transform(df_train_features)\n",
    "df_valid_tfm = ss.transform(df_valid_features)\n",
    "\n",
    "train_audio = AudioDataset(df_train_tfm, train_text)\n",
    "valid_audio = AudioDataset(df_valid_tfm, valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data = MultimodalDataLoader(audio_dataset=train_audio,\n",
    "                                  dataset=train_text)\n",
    "multi_data_valid = MultimodalDataLoader(audio_dataset=valid_audio,\n",
    "                                  dataset=valid_text)\n",
    "multi_db = DataBunch(multi_data, multi_data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalRNN(\n",
       "  (encoder): Embedding(10002, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(10002, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): None\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       "  (multimode): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(404, 1150)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1150, 1150)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1150, 400)\n",
       "    )\n",
       "  )\n",
       "  (multidecoder): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=10002, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_sz = 4\n",
    "vocab_sz = 10002\n",
    "emb_sz = 400\n",
    "n_hid = 1150\n",
    "n_layers = 3\n",
    "pad_token = 1\n",
    "qrnn = False\n",
    "bidir = False\n",
    "drop_mult = 0.5\n",
    "dps = np.array([0.25, 0.1, 0.2, 0.02, 0.15]) * drop_mult\n",
    "hidden_p = dps[4]\n",
    "input_p = dps[0]\n",
    "embed_p = dps[3]\n",
    "weight_p = dps[2]\n",
    "tie_weights = True\n",
    "output_p = dps[1]\n",
    "bias = True\n",
    "\n",
    "class MultiModalRNN(RNNCore):\n",
    "    def __init__(self, audio_sz, output_p, bias, tie_encoder:bool=True, **kwargs):\n",
    "        super(MultiModalRNN, self).__init__(**kwargs)\n",
    "        self.rnns = None\n",
    "        self.audio_sz = audio_sz\n",
    "        self.multimode = [nn.LSTM(emb_sz + audio_sz if l == 0 else n_hid,\n",
    "                                  (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                                  1, bidirectional=bidir) for l in range(n_layers)]\n",
    "        self.multimode = [WeightDropout(rnn, weight_p) for rnn in self.multimode]\n",
    "        self.multimode = torch.nn.ModuleList(self.multimode)\n",
    "        \n",
    "        if tie_encoder:\n",
    "            enc = self.encoder\n",
    "        else:\n",
    "            enc = None\n",
    "        \n",
    "        self.multidecoder = LinearDecoder(vocab_sz,\n",
    "                                          emb_sz,\n",
    "                                          output_p,\n",
    "                                          tie_encoder=enc,\n",
    "                                          bias=bias)\n",
    "        \n",
    "    def forward(self, input:LongTensor, input_audio:Tensor)->Tuple[Tensor,Tensor,Tensor]:\n",
    "        sl,bs = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(self.encoder_dp(input))\n",
    "        raw_output = torch.cat([raw_output, input_audio], dim=2)\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.multimode, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = to_detach(new_hidden)\n",
    "        \n",
    "        output = self.multidecoder.output_dp(outputs[-1])\n",
    "        decoded = self.multidecoder.decoder(output.view(output.size(0)*output.size(1),\n",
    "                                                        output.size(2)))\n",
    "        \n",
    "        return decoded, raw_outputs, outputs\n",
    "    \n",
    "    def _one_hidden(self, l:int)->Tensor:\n",
    "        \"Return one hidden state.\"\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "        return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states.\"\n",
    "        [r.reset() for r in self.multimode if hasattr(r, 'reset')]\n",
    "        self.weights = next(self.parameters()).data\n",
    "        if self.qrnn: self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n",
    "        else: self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]\n",
    "    \n",
    "multimodal_rnn = MultiModalRNN(audio_sz=audio_sz,\n",
    "                              vocab_sz=vocab_sz,\n",
    "                              emb_sz=emb_sz,\n",
    "                              n_hid=n_hid,\n",
    "                              n_layers=n_layers,\n",
    "                              pad_token=pad_token,\n",
    "                              qrnn=qrnn,\n",
    "                              bidir=bidir,\n",
    "                              hidden_p=hidden_p,\n",
    "                              input_p=input_p,\n",
    "                              embed_p=embed_p,\n",
    "                              weight_p=weight_p,\n",
    "                              output_p=output_p,\n",
    "                              bias=bias,\n",
    "                              tie_encoder=tie_weights)\n",
    "\n",
    "multimodal_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner(multi_db, multimodal_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_MODEL_WEIGHTS = False\n",
    "weights_url = 'https://storage.googleapis.com/w210-capstone/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "if DOWNLOAD_MODEL_WEIGHTS:\n",
    "    Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "    download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_TO_MULTI = {\n",
    "    '0.encoder.weight': 'encoder.weight',\n",
    "    '0.encoder_dp.emb.weight': 'encoder_dp.emb.weight',\n",
    "    '0.rnns.0.weight_hh_l0_raw': 'multimode.0.weight_hh_l0_raw',\n",
    "    '0.rnns.0.module.weight_ih_l0': 'multimode.0.module.weight_ih_l0',\n",
    "    '0.rnns.0.module.weight_hh_l0': 'multimode.0.module.weight_hh_l0',\n",
    "    '0.rnns.0.module.bias_ih_l0': 'multimode.0.module.bias_ih_l0',\n",
    "    '0.rnns.0.module.bias_hh_l0': 'multimode.0.module.bias_hh_l0',\n",
    "    '0.rnns.1.weight_hh_l0_raw': 'multimode.1.weight_hh_l0_raw',\n",
    "    '0.rnns.1.module.weight_ih_l0': 'multimode.1.module.weight_ih_l0',\n",
    "    '0.rnns.1.module.weight_hh_l0': 'multimode.1.module.weight_hh_l0',\n",
    "    '0.rnns.1.module.bias_ih_l0': 'multimode.1.module.bias_ih_l0',\n",
    "    '0.rnns.1.module.bias_hh_l0': 'multimode.1.module.bias_hh_l0', \n",
    "    '0.rnns.2.weight_hh_l0_raw': 'multimode.2.weight_hh_l0_raw', \n",
    "    '0.rnns.2.module.weight_ih_l0': 'multimode.2.module.weight_ih_l0',\n",
    "    '0.rnns.2.module.weight_hh_l0': 'multimode.2.module.weight_hh_l0',\n",
    "    '0.rnns.2.module.bias_ih_l0': 'multimode.2.module.bias_ih_l0',\n",
    "    '0.rnns.2.module.bias_hh_l0': 'multimode.2.module.bias_hh_l0',\n",
    "    '1.decoder.weight': 'multidecoder.decoder.weight',\n",
    "    '1.decoder.bias': 'multidecoder.decoder.bias'\n",
    "}\n",
    "\n",
    "map_weights(learn,\n",
    "            INIT_MODEL_PATH/f'models/{init_model_name}_best.pth',\n",
    "            MODEL_PATH/f'tmp/itos.pkl',\n",
    "            PRETRAINED_TO_MULTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cpu_load(self, name:PathOrStr):\n",
    "#     \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "#        We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "#     self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "# setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not GPU:\n",
    "#     learn.cpu_load(f'{model_name}_best')\n",
    "# else:\n",
    "#     learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6739d45cc779438f9d9d7889949d0a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c7d4f9b9358a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     cbs = [OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     17\u001b[0m                              pct_start=pct_start, **kwargs)]\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         fit(epochs, self.model, self.loss_fn, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 138\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_fn, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_fn, opt, cb_handler, metrics)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, smooth_loss, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'child'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{smooth_loss:.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     def on_epoch_end(self, epoch:int, num_batch:int, smooth_loss:Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 46:24<6:57:37]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.569366</th>\n",
       "    <th>2.783916</th>\n",
       "    <th>0.463589</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='6337', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-eb5e76a05ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     18\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 161\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(10, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  2.7839158\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path = Path(MODEL_PATH)\n",
    "learn.save(f'{model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, context_length, temp=1):\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def get_word_from_index(idx):\n",
    "\n",
    "    return data_lm.valid_ds.vocab.textify([idx])\n",
    "\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = 'xeol \\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = 'xbol'\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], max_len=500, GPU=False, context_length=20, beam_width=5, temp=1, verbose=True, graph=False):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    if graph:\n",
    "        optimization_graph = Digraph()\n",
    "\n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in range(max_len):\n",
    "        print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "            top_probabilities = np.argwhere(multinom_draw != 0).flatten()\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "                if graph:\n",
    "                    optimization_graph.node(\"%d_%d\" % (word_number, next_word_idx), \"%s (%.2f)\" % (get_word_from_index(next_word_idx), candidate[1]))\n",
    "                    optimization_graph.edge(\"%d_%d\" % (word_number - 1, context[len(context) -1]), \"%d_%d\" % (word_number, next_word_idx))\n",
    "                \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "\n",
    "        context_and_scores = context_and_scores[:15] #for now, only keep the top 15 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "\n",
    "    if graph:\n",
    "        now = str(datetime.now())\n",
    "        optimization_graph.render(directory='graph_viz/', filename=now, cleanup=True)\n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word: 1 / 80\n",
      "Generating word: 2 / 80\n",
      "Generating word: 3 / 80\n",
      "Generating word: 4 / 80\n",
      "Generating word: 5 / 80\n",
      "Generating word: 6 / 80\n",
      "Generating word: 7 / 80\n",
      "Generating word: 8 / 80\n",
      "Generating word: 9 / 80\n",
      "Generating word: 10 / 80\n",
      "Generating word: 11 / 80\n",
      "Generating word: 12 / 80\n",
      "Generating word: 13 / 80\n",
      "Generating word: 14 / 80\n",
      "Generating word: 15 / 80\n",
      "Generating word: 16 / 80\n",
      "Generating word: 17 / 80\n",
      "Generating word: 18 / 80\n",
      "Generating word: 19 / 80\n",
      "Generating word: 20 / 80\n",
      "Generating word: 21 / 80\n",
      "Generating word: 22 / 80\n",
      "Generating word: 23 / 80\n",
      "Generating word: 24 / 80\n",
      "Generating word: 25 / 80\n",
      "Generating word: 26 / 80\n",
      "Generating word: 27 / 80\n",
      "Generating word: 28 / 80\n",
      "Generating word: 29 / 80\n",
      "Generating word: 30 / 80\n",
      "Generating word: 31 / 80\n",
      "Generating word: 32 / 80\n",
      "Generating word: 33 / 80\n",
      "Generating word: 34 / 80\n",
      "Generating word: 35 / 80\n",
      "Generating word: 36 / 80\n",
      "Generating word: 37 / 80\n",
      "Generating word: 38 / 80\n",
      "Generating word: 39 / 80\n",
      "Generating word: 40 / 80\n",
      "Generating word: 41 / 80\n",
      "Generating word: 42 / 80\n",
      "Generating word: 43 / 80\n",
      "Generating word: 44 / 80\n",
      "Generating word: 45 / 80\n",
      "Generating word: 46 / 80\n",
      "Generating word: 47 / 80\n",
      "Generating word: 48 / 80\n",
      "Generating word: 49 / 80\n",
      "Generating word: 50 / 80\n",
      "Generating word: 51 / 80\n",
      "Generating word: 52 / 80\n",
      "Generating word: 53 / 80\n",
      "Generating word: 54 / 80\n",
      "Generating word: 55 / 80\n",
      "Generating word: 56 / 80\n",
      "Generating word: 57 / 80\n",
      "Generating word: 58 / 80\n",
      "Generating word: 59 / 80\n",
      "Generating word: 60 / 80\n",
      "Generating word: 61 / 80\n",
      "Generating word: 62 / 80\n",
      "Generating word: 63 / 80\n",
      "Generating word: 64 / 80\n",
      "Generating word: 65 / 80\n",
      "Generating word: 66 / 80\n",
      "Generating word: 67 / 80\n",
      "Generating word: 68 / 80\n",
      "Generating word: 69 / 80\n",
      "Generating word: 70 / 80\n",
      "Generating word: 71 / 80\n",
      "Generating word: 72 / 80\n",
      "Generating word: 73 / 80\n",
      "Generating word: 74 / 80\n",
      "Generating word: 75 / 80\n",
      "Generating word: 76 / 80\n",
      "Generating word: 77 / 80\n",
      "Generating word: 78 / 80\n",
      "Generating word: 79 / 80\n",
      "Generating word: 80 / 80\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU, seed_text='xbos xbol [verse-1]', max_len=80, context_length=200, beam_width=3, verbose=False, temp=1.2, graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you 59.46360991574005\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol and i 'll tell you what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me 59.775467989144616\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you 60.44527429931548\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you 60.82731807064366\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you 60.86317126872393\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you 60.89976426813252\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol xeol \n",
      " xbol [verse-2] xeol \n",
      " 61.14334932227873\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol xeol \n",
      " xbol [verse-2] xeol \n",
      " 61.66071819183748\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to see xeol \n",
      " xbol tell me what you want to see xeol \n",
      " xbol tell me what you want to see xeol \n",
      " xbol tell me what you 61.715518237806755\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you 61.83535763751709\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want 61.85429537584041\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol xeol \n",
      " xbol [verse-2] xeol \n",
      " 61.974755520757306\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol xeol \n",
      " xbol [verse-2] xeol \n",
      " 62.35712420489536\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want xeol \n",
      " xbol and tell me what you need xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol now tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you need xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol tell me what you want xeol \n",
      " xbol xeol \n",
      " xbol [chorus] xeol \n",
      " 63.057794755875165\n",
      "\n",
      "\n",
      "xbos xbol [verse-1] xeol \n",
      " xbol aye , tell me what you want to do xeol \n",
      " xbol tell me what you want from me xeol \n",
      " xbol tell me what you want to hear xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to do xeol \n",
      " xbol tell me what you want to xeol \n",
      " xbol xeol \n",
      " xbol [chorus] xeol \n",
      " xbol 63.16089396123926\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "for song, score in final_scores:\n",
    "    print_words(song)\n",
    "    print(score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
