{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions\n",
    "Define this notebooks \"initializer model\" (pretrained parameters and itos mapping) and the output model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '4.2-Clas-108k-lines'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "init_model_name = '4.1-LM-108k-lines'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')\n",
    "INIT_MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "To create the model's tokens with the correct train-test split, run the code below. Only needed once on the notebook's first ever run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FIRST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics, line_num=True):\n",
    "    '''\n",
    "    Tokenizes lyrics\n",
    "    '''\n",
    "    tk = nltk.tokenize.LineTokenizer(blanklines='keep')\n",
    "    tokd = tk.tokenize(lyrics)\n",
    "    \n",
    "    re_tk = nltk.tokenize.RegexpTokenizer(r'\\[[^\\]]+\\]|\\w+|[\\d\\.,]+|\\S+',\n",
    "                                          discard_empty=False)\n",
    "    re_tokd = re_tk.tokenize_sents(tokd)\n",
    "    \n",
    "    if line_num:\n",
    "        [s.insert(0, f'xBOL {line_num+1}') for line_num, s in enumerate(re_tokd)] # insert start token for each line\n",
    "    else:\n",
    "        [s.insert(0, f'xBOL') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "    [s.append('xEOL') for s in re_tokd] # append end token for each line\n",
    "    \n",
    "    flat = list(itertools.chain(*re_tokd))\n",
    "    flat.insert(0, 'xBOS')\n",
    "    flat.append('xEOS')\n",
    "    # lower case and de-space\n",
    "    flat = [w.lower().replace(' ', '-') for w in flat]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(y).reshape(-1, 1)\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tag(X, tag_list):\n",
    "    \"\"\"\n",
    "    Apply heuristic for genre tagging. Some genres take priority, even if\n",
    "        it doesn't appear in tag1. e.g. 'christian' is highly distinguishable\n",
    "    \n",
    "    1. if all tags are missing set to 'missing'\n",
    "    2. if any of the three tags are 'foreign' set to 'foreign'\n",
    "    2. if any of the three tags are 'christian', set to 'christian'\n",
    "    3. if any of the three tags are 'country', set to 'country'\n",
    "    4. if any of the three tags are 'instrumental' set to 'instrumental'\n",
    "    5. if any of the three tags are 'christmas' set to 'christmas'\n",
    "    6. check membership in top tag list starting with tag1 as priority.\n",
    "       top tags are constructed after consolidation\n",
    "    7. All else is set to \"other\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if pd.isnull([X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]).all():\n",
    "        return 'missing'\n",
    "    elif 'foreign' in [X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]:\n",
    "        return 'foreign'\n",
    "    elif 'christian' in [X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]:\n",
    "        return 'christian'\n",
    "    elif 'country' in [X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]:\n",
    "        return 'country'\n",
    "    elif 'instrumental' in [X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]:\n",
    "        return 'instrumental'\n",
    "    elif 'christmas' in [X.mapped_tag1, X.mapped_tag2, X.mapped_tag3]:\n",
    "        return 'christmas'\n",
    "    elif X.mapped_tag1 in tag_list:\n",
    "        return X.mapped_tag1\n",
    "    elif X.mapped_tag2 in tag_list:\n",
    "        return X.mapped_tag2\n",
    "    elif X.mapped_tag3 in tag_list:\n",
    "        return X.mapped_tag3\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "def map_tag(df, genre_map, tag_list):\n",
    "    \"\"\"\n",
    "    Pass in genre tag column(s) to get mapped genre tag\n",
    "    \"\"\"\n",
    "    num_columns = df.shape[1]\n",
    "    assert all([w.startswith('tag') for w in df.columns]),\"check tag columns\"\n",
    "    series_out = df.copy()\n",
    "    for i in range(1, num_columns+1):\n",
    "        series_out = pd.merge(series_out, genre_map, how='left',\n",
    "                              left_on=f'tag{i}', right_on='tag',\n",
    "                              validate='m:1')\n",
    "        series_out.loc[series_out.mapped_tag.isnull(), 'mapped_tag'] = series_out[f'tag{i}']\n",
    "        series_out.drop(columns='tag', inplace=True)\n",
    "        series_out.rename(columns={'mapped_tag': f'mapped_tag{i}'}, inplace=True)\n",
    "        \n",
    "    series_out = series_out.iloc[:, -num_columns:]\n",
    "        \n",
    "    combined_out = series_out.apply(combine_tag, axis=1, tag_list=tag_list)\n",
    "        \n",
    "    return pd.DataFrame(combined_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens_and_genre(model_path):\n",
    "    '''\n",
    "    500k link: https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv\n",
    "    108k link: https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv\n",
    "    '''\n",
    "    model_path = Path(model_path)\n",
    "    model_path.mkdir(exist_ok=True)\n",
    "\n",
    "    tags_and_lyrics_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics_tags.csv'\n",
    "\n",
    "\n",
    "    # load scraped data\n",
    "    df = pd.read_csv(tags_and_lyrics_url, index_col=0)\n",
    "\n",
    "    # only keep lyrics with length < 5000\n",
    "    df = df[df.lyrics.str.len() < 5000]\n",
    "    print('Tokenizing...')\n",
    "    df['tokd'] = df.lyrics.apply(tokenize_lyrics, line_num=True)\n",
    "    df['tokd_len'] = df.tokd.apply(len)\n",
    "\n",
    "\n",
    "    ### GENRE FEATURE ENGINEERING\n",
    "    # bring in manual consolidation file\n",
    "    genre_map = pd.read_excel('../data/external/genre_tag_mapping.xlsx', header=None,\n",
    "                             names=['tag', 'mapped_tag'], usecols=[0,4], skiprows=1)\n",
    "    genre_map.loc[genre_map['mapped_tag'].isnull(), 'mapped_tag'] = genre_map['tag']\n",
    "\n",
    "    # come up with top 20 based on conslidated\n",
    "    top_tags = pd.read_excel('../data/external/genre_tag_mapping.xlsx', header=None,\n",
    "                             names=['tag', 'tag1', 'tag2', 'combined', 'mapped_tag'],\n",
    "                             skiprows=1)\n",
    "    top_tags.loc[top_tags['mapped_tag'].isnull(), 'mapped_tag'] = top_tags['tag']\n",
    "    top_tags = top_tags.groupby('mapped_tag')\\\n",
    "        .sum().sort_values('combined', ascending=False)\n",
    "    tag_list = set(top_tags.head(20).index)\n",
    "\n",
    "    tag_feat = FunctionTransformer(map_tag, validate=False,\n",
    "                               kw_args={'genre_map': genre_map,\n",
    "                                        'tag_list': tag_list})\n",
    "\n",
    "    genre_transformer_text = Pipeline(steps=[\n",
    "        ('tagger', tag_feat)\n",
    "    ])\n",
    "\n",
    "\n",
    "    preprocessor_text = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('genre', genre_transformer_text, genre_features)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    genres = pd.DataFrame(preprocessor_text.fit_transform(df), columns=['genre'])\n",
    "    full_df = pd.concat([df, genres], axis=1)\n",
    "\n",
    "    sub_df = full_df[(full_df['genre'] != 'missing') & (full_df['genre'] != 'other')]\n",
    "\n",
    "    df_train, df_valid = train_test_split(sub_df, test_size=0.2, random_state=2018)\n",
    "\n",
    "    encoder = ModifiedLabelEncoder()\n",
    "    train_labels = encoder.fit_transform(df_train['genre'])\n",
    "    valid_labels = encoder.transform(df_valid['genre'])\n",
    "\n",
    "    # tokens\n",
    "    print('Saving...')\n",
    "    tokens = np.array(df_train.tokd)\n",
    "    np.save(MODEL_PATH/'train_tok.npy', tokens)\n",
    "\n",
    "    tokens = np.array(df_valid.tokd)\n",
    "    np.save(MODEL_PATH/'valid_tok.npy', tokens)\n",
    "\n",
    "    #labels\n",
    "    np.save(MODEL_PATH/'train_lbl.npy', list(itertools.chain(*train_labels)))\n",
    "    np.save(MODEL_PATH/'valid_lbl.npy', list(itertools.chain(*valid_labels)))\n",
    "    print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    process_tokens_and_genre(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_and_lyrics_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics_tags.csv'\n",
    "\n",
    "\n",
    "# load scraped data\n",
    "df = pd.read_csv(tags_and_lyrics_url, index_col=0)\n",
    "\n",
    "# only keep lyrics with length < 5000\n",
    "df = df[df.lyrics.str.len() < 5000]\n",
    "print('Tokenizing...')\n",
    "df['tokd'] = df.lyrics.apply(tokenize_lyrics, line_num=True)\n",
    "df['tokd_len'] = df.tokd.apply(len)\n",
    "\n",
    "\n",
    "### GENRE FEATURE ENGINEERING\n",
    "# bring in manual consolidation file\n",
    "genre_map = pd.read_excel('../data/external/genre_tag_mapping.xlsx', header=None,\n",
    "                         names=['tag', 'mapped_tag'], usecols=[0,4], skiprows=1)\n",
    "genre_map.loc[genre_map['mapped_tag'].isnull(), 'mapped_tag'] = genre_map['tag']\n",
    "\n",
    "# come up with top 20 based on conslidated\n",
    "top_tags = pd.read_excel('../data/external/genre_tag_mapping.xlsx', header=None,\n",
    "                         names=['tag', 'tag1', 'tag2', 'combined', 'mapped_tag'],\n",
    "                         skiprows=1)\n",
    "top_tags.loc[top_tags['mapped_tag'].isnull(), 'mapped_tag'] = top_tags['tag']\n",
    "top_tags = top_tags.groupby('mapped_tag')\\\n",
    "    .sum().sort_values('combined', ascending=False)\n",
    "tag_list = set(top_tags.head(20).index)\n",
    "\n",
    "tag_feat = FunctionTransformer(map_tag, validate=False,\n",
    "                           kw_args={'genre_map': genre_map,\n",
    "                                    'tag_list': tag_list})\n",
    "\n",
    "genre_transformer_text = Pipeline(steps=[\n",
    "    ('tagger', tag_feat)\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor_text = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('genre', genre_transformer_text, genre_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "genres = pd.DataFrame(preprocessor_text.fit_transform(df), columns=['genre'])\n",
    "full_df = pd.concat([df, genres], axis=1)\n",
    "\n",
    "sub_df = full_df[(full_df['genre'] != 'missing') & (full_df['genre'] != 'other')]\n",
    "\n",
    "df_train, df_valid = train_test_split(sub_df, test_size=0.2, random_state=2018)\n",
    "\n",
    "encoder = ModifiedLabelEncoder()\n",
    "train_labels = encoder.fit_transform(df_train['genre'])\n",
    "valid_labels = encoder.transform(df_valid['genre'])\n",
    "\n",
    "# tokens\n",
    "print('Saving...')\n",
    "tokens = np.array(df_train.tokd)\n",
    "np.save(MODEL_PATH/'train_tok.npy', tokens)\n",
    "\n",
    "tokens = np.array(df_valid.tokd)\n",
    "np.save(MODEL_PATH/'valid_tok.npy', tokens)\n",
    "\n",
    "#labels\n",
    "np.save(MODEL_PATH/'train_lbl.npy', list(itertools.chain(*train_labels)))\n",
    "np.save(MODEL_PATH/'valid_lbl.npy', list(itertools.chain(*valid_labels)))\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our classifier further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train.\n",
      "Numericalizing valid.\n"
     ]
    }
   ],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    data_clas = TextClasDataBunch.from_tokens(MODEL_PATH,\n",
    "                                            bs=128,\n",
    "                                            max_vocab=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    data_clas = TextClasDataBunch.from_id_files(MODEL_PATH/'tmp')\n",
    "    data_clas.path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clas.train_ds.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "DOWNLOAD_INIT_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier_learner(data:DataBunch, bptt:int=70, emb_sz:int=400, nh:int=1150, nl:int=3, pad_token:int=1,\n",
    "               drop_mult:float=1., qrnn:bool=False,max_len:int=10*70, lin_ftrs:Collection[int]=None,\n",
    "               ps:Collection[float]=None, **kwargs) -> 'TextClassifierLearner':\n",
    "    \"Create a RNN classifier.\"\n",
    "    dps = default_dropout['classifier'] * drop_mult\n",
    "    if lin_ftrs is None: lin_ftrs = [50]\n",
    "    if ps is None:  ps = [0.1]\n",
    "    ds = data.train_ds\n",
    "    vocab_size, n_class = len(data.vocab.itos), len(np.unique(data.train_ds.labels))\n",
    "    layers = [emb_sz*3] + lin_ftrs + [n_class]\n",
    "    ps = [dps[4]] + ps\n",
    "    model = get_rnn_classifier(bptt, max_len, n_class, vocab_size, emb_sz, nh, nl, pad_token,\n",
    "                layers, ps, input_p=dps[0], weight_p=dps[1], embed_p=dps[2], hidden_p=dps[3], qrnn=qrnn)\n",
    "    learn = RNNLearner(data, model, bptt, split_func=rnn_classifier_split, **kwargs)\n",
    "    return learn\n",
    "\n",
    "default_dropout = {'language': np.array([0.25, 0.1, 0.2, 0.02, 0.15]),\n",
    "                   'classifier': np.array([0.4,0.5,0.05,0.3,0.4])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True) -> Rank0Tensor:\n",
    "    \"Computes the f_beta between preds and targets\"\n",
    "    beta2 = beta**2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.5, metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "# itos_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "# if DOWNLOAD_INIT_MODEL:\n",
    "#     Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_INIT_MODEL:\n",
    "    untar_data('https://s3.amazonaws.com/fast-ai-modelzoo/wt103',\n",
    "               dest=MODEL_PATH/'models'/f'{init_model_name}')\n",
    "    \n",
    "    # trained weights\n",
    "    with open(MODEL_PATH/'models'/f'{model_name}_best.pth', 'wb') as f:\n",
    "        res = requests.get(f'https://storage.googleapis.com/w210-capstone/models/{model_name}_best.pth')\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a folder in this model's directory with the name of the initializer model. In that folder, copy a .pth file in the form lstm_<init_model_name>.pth and a .pkl file in the form itos_<init_model_name>.pkl' in order to transfer weights and tokens correctly from the initializer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    learn.load_pretrained(MODEL_PATH/f'{init_model_name}/lstm_{init_model_name}.pth', \n",
    "                          MODEL_PATH/f'{init_model_name}/itos_{init_model_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    if not GPU:\n",
    "        learn.cpu_load(f'{model_name}_best')\n",
    "    else:\n",
    "        learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 35:34\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.771330    12.827343   0.170142  (35:34)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 35:46\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.780451    2.777184    0.172278  (35:46)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(1, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  2.7771838\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e3d5dd93cbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mpred_batch\u001b[0;34m(self, is_test)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "learn.pred_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save_encoder(f'{model_name}_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    MODEL_OUTPUT_NAME = MODEL_PATH/'models'/f'{model_name}_best.pth'\n",
    "    CLOUD_STORAGE = f'gs://w210-capstone/models/{model_name}_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.1-LM-108k-lines/models/4.1-LM-108k-lines_best.pth [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/150.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $MODEL_OUTPUT_NAME $CLOUD_STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE_PATH = MODEL_PATH/'models'/f'{model_name}_architecture.pkl'\n",
    "ARCHITECTURE_STORAGE = f'gs://w210-capstone/models/{model_name}_architecture.pkl'\n",
    "ITOS_PATH = MODEL_PATH/'tmp'/'itos.pkl'\n",
    "ITOS_STORAGE = f'gs://w210-capstone/models/{model_name}_itos.pkl'\n",
    "\n",
    "model_dump = learn.model\n",
    "with open(ARCHITECTURE_PATH, 'wb') as f:\n",
    "    pickle.dump(model_dump, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.1-LM-108k-lines/models/4.1-LM-108k-lines_architecture.pkl [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/335.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $ARCHITECTURE_PATH $ARCHITECTURE_STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.1-LM-108k-lines/tmp/itos.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][310.1 KiB/310.1 KiB]                                                \n",
      "Operation completed over 1 objects/310.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $ITOS_PATH $ITOS_STORAGE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
