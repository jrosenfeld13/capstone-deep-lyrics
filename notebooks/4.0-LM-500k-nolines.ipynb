{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions\n",
    "Define this notebooks \"initializer model\" (pretrained parameters and itos mapping) and the output model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '4.0-LM-500k-nolines'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "init_model_name = 'wt103'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "To create the model's tokens with the correct train-test split, run the code below. Only needed once on the notebook's first ever run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FIRST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics, line_num=True):\n",
    "    '''\n",
    "    Tokenizes lyrics\n",
    "    '''\n",
    "    tk = nltk.tokenize.LineTokenizer(blanklines='keep')\n",
    "    tokd = tk.tokenize(lyrics)\n",
    "    \n",
    "    re_tk = nltk.tokenize.RegexpTokenizer(r'\\[[^\\]]+\\]|\\w+|[\\d\\.,]+|\\S+',\n",
    "                                          discard_empty=False)\n",
    "    re_tokd = re_tk.tokenize_sents(tokd)\n",
    "    \n",
    "    if line_num:\n",
    "        [s.insert(0, f'xBOL {line_num+1}') for line_num, s in enumerate(re_tokd)] # insert start token for each line\n",
    "    else:\n",
    "        [s.insert(0, f'xBOL') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "    [s.append('xEOL') for s in re_tokd] # append end token for each line\n",
    "    \n",
    "    flat = list(itertools.chain(*re_tokd))\n",
    "    flat.insert(0, 'xBOS')\n",
    "    flat.append('xEOS')\n",
    "    # lower case and de-space\n",
    "    flat = [w.lower().replace(' ', '-') for w in flat]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens(model_path, small_corpus=False, line_num=True):\n",
    "    '''\n",
    "    500k link: https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv\n",
    "    108k link: https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv\n",
    "    '''\n",
    "    model_path = Path(model_path)\n",
    "    model_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    small_corpus_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv'\n",
    "    large_corpus_url = 'https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv'\n",
    "\n",
    "    # load scraped data\n",
    "    if small_corpus:\n",
    "        df = pd.read_csv(small_corpus_url,\n",
    "                     header=None, escapechar='\\\\',\n",
    "                     names=['msd_id', 'lyrics'])\n",
    "    \n",
    "    if not small_corpus:\n",
    "        df = pd.read_csv(large_corpus_url, index_col=[0])\n",
    "    \n",
    "    # only keep lyrics with length < 5000\n",
    "    df = df[df.lyrics.str.len() < 5000]\n",
    "    print('Tokenizing...')\n",
    "    df['tokd'] = df.lyrics.apply(tokenize_lyrics, line_num=line_num)\n",
    "    df['tokd_len'] = df.tokd.apply(len)\n",
    "\n",
    "    # split train/test\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=2018)\n",
    "    \n",
    "    # tokens\n",
    "    print('Saving...')\n",
    "    tokens = np.array(df_train.tokd)\n",
    "    np.save(model_path/'train_tok.npy', tokens)\n",
    "    \n",
    "    tokens = np.array(df_test.tokd)\n",
    "    np.save(model_path/'valid_tok.npy', tokens)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    process_tokens(MODEL_PATH, small_corpus=False, line_num=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                          bs=128,\n",
    "                                          max_vocab=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.from_id_files(MODEL_PATH/'tmp')\n",
    "    data_lm.path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "DOWNLOAD_INIT_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "# itos_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "# if DOWNLOAD_INIT_MODEL:\n",
    "#     Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/models/4.0-LM-500k-nolines/models/wt103')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untar_data('https://s3.amazonaws.com/fast-ai-modelzoo/wt103',\n",
    "           dest=MODEL_PATH/'models'/f'{init_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    learn.load_pretrained(MODEL_PATH/'models'/f'{init_model_name}/lstm_{init_model_name}.pth', \n",
    "                          MODEL_PATH/'models'/f'{init_model_name}/itos_{init_model_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    if not GPU:\n",
    "        learn.cpu_load(f'{model_name}_best')\n",
    "    else:\n",
    "        learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1:10:44\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.838940    2.722366    0.486826  (1:10:44)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 11:47:17\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.754317    2.653085    0.497598  (1:10:42)\n",
      "2      2.695400    2.614056    0.503625  (1:10:30)\n",
      "3      2.670430    2.586842    0.507888  (1:10:42)\n",
      "4      2.634851    2.567393    0.510872  (1:10:47)\n",
      "5      2.616007    2.548971    0.513701  (1:10:39)\n",
      "6      2.625343    2.538556    0.515376  (1:10:52)\n",
      "7      2.615963    2.527840    0.517034  (1:10:49)\n",
      "8      2.572687    2.516187    0.518694  (1:10:45)\n",
      "9      2.562337    2.507846    0.520121  (1:10:37)\n",
      "10     2.589528    2.503078    0.520817  (1:10:49)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(10, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  2.5030775\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save_encoder(f'{model_name}_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT_NAME = MODEL_PATH/'models'/f'{model_name}_best.pth'\n",
    "CLOUD_STORAGE = f'gs://w210-capstone/models/{model_name}_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.0-LM-500k-nolines/models/4.0-LM-500k-nolines_best.pth [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/150.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $MODEL_OUTPUT_NAME $CLOUD_STORAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, context_length, temp=1):\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = '\\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = word\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], max_len=500, GPU=False, context_length=20, beam_width=5, verbose=True, temp=1):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    temperature : float\n",
    "        Scales the logits before softmax. A higher temp (>1) increases variety whereas a low temp (<=1) will often result in a loop\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in range(max_len):\n",
    "        if verbose: print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "            top_probabilities = np.argwhere(multinom_draw != 0).flatten()\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "        \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "#         np.random.shuffle(context_and_scores)\n",
    "\n",
    "        context_and_scores = context_and_scores[:15] #for now, only keep the top 15 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "    \n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU, seed_text='xbos xbol', max_len=80, context_length=40, beam_width=3, verbose=False, temp=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you didn 't have to make up your mind \n",
      " xbol to 210.72907546229337\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you didn 't have to make up your mind \n",
      " xbol so 211.5495533756906\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do it as far as i do \n",
      " xbol you didn 't have to do \n",
      " xbol \n",
      " 212.44683778045095\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why don 't \n",
      " xbol you 212.70213234564133\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why don 't \n",
      " xeos\n",
      "213.30172145884578\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do the way we do \n",
      " xbol 213.3856910513018\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do it as far as i do \n",
      " xbol you didn 't have to do it yet \n",
      " 213.80215126285265\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do it as far as i do \n",
      " xbol you didn 't have to do it with one 214.52989788150515\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why \n",
      " xbol i 've been 215.44938417616098\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you didn 't have to make up your mind everytime \n",
      " xbol 215.462650333573\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do it as far as i do \n",
      " xbol you didn 't have to do \n",
      " xbol two 216.05020367924715\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why \n",
      " xbol \n",
      " xbol time 216.44904259290854\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why don 't you ask me 216.7407311798609\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why \n",
      " xbol i 've tried 217.30807831485012\n",
      "\n",
      "\n",
      "xbos xbol hop off put it on ice \n",
      " xbol if you 've got my heart broken \n",
      " xbol i don 't know where you 've gone to \n",
      " xbol no , if you don 't like my love \n",
      " xbol then i don 't, i just don 't know ... \n",
      " xbol \n",
      " xbol oh baby \n",
      " xbol you didn 't have to do everything you do \n",
      " xbol you don 't have to do why \n",
      " xbol \n",
      " xbol step 217.60093647969447\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "for song, score in final_scores:\n",
    "    print_words(song)\n",
    "    print(score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
