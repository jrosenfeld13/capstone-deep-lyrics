{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions\n",
    "Define this notebooks \"initializer model\" (pretrained parameters and itos mapping) and the output model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '4.2-LM-108k-lines-genre-song_title'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "init_model_name = '4.1-LM-108k-lines'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')\n",
    "INIT_MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "To create the model's tokens with the correct train-test split, run the code below. Only needed once on the notebook's first ever run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FIRST_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics_with_tags(lyrics, line_num=True, genre=False, song_title=False):\n",
    "    tk = nltk.tokenize.LineTokenizer(blanklines='keep')\n",
    "    tokd = tk.tokenize(lyrics)\n",
    "    \n",
    "    re_tk = nltk.tokenize.RegexpTokenizer(r'\\[[^\\]]+\\]|\\w+|[\\d\\.,]+|\\S+',\n",
    "                                          discard_empty=False)\n",
    "    re_tokd = re_tk.tokenize_sents(tokd)\n",
    "\n",
    "    if genre:\n",
    "        [s.insert(0, f'xGENRE') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "    elif song_title:\n",
    "        [s.insert(0, f'xTITLE') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "    else:\n",
    "        if line_num:\n",
    "            [s.insert(0, f'xBOL {line_num+1}') for line_num, s in enumerate(re_tokd)] # insert start token for each line\n",
    "        else:\n",
    "            [s.insert(0, f'xBOL') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "        [s.append('xEOL') for s in re_tokd] # append end token for each line\n",
    "\n",
    "    flat = list(itertools.chain(*re_tokd))\n",
    "    # lower case and de-space\n",
    "    flat = [w.lower().replace(' ', '-') for w in flat]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens(model_path):\n",
    "    '''\n",
    "    500k link: https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv\n",
    "    108k link: https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv\n",
    "    '''\n",
    "    model_path = Path(MODEL_PATH)\n",
    "    model_path.mkdir(exist_ok=True)\n",
    "\n",
    "    small_corpus_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv'\n",
    "    audio_url = 'https://storage.googleapis.com/w210-capstone/data/msd-aggregate.csv'\n",
    "    tag_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics_tags.csv'\n",
    "\n",
    "    # load scraped data\n",
    "    df = pd.read_csv(small_corpus_url,\n",
    "                     header=None, escapechar='\\\\',\n",
    "                     names=['msd_id', 'lyrics'])\n",
    "\n",
    "    # only keep lyrics with length < 5000\n",
    "    df = df[df.lyrics.str.len() < 5000]\n",
    "\n",
    "    # bring in audio features\n",
    "    df_audio = pd.read_csv(audio_url)\n",
    "    df_audio.rename(columns={'track_id': 'msd_id'}, inplace=True)\n",
    "\n",
    "    # bring in tags\n",
    "    df_tags = pd.read_csv(tag_url, index_col=0)\n",
    "    df_tags.drop(columns=['lyrics'], inplace=True)\n",
    "\n",
    "    # match audio to keys from lyrics\n",
    "    df_audio = pd.merge(df, df_audio, how='inner', on='msd_id')\n",
    "\n",
    "    # mat\n",
    "    df_all = pd.merge(df_audio, df_tags, how='inner', on='msd_id')\n",
    "    df = df_all[['tag1', 'tag2', 'title', 'lyrics']]\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    lyrics = df.lyrics.apply(tokenize_lyrics_with_tags, line_num=True)\n",
    "    genre = df.tag1.astype(str).apply(tokenize_lyrics_with_tags, line_num=False, genre=True)\n",
    "    song_title = df.title.apply(tokenize_lyrics_with_tags, line_num=False, song_title=True)\n",
    "\n",
    "    full_song = (['xbos'] + genre + song_title + lyrics + ['xeos'])\n",
    "\n",
    "    # split train/test\n",
    "    df_train, df_test = train_test_split(full_song, test_size=0.2, random_state=2018)\n",
    "\n",
    "    # tokens\n",
    "    print('Saving...')\n",
    "    tokens = np.array(df_train)\n",
    "    np.save(model_path/'train_tok.npy', tokens)\n",
    "\n",
    "    tokens = np.array(df_test)\n",
    "    np.save(model_path/'valid_tok.npy', tokens)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    process_tokens(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                          bs=128,\n",
    "                                          max_vocab=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.from_id_files(MODEL_PATH/'tmp')\n",
    "    data_lm.path = MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "DOWNLOAD_INIT_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "# itos_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "# if DOWNLOAD_INIT_MODEL:\n",
    "#     Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_INIT_MODEL:\n",
    "    untar_data('https://s3.amazonaws.com/fast-ai-modelzoo/wt103',\n",
    "               dest=MODEL_PATH/'models'/f'{init_model_name}')\n",
    "    \n",
    "    # trained weights\n",
    "    with open(MODEL_PATH/'models'/f'{model_name}_best.pth', 'wb') as f:\n",
    "        res = requests.get(f'https://storage.googleapis.com/w210-capstone/models/{model_name}_best.pth')\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a folder in this model's directory with the name of the initializer model. In that folder, copy a .pth file in the form lstm_<init_model_name>.pth and a .pkl file in the form itos_<init_model_name>.pkl' in order to transfer weights and tokens correctly from the initializer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    learn.load_pretrained(MODEL_PATH/f'{init_model_name}/lstm_{init_model_name}.pth', \n",
    "                          MODEL_PATH/f'{init_model_name}/itos_{init_model_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    if not GPU:\n",
    "        learn.cpu_load(f'{model_name}_best')\n",
    "    else:\n",
    "        learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(10, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save_encoder(f'{model_name}_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN: pass\n",
    "MODEL_OUTPUT_NAME = MODEL_PATH/'models'/f'{model_name}_best.pth'\n",
    "CLOUD_STORAGE = f'gs://w210-capstone/models/{model_name}_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.2-LM-108k-lines-genre-song_title/models/4.2-LM-108k-lines-genre-song_title_best.pth [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/150.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $MODEL_OUTPUT_NAME $CLOUD_STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE_PATH = MODEL_PATH/'models'/f'{model_name}_architecture.pkl'\n",
    "ARCHITECTURE_STORAGE = f'gs://w210-capstone/models/{model_name}_architecture.pkl'\n",
    "ITOS_PATH = MODEL_PATH/'tmp'/'itos.pkl'\n",
    "ITOS_STORAGE = f'gs://w210-capstone/models/{model_name}_itos.pkl'\n",
    "\n",
    "model_dump = learn.model\n",
    "with open(ARCHITECTURE_PATH, 'wb') as f:\n",
    "    pickle.dump(model_dump, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.2-LM-108k-lines-genre-song_title/models/4.2-LM-108k-lines-genre-song_title_architecture.pkl [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/381.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $ARCHITECTURE_PATH $ARCHITECTURE_STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/models/4.2-LM-108k-lines-genre-song_title/tmp/itos.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][310.2 KiB/310.2 KiB]                                                \n",
      "Operation completed over 1 objects/310.2 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $ITOS_PATH $ITOS_STORAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp.generate_lyrics import DeepLyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_lyric = DeepLyric(learn.model, weights=None, itos=data_lm.train_ds.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_lyric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word: 1 / 50\n",
      "Generating word: 2 / 50\n",
      "Generating word: 3 / 50\n",
      "Generating word: 4 / 50\n",
      "Generating word: 5 / 50\n",
      "Generating word: 6 / 50\n",
      "Generating word: 7 / 50\n",
      "Generating word: 8 / 50\n",
      "Generating word: 9 / 50\n",
      "Generating word: 10 / 50\n",
      "Generating word: 11 / 50\n",
      "Generating word: 12 / 50\n",
      "Generating word: 13 / 50\n",
      "Generating word: 14 / 50\n",
      "Generating word: 15 / 50\n",
      "Generating word: 16 / 50\n",
      "Generating word: 17 / 50\n",
      "Generating word: 18 / 50\n",
      "Generating word: 19 / 50\n",
      "Generating word: 20 / 50\n",
      "Generating word: 21 / 50\n",
      "Generating word: 22 / 50\n",
      "Generating word: 23 / 50\n",
      "Generating word: 24 / 50\n",
      "Generating word: 25 / 50\n",
      "Generating word: 26 / 50\n",
      "Generating word: 27 / 50\n",
      "Generating word: 28 / 50\n",
      "Generating word: 29 / 50\n",
      "Generating word: 30 / 50\n",
      "Generating word: 31 / 50\n",
      "Generating word: 32 / 50\n",
      "Generating word: 33 / 50\n",
      "Generating word: 34 / 50\n",
      "Generating word: 35 / 50\n",
      "Generating word: 36 / 50\n",
      "Generating word: 37 / 50\n",
      "Generating word: 38 / 50\n",
      "Generating word: 39 / 50\n",
      "Generating word: 40 / 50\n",
      "Generating word: 41 / 50\n",
      "Generating word: 42 / 50\n",
      "Generating word: 43 / 50\n",
      "Generating word: 44 / 50\n",
      "Generating word: 45 / 50\n",
      "Generating word: 46 / 50\n",
      "Generating word: 47 / 50\n",
      "Generating word: 48 / 50\n",
      "Generating word: 49 / 50\n",
      "Generating word: 50 / 50\n"
     ]
    }
   ],
   "source": [
    "deep_lyric.generate_text(seed_text='xbos xgenre country', \n",
    "                         verbose=1, context_length=100, beam_width=3,\n",
    "                         max_len=50, top_k=5, temperature=1.45,\n",
    "                         GPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONG START\n",
      " genre: country \n",
      " title: the kiss of gold \n",
      "\n",
      "xbol-1 when i 'm with you \n",
      " there 's so much out there for me \n",
      " here and now , my dear \n",
      " there is nothing more left to do \n",
      " \n",
      " when my whole life through \n",
      " i "
     ]
    }
   ],
   "source": [
    "deep_lyric.print_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_lyric.save_lyrics_to_file('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word: 1 / 20\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-aa332739c49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdeep_lyric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdeep_lyric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_lyrics_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test{i}.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/capstone-deep-lyrics/notebooks/src/nlp/generate_lyrics.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(self, seed_text, max_len, GPU, context_length, beam_width, verbose, temperature, top_k, audio)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_and_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# Obtain probabilities for next word given the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;31m# Multinomial draw from the probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/capstone-deep-lyrics/notebooks/src/nlp/generate_lyrics.py\u001b[0m in \u001b[0;36mget_text_distribution\u001b[0;34m(self, context, context_length, temperature, GPU, audio)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# forward pass the \"context\" into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'language'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pre-multi'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'post-multi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/text/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mraw_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_dp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mnew_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fastai/text/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, scale)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmasked_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n\u001b[0;32m---> 70\u001b[0;31m                            self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#def _repackage_var(h:Tensors)->Tensors:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    deep_lyric.generate_text(max_len=20)\n",
    "    deep_lyric.save_lyrics_to_file(f'test{i}.txt', GPU=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
