{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning PyTorch for Multimodality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model of Sequential Modules\n",
    "\n",
    "Example from [here](https://github.com/jcjohnson/pytorch-examples#pytorch-optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 707.7402954101562\n",
      "1 694.0547485351562\n",
      "2 680.6409301757812\n",
      "3 667.4664306640625\n",
      "4 654.5130615234375\n",
      "5 641.800537109375\n",
      "6 629.3379516601562\n",
      "7 617.1375732421875\n",
      "8 605.156494140625\n",
      "9 593.393798828125\n",
      "10 581.8489990234375\n",
      "11 570.5316162109375\n",
      "12 559.4170532226562\n",
      "13 548.4935302734375\n",
      "14 537.7697143554688\n",
      "15 527.2457885742188\n",
      "16 516.91748046875\n",
      "17 506.77734375\n",
      "18 496.7988586425781\n",
      "19 486.9962158203125\n",
      "20 477.3673095703125\n",
      "21 467.897216796875\n",
      "22 458.6047058105469\n",
      "23 449.4712219238281\n",
      "24 440.4930114746094\n",
      "25 431.6700744628906\n",
      "26 422.9800720214844\n",
      "27 414.42974853515625\n",
      "28 406.0163879394531\n",
      "29 397.7267761230469\n",
      "30 389.5657653808594\n",
      "31 381.53240966796875\n",
      "32 373.6302185058594\n",
      "33 365.85687255859375\n",
      "34 358.19830322265625\n",
      "35 350.66436767578125\n",
      "36 343.2438659667969\n",
      "37 335.9500427246094\n",
      "38 328.7704772949219\n",
      "39 321.715576171875\n",
      "40 314.7672119140625\n",
      "41 307.9325866699219\n",
      "42 301.1885681152344\n",
      "43 294.5320129394531\n",
      "44 287.96746826171875\n",
      "45 281.50494384765625\n",
      "46 275.1405944824219\n",
      "47 268.890869140625\n",
      "48 262.7414855957031\n",
      "49 256.6768493652344\n"
     ]
    }
   ],
   "source": [
    "N, D_in, Z_in, H, H2, D_out = 64, 400, 20, 300, 200, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "z = torch.randn(N, Z_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(50):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.weight', '0.bias', '2.weight', '2.bias'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding to \"Multi-Modal\" with Custom Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So rather than stringing together modules like above, we have to create a custom class for our model. Mainly, this is because we are concatenating multiple inputs.\n",
    "\n",
    "This still hasn't been tested on real data, and I don't know all the \"gotchas\" of these modules yet, but this works as expected thus far, and creates weight matrices as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multimodal(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, Z_in, H2, D_out):\n",
    "        super(Multimodal, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.multi = torch.nn.Linear(H + Z_in, H2)\n",
    "        self.linear2 = torch.nn.Linear(H2, D_out)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        h1 = self.linear1(x)\n",
    "        h1_z = torch.cat([h1, z], dim=1)\n",
    "        h2 = self.multi(h1_z)\n",
    "        out = self.linear2(h2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 686.3792114257812\n",
      "1 669.9608764648438\n",
      "2 653.8302612304688\n",
      "3 637.9819946289062\n",
      "4 622.4102783203125\n",
      "5 607.1083984375\n",
      "6 592.0684814453125\n",
      "7 577.2822265625\n",
      "8 562.7410278320312\n",
      "9 548.4363403320312\n",
      "10 534.3598022460938\n",
      "11 520.5030517578125\n",
      "12 506.8583068847656\n",
      "13 493.4178466796875\n",
      "14 480.1744384765625\n",
      "15 467.1211853027344\n",
      "16 454.2517395019531\n",
      "17 441.5601806640625\n",
      "18 429.0411682128906\n",
      "19 416.68994140625\n",
      "20 404.5023193359375\n",
      "21 392.4747314453125\n",
      "22 380.604248046875\n",
      "23 368.8885498046875\n",
      "24 357.3259582519531\n",
      "25 345.9154357910156\n",
      "26 334.65643310546875\n",
      "27 323.54913330078125\n",
      "28 312.59417724609375\n",
      "29 301.7928161621094\n",
      "30 291.1467590332031\n",
      "31 280.6581726074219\n",
      "32 270.3296813964844\n",
      "33 260.16436767578125\n",
      "34 250.16555786132812\n",
      "35 240.3369598388672\n",
      "36 230.6824951171875\n",
      "37 221.20635986328125\n",
      "38 211.912841796875\n",
      "39 202.80638122558594\n",
      "40 193.8914337158203\n",
      "41 185.17250061035156\n",
      "42 176.65402221679688\n",
      "43 168.3402862548828\n",
      "44 160.23550415039062\n",
      "45 152.34361267089844\n",
      "46 144.66835021972656\n",
      "47 137.21310424804688\n",
      "48 129.98095703125\n",
      "49 122.97457885742188\n"
     ]
    }
   ],
   "source": [
    "N, D_in, Z_in, H, H2, D_out = 64, 400, 20, 300, 200, 10\n",
    "\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "z = torch.randn(N, Z_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "model = Multimodal(D_in, H, Z_in, H2, D_out)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(50):\n",
    "    y_pred = model(x, z)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the \"multi\" weights have input weights of length 320 because we take 300 from the output of `linear1` + 20 from the auxillary input (e.g. z) and then we map this to the output of 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear1.weight', 'linear1.bias', 'multi.weight', 'multi.bias', 'linear2.weight', 'linear2.bias'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 320])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().get('multi.weight').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal(\n",
      "  (linear1): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (multi): Linear(in_features=320, out_features=200, bias=True)\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
