{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Lyrics Generator - ULMFiT\n",
    "\n",
    "## Set up instructions\n",
    "\n",
    "### Create VM Instance\n",
    "\n",
    "- Go to cloud.google.com, and create a new VM instance\n",
    "- Disk size: 100GB or more\n",
    "- CPUs + Memory: 2vCPUs, 7.5 GB Memory\n",
    "- GPU: K80 (cheaper, less power) or P100 (2.5x more expensive, more power)\n",
    "- Enable http, https traffic\n",
    "- Boot: Deep learning pytorch instance\n",
    "\n",
    "### Network configuration\n",
    "\n",
    "In Google cloud platform:\n",
    "\n",
    "- Go to Networking -> VPC Network, External IP addresses\n",
    "- Select your VM instance and change the external address type from Ephemeral to Static\n",
    "- Go to Networking -> VPC Network, Firewall Rules\n",
    "- Add a new Rule, called Jupyter, ip ranges 0.0.0.0/0, protocols and ports tcp:8888, apply to all targets\n",
    "\n",
    "### VM + Jupyter Setup\n",
    "\n",
    "- SSH to VM\n",
    "- Enlist into Github repo\n",
    "- Run src/setup.sh\n",
    "- Run jupyter notebook\n",
    "- Open a google cloud shell\n",
    "- Run gcloud init and answer the questions\n",
    "- To set up a tunnel and run jupyter locally, run ```gcloud compute --project \"<your project>\" ssh --zone \"<your zone>\" \"<your instance name>\" -- -L 8888:localhost:8888```\n",
    "- Open jupyter notebook in your local computer and have fun\n",
    "\n",
    "### Notebook first run\n",
    "Here are some steps to run the first time you use the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokens\n",
    "To create the model's tokens with the correct train-test split, run ```src/data_collection/lm_data_lyrics.py -o path/to/save```. \n",
    "We recommend saving in data/models/{MODEL_NAME}. Alternatively, run the magic command below and replace the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train.\n",
      "Numericalizing valid.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/data_collection/lm_data_lyrics.py -o ../data/models/3.3-ULMFiT-108k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '3.3-ULMFiT-108k'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)\n",
    "\n",
    "print(data_lm.train_ds.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  pretrained_model=URLs.IMDB,\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1432a6b8e0f409f8d80925567999a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=141772796), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DOWNLOAD_MODEL_WEIGHTS = True\n",
    "weights_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "if DOWNLOAD_MODEL_WEIGHTS:\n",
    "    Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "    download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GPU:\n",
    "    learn.cpu_load(f'{model_name}_best')\n",
    "else:\n",
    "    learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 12:41\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      3.217470    3.144312    0.427131  (12:41)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value='0.00% [0/5 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1:03:24\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      3.155382    3.080042    0.433641  (12:36)\n",
      "1      3.095709    3.042187    0.437375  (12:41)\n",
      "2      3.053704    3.006545    0.441227  (12:43)\n",
      "3      3.007466    2.978606    0.444195  (12:42)\n",
      "4      2.949047    2.956026    0.446773  (12:41)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(5, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value='0.00% [0/5 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1:03:31\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      2.759288    2.828644    0.460429  (12:45)\n",
      "1      2.688502    2.821735    0.461557  (12:41)\n",
      "2      2.672965    2.818378    0.462140  (12:39)\n",
      "3      2.722103    2.815085    0.461849  (12:42)\n",
      "4      2.686170    2.808238    0.462962  (12:42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "#     learn.unfreeze()\n",
    "    learn.fit(5, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  2.8082383\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4FVX6B/Dvm05IIJTQwUhHuiAqTURUBBfX1f2tuMWy6rq6iKtbECu4Kqtrw+6ua1n7uioKiNLBRpXem7QAoYUESD+/P6ZkZu7MnZtwU+by/TxPnsydmXvvyeTe95x5zzkzopQCERHFlriaLgAREUUfgzsRUQxicCciikEM7kREMYjBnYgoBjG4ExHFIAZ3IqIYxOBORBSDGNyJiGJQQk29cePGjVVWVlZNvT0RUSAtW7bsoFIq02+/GgvuWVlZWLp0aU29PRFRIInIj5Hsx7QMEVEMYnAnIopBDO5ERDGIwZ2IKAYxuBMRxSAGdyKiGMTgTkQUgwIX3Dftz8NTX23EwfzCmi4KEVGtFbjgvnl/PibP2YLDx4tquihERLVW4II7ERH5Y3AnIopBgQ3uStV0CYiIaq/ABXeRmi4BEVHtF7jgTkRE/hjciYhiEIM7EVEMCmxwV2CPKhGRl8AFd/anEhH5C1xwJyIifwzuREQxKLDBnZOYiIi8+QZ3EUkRkcUislJE1orIhDD7Xi0iSkT6RreY1veoqlcmIoodCRHsUwhgqFIqX0QSAXwtIl8opb637iQi6QDuALCoCspJREQV4NtyV5p8/WGi/uOWFHkYwOMACqJXPCIiqoyIcu4iEi8iKwAcADBTKbXIsb03gNZKqak+r3OLiCwVkaU5OTmVLjQREYUXUXBXSpUqpXoBaAWgn4h0M7aJSByApwHcHcHrvKqU6quU6puZmVnZMuuvdUpPJyKKaRUaLaOUOgpgHoDhltXpALoBmCciOwCcB+CzqutUZY8qEZGfSEbLZIpIhr5cB8AwABuM7UqpXKVUY6VUllIqC8D3AEYppZZWUZmJiMhHJC335gDmisgqAEug5dynishEERlVtcUjIqLK8B0KqZRaBaC3y/oHPPYfcurF8scLhxEReQvcDFVOYiIi8he44E5ERP4Y3ImIYlBggzvHuRMReQtccGfKnYjIX+CCOxER+WNwJyKKQQzuREQxiMGdiCgGBS64C2cxERH5ClxwJyIifwzuREQxKLDBnZOYiIi8BS64M+NOROQvcMGdiIj8MbgTEcWgwAZ33qyDiMhb4II7h7kTEfkLXHAnIiJ/DO5ERDGIwZ2IKAYFNrhzEhMRkbfABXd2qBIR+QtccCciIn8M7kREMSiwwZ0pdyIib4EL7sJLhxER+QpccCciIn8M7kREMYjBnYgoBgU2uCvOYiIi8hS84M7+VCIiX8EL7kRE5IvBnYgoBgU2uDPjTkTkLXDBnSl3IiJ/gQvuRETkzze4i0iKiCwWkZUislZEJrjsc5eIrBORVSIyW0TOqJriEhFRJCJpuRcCGKqU6gmgF4DhInKeY58fAPRVSvUA8BGAx6NbzFAc5k5E5M03uCtNvv4wUf9Rjn3mKqVO6A+/B9AqqqW0EN6tg4jIV0Q5dxGJF5EVAA4AmKmUWhRm998C+MLjdW4RkaUisjQnJ6fipSUioohEFNyVUqVKqV7QWuT9RKSb234i8isAfQE84fE6ryql+iql+mZmZla2zERE5KNCo2WUUkcBzAMw3LlNRIYBuBfAKKVUYVRKR0RElRLJaJlMEcnQl+sAGAZgg2Of3gBegRbYD1RFQUOxR5WIyEtCBPs0B/CmiMRDqww+VEpNFZGJAJYqpT6DloZJA/BfvcNzp1JqVFUUmN2pRET+fIO7UmoVgN4u6x+wLA+LcrmIiOgUcIYqEVEMCmxw5yQmIiJvgQvunMNEROQvcMGdiIj8MbgTEcUgBnciohgU2ODO/lQiIm+BC+7CaUxERL4CF9yJiMgfgzsRUQwKbHDnJCYiIm+BC+6cxERE5C9wwZ2IiPwxuBMRxaDABnfFpDsRkafABXem3ImI/AUuuBMRkT8GdyKiGMTgTkQUgwIb3NmdSkTkLXjBnT2qRES+ghfciYjIF4M7EVEMCmxw5xwmIiJvgQvuvFkHEZG/wAV3IiLyx+BORBSDAhvcFUe6ExF5Clxw5806iIj8BS64ExGRPwZ3IqIYxOBORBSDghvc2Z9KROQpcMGd/alERP4CF9yJiMgfgzsRUQzyDe4ikiIii0VkpYisFZEJLvski8gHIrJFRBaJSFZVFNaKKXciIm+RtNwLAQxVSvUE0AvAcBE5z7HPbwEcUUq1B/A0gL9Ht5jlhLOYiIh8+QZ3pcnXHybqP86G8xUA3tSXPwJwkTAKExHVmIhy7iISLyIrABwAMFMptcixS0sAuwBAKVUCIBdAo2gWlIiIIhdRcFdKlSqlegFoBaCfiHRz7OLWSg9Ji4vILSKyVESW5uTkVLy0REQUkQqNllFKHQUwD8Bwx6bdAFoDgIgkAKgP4LDL819VSvVVSvXNzMysVIHLX+uUnk5EFNMiGS2TKSIZ+nIdAMMAbHDs9hmA6/TlqwHMUapqwi8z+URE/hIi2Kc5gDdFJB5aZfChUmqqiEwEsFQp9RmA1wD8R0S2QGuxX1NlJSYiIl++wV0ptQpAb5f1D1iWCwD8PLpFIyKiygrsDFXeiYmIyFvggjtT7kRE/gIX3ImIyB+DOxFRDApscOc4dyIib4EL7hznTkTkL3DBnYiI/DG4ExHFIAZ3IqIYFNjgzv5UIiJvAQzu7FElIvITwOBORER+GNyJiGJQYIN7FV0unogoJgQuuHMSExGRv8AFdyIi8sfgTkQUgwIb3JlxJyLyFrjgzpQ7EZG/wAV3IiLyx+BORBSDGNyJiGJQcIM7e1SJiDwFLrgLZzEREfkKXHAnIiJ/DO5ERDEosMFdMelOROQpcMGdGXciIn+BC+5EROSPwZ2IKAYxuBMRxaDABnfeiImIyFvggjvnMBER+Uuo6QJQBPatBvYsBxKSgfgk7ce2nATEJ4dZTmStSHSaYXAPgi2zgFkPndprxOuBPiHJo4LQK4H4ZMdyUoTPrczrJANxgTt5JAqEwAb30yrnfs7NQPefAyWFQGmR9lNSBJQWOpaL9X28lo3nhnmdwrzwzy0tiu7fFpfgXUnEJQBx8dpvideWJa58vbHOuuy5LsHy/Ahe0/V9Esqf7/uaEZbN8zXjWfHRKQlccI/T0wtlp1N0T07TfmoDpXwqGL/Kxq2CKbT8Ltb2LykEykqAslJAlerLZdpvY5sq1daZ20vL15nbS8t/W5dVKaDKavpo+rNVAnrAD6m0nOs8KhXPbXEuFVOcS2UTriJ0qzA9Kizn3xSf4EglulT2ZoUfX9P/kcDwDe4i0hrAWwCaASgD8KpS6lnHPvUBvA2gjf6a/1BKvR794p6mwb02EdG+ZAnJQHJNF+YUKeUI/uEqDJfKwXVdieX5pY5Kpiz0NUPWOZ7v+34eFZnXe5UUuOznVs5SxzEoQ8ixqolLgEi8oxJwpAt9+6PCVBy257ikEOMTvVOQ8Um17kwrkpZ7CYC7lVLLRSQdwDIRmamUWmfZ53YA65RSPxGRTAAbReQdpVSUz+GB+DgjuEf7lem0I6K1GoN3Als7OCvHcJVTWUloBWH8Li12P6NzTSHqZ4UlReH3K8p3PMfltctKons84hIclYB12dEP1e0qoPevovv+Dr6faqVUNoBsfTlPRNYDaAnAGtwVgHTRLraeBuAwtEoh6vTYjlJGd6KaFfTKsay0EhWHNXVoeY5r2tGSYrQ+p/ik9lPFKvRfEZEsAL0BLHJseh7AZwD2AkgH8AulqiahGRfHtAwRRUFcPBBXB0isU9MlqRIRJ4lEJA3A/wDcqZQ65th8KYAVAFoA6AXgeRGp5/Iat4jIUhFZmpOTU7kC6zl3xnYiIm8RBXcRSYQW2N9RSn3ssssNAD5Wmi0AtgPo7NxJKfWqUqqvUqpvZmZm5QrMtAwRkS/f4K7n0V8DsF4p9ZTHbjsBXKTv3xRAJwDbolVIK46WISLyF0nOfQCAXwNYLSIr9HXjoQ17hFLqZQAPA3hDRFZDu5/GX5VSB6ugvMy5ExFFIJLRMl/D5wZISqm9AC6JVqHCMQqyYlcufnFOdbwjEVHw1K5R9xE4fFwbOv/e4p01XJLqM2XFHmSNm4bjhVUyupSIYlDggnv9Ook1XYRq9+LcrQCAXUdO1HBJiCgoAhfcWzdMBQBc3z+rZgtSjZIStH9TQXEAroVCRLVC4II7ANRNijcvQ3A6SNaD+8G8whouCREFRSCDe0piPAqKS2u6GNVmS04+AODOD1b47ElEpAlkcE9OiDutUhS/6NsaAHDV2S1ruCREFBSBDO4pifEoLDl9Wu7G2P6UJF7LmogiE8jgnpwYH3HLvaS0DH/5aCUO5dd8vlophedmb8axgmLz8ZQVe3xTTCWl2t967CSHQhJRZAIZ3FMS4yJuuT87ezM+XLobff42q4pL5W/B5oN4cuYm9HjoKwDA/E05GPv+Cjw9c1PY5xWXarNx8/RKgShWrN2bi216nxJFVzCDe0LkHarPzdniuS33RHFUOmaVUliwKQfK5ZIIz83ejKxx0wCUX/TMcOCYdjaR43NWUViitdwXbz98ymUlqk1GTv4aQ5+cX9PFiEmBDO6lSmHJjiOYPHszpqzYE3bfHq3qh6w7kFeArHHT0HPiV7jyxW9PuTzjP1mN3/x7MTre90XItif1Vnl27kkzlWQE+Xx9xmmiz+25ivW0zIG8QjNFE87JolK8PH9rrbhyZmFJKc56YAa+XLvPfPybfy/Gmj25NVwyotgWyOButGCfmrkJY99fgc9X7sX5j83GnqMncdmzC3GyqLw1vmp3eRDZl1sAAFi7p/xy9OuznZemrzgjaBeXKmTnut9h5e4PV+LoCe3SCUbMXbBZu6Z9kSNgK6Ww63D5bNSikvLtxwr88+5dHpiBSV9swNUvn3rFVRllZcq8VMKWA/k4UVSK3/1nGQBgfXYeFmzKwT0fr66RshGdLgIZ3J3u/WQ1snMLMGDSHKzPPoaX52vT9a1BHigP5IUlkQ+jzBo3zUyrbMvJx0GXFMoZjVLN5UP57reNTUtOQO7J8px5cWkZOjVLBwCs3H3UVtZPftiDQY/PxeDH52Lz/jxbcLe+hp8fdh41l/MLS9D3b7Pw/uKd2LgvL+LXqIynZm5C1we/RHFpGcoch9o484iL8UloWw7ko6wWnDnR6Ssmgrsz/dAiIwUAsNfRip6+Ohtr9uTi319vr/B7tL1nGoY+OR99XTpmjcoEAE7oQTonrxCjX/0e6cnahTe/WrcfHy8vTyHNWLMPhXqLf1vOcfz2zSUAtOB314crAQA7D5/AxU8vMNMyAHDxU/N9g8bFZzUFAAxo38hc9/TMTTiYX4hxH6/Gpc8siPwPD+OdRT9i+DMLQvotnp+r9XPMXr8/pDLK0888oh3ai0vLMPb9H3DgWEHIthNFJbZjWBWW/XgE9326GkopbNqfh2FPzcefP1pl2X64VqTJaquiCjS4KDIxEdyPO1roRkelM7D8d9luXP7c11i8o7xjMiM1EfM2HnC9yqT1y2j9XlqD2YmiEtuwzP975TsAwLuLduK7bYeQZ7mS4zpLCkgBeOPbHebjb7cewnOzN5uB0cqatikpU5g4dR2OF5a4BjIAaF5fq9y+2XLIbCm7nXF4KS1TZuewV6fzV2v34d5P1mDDvjxs9RjtcOvby81hn4YjemrKLcxV5KzE6eqXvsWUFXtxxQvfhGw764EvcctbSyv92pH4zWuL8Pb3O5F7shg5+mUi/rd8NwBgyY7DuOql72yNALLjFU+jL5DB/d2bzw27/cmZmzBjTTa2HNCCzv9+f77nvskJcbj+9SW45+PV+MtHK80gOGXFHrQbP931OdZAefREaEAqK1PIyXcPvAa3lutr32zHM7M229Z1apqOopIyNE5LMte98e0O3PjGEvR7dDZmr9+PrHHTcOR4eTro/SW7zOXPVu4FUN7fEImrXvoWY977AXkFxeg58St0vn9GyD47LX0CztSLlTVgf7f1kHm8Vu46ihNF5V/oZT8eQc8JX6HPwzPxyLR12HnoBAZMmoPdEV4Jc6Xet5Jt+Ts3788zU2pzN1bunr1WPx46jqxx03Dli9+EnAkYDYypq7LNY52Rql3B1Og/2bQ/uumwsjKF5TuPuI7Sqm7zN+Xg/Mdmm48P5BVg3d7I+7PyGdyjLpDBvVVGqu8+Ez9fhw/1IBfubPh4YXmr9MOlu/G8PnRy7Pve13F5Z9FOszV74T/mAdDG3hvOeWQW3v6+/ExgSKfy+8W2bqjdaX3Mez+EvK5bRdGkXjKKSsuQmZ5iW79I71Q2hnpu1iuyopIy2ymusZxdgeC+YtdRTF2Vje76eHwAIQHkze92mMu3vq11lp4sKsWzjsrpKcsY/hW7jmL5ziPmY2vawhg9c+h4Ef65cDsGPzEXe46exC9e+T6iMndqqvVfnN0mw1z3O71cFbVu7zFbh7Zhygqtovxh51FbRz0AJOh9CLsOnzCv4lkvRQvuxv8gKT7067Zu77FKB+d+j87Gz1781qzAa9J1/16M7NwCfLNFuwHbiGcXYsTkhRE/33mGFwQlpWW1utyBDO51IpiGf02/NhjUQQuqvVpnuO5zff+skBZDTl6h2eL38tK8reh8/wxk5540O2dnjB2MCaO6AtAClFXPVhlonJYMAGiXmWbb9sDlZ+Ht33qfiRQUl6K41N5yz0xPNpeN1u9x/bezpTvu49V44ssNtpb2mY3r4su1+zBjTTZW7jpqCy5egcZ6nLTRPOX9GXuOasuvf7sdT8+yT8jKsVzJsqC4FFNXZZuPp+mt3LIyhQc/W+v6vnuOnsSrC7ZiX24Bhj45D1njpuH1b7Yja9w0W7poo94qXr7zqFmeq85u5fqabo6eKDI7tUdMXohBj88N2cfeErUfJ+MzlpQQZ6YYjGNupNUSE+xftwWbcjBi8kK8/f2PleoTMM4gv1q331y35UAeRjy7EFnjpuH9KNzQ5okvNyBr3DTM3XggZFvWuGno/uCXHmVzH1jg5VRSctXpu62HsP3gcQBAjwlfocdDX5np2z1HT2LpjtozFyWQwd3thh1X9Gphe5xfWGIGmsT4OHRsmoa6jkrBbdTItNXZGPaU+6SK16+339fv/MfmANBy3FmN6+Lctg1dn5eWnIAG+il6w7pJtm0N6yZhYIfGIc+ZcvsA9GydgYLiMhQWl6FuUvkdEY0hlQCwab9WEd3w+hLkniw2v1QD25e/5gtz7bne44Ul+N1/luHWt5fjihe+waeWuQJep8cTP1+H/XqO//Dx0C+uUgq7j7gPAzU8O3tzyLrzHpuN6WuyQ9YbxwsAHp2+AZc/txDbcrQvlZG6Ms5GnKOiHp2+HkoplJSWB+COTe2VqlOviTPR5YEZtiDrrOhm6GP1AaCoxL7NOG7PzdliOzvZdfiEeXY4d8MBW4VkpGnun7IWw59ZgF2HT+DTH8LP23Az35JyGvbUArNvZ1wUhpsan50bXl/iut3oU+rSvB6A0LPPcJ3I1uN7/6drIipPWZnyHFCQE8VLYheXlrmWffQ/vzfP1o3BE8YovAv/MQ9Xv/xd1MpwqgIZ3I3T3izLEMQpK/Zixp2D8N09Q5GekmALgIDWsl790KXY/tgI9G6TgWX3DcOFnTNREee3a+S63vgQNKuX4rq9bnKCGYjW7T1mm1jVwBHsAeBfv+mLnq0z0LxeClbvycXmA/lIT0nAzD8OxtV9WqHE48P99eaDZuAdd1nnkO23DG6LoZ2bmB9Kg1FBADADqNN/l+3GuY/OxuLth10v5TD+kzV4d1F5S/GmgWeaHbst6rsfF8Mf3g1NUQ3uaP/fWFuCRivvvk+14LXf0bE8bVU2zrxnOjbuL29pnywuxZQVe/C5Twqjw73lE9GsFZ0zoIz+pz1dZA3aHy7dbS4v33nErBSycwvQ+f4Z+NfCbSgoLsXfpq0399uacxyDHp+LOz9YgfmbcrBy11Hf1vzlPZqHlNOaHqyIiqaGnJWgcc+B299dbtvvpKMzfvgzC5A1bhr2HyuwBc+tHp87p7bjp6Pt+Okh5Z2+OhvnPDIrai3nDvd+YQ6O8GP8HUb6rTb0gQABDe4AsGbCpZh2xyDz8eTRvdG5WT00r18HLTPq4IjegmiZoeW44+IEcXECEcEntw1Ao7Rk/KRnC9fX9pKS6J4OOqC3GNJT3G8BmNUo1fwCbtiXh09vG2BuM1qo2x8bAQCYMKorhulDGa0twL25J9GhaTraZabB67OTnBCHA3laoGtSLzlke3pyAto0TA1pnb80byvOfXQWPly6y3W0iZX1Az/rrsEYM7Q9ACAnzx5gU5PikZGqVVyN0+1l+Vnvlp6pMqOchRFcGO6bLYdQUFyKfR6jhqavLm9pHy8sxdj3V2DMez9g7gZ7isEriFrPUNzSBscLS7D36Elc/txC7Djk3vGbEBeHlbuO2tb9bdr6sNcTuu7fi3HFC9/ggSlrMXn2ZrzmMnT3YH6hLcVVUFyKPUdP2j6DSQneX++yMoWBf5+DN/QU15n3TI+49QzYR7ccLyr1fK8Tlv3yCoqxQT9bPvfR2djvaGlXJChaJ/N9sTobt72jVSpLdhzxekrEjE74ZT/aX8s5akz0URHOM1nnpMTck8U4fLzIbCD8+rVF+O/SXahqgQ3uackJqJucgGev6YWPb+uPUZZAnV9Ygpl6HjLc7fiapIdvUVaU8+5Qi8dfhLsv7ojz2pa3+F/9dR/bBB4jTSMi2DFpJK6zlPeA5cP/zZZDAIBGLi19w/68AmTnFiAhTtC4bnLIqKL2TdJswy9tzz1WiL9YOjgNb93Yz3X/RnWT0L5JOm4a1BZAaCBpUDcJGXr6rJ6j0hvapQn+8fOeIa/50a3n49fnnYG8whJbCiScA8cKzZb7zD8O9tzPWqHd8MYS/HhIaynmnij2vAnKBU/Mww87j2Daqmz0fngmAGB0v9bm9q4PfomHPluLNfqM50v0Stmq1CVg9TmjAV5ZsM22rkOT0LTRe4t34qmZm/Dw1HVoP346ssZNMwPgPMfon873z8CASXNsqYkre7XEqt1HzRyx1ffbDmH3kZN46PN15rr/fP+jbR9nmmOznkaauW6/rfyLtx+yVZDWkVvTVmebs7atHfQAQlrZZ96jjU7LKyhGSWkZCopLPS8QaL18xe/fKT9bKC4tw5HjRa4VRV5BMbLGTcPJolKUlakKt/KtadyikjKzkTVr/X7bficK7WU+55FZOPvhmWg7fjpOFJVg4eaDvinMaAhscDdc0aslzm7TwLbOeuDC3VDbGowXjb8oovdbO+FSfHmndxCxalIvBWMu6oC4OMHXf70Q7958Li7p2sy2T2Z6aAvbcGbjuuZyb30UiDWNc+OAM2373/vJGrw0bytKyhTi4gT92zXG8vsvNl9reLdmuG9kl4jKbuh3pns/QkK8duxS9X4MaysZ0I67cezr1UnAM7/oZfu72rsEsz5nNDA7niN16HihOa+hqUv6p0FqIu6+uGPIJJn/6RPKek78CtNWheb8DVe++K0t1XDzoLb4v75aR218nNg6M89sXBdt9Hv8Gn/HHS6joqwtwjuHdTAreLdjYjBScR/oI8ASIpjhm19UglHPf4ML/zEv5IqiIv7Pf+hzeyf3xU9rk99ufmspXppX3o9z4xtLccxyZjP+k/Jc/4TP1+H8x+a4jj5KcLmm0ow12iitse+vQOf7Z6DTfaHDcAFgskv/DaANwez98Ey869KZbFQuXR6YgX6PzsbVL38X0lHsrBSsrfUdh8oryVfmbzXTjqmOvrzjRfYzY+tnz2h0hjuripbAB3c31iFn9VO9gztQnrdvWi8F3VrWs2373QVtMesuLZDfekE7AFr+3LhsQEW0apCK/u3KOzl/P6Qd4uMEyQneI3/GjygPxPeNPAtA+dhpQPuATB0zEBseHg4AaOJSUTSsm4Qdk0Zi7p+GQERwqaNyCSc1Kd4zFWWkSxPj41yH+B3ML8TX+rC46av34ae9y+8i1ahuaDl3TBoJEanwTVgO5Rdh37EC1EmMN2cDW/Vu0wDLdoaeqpeWlVV43HlSfBzaZqbh71f10F/DHgiSE+PN/4/1khQA8OvzznBtQPzhwvYY0jETJ4tLbSOivIz7eDUO5ReaI7JGdPf+f+ZbUhfdH/rK1hL3mjT09eaDZivcqPT6e/Q1WVlz5l+sCT3rcht9dPRkaMf899u01vS01aEVrnUS2KLth13nQOTq9zx41XFmBADnWhoqxkgjZ0ex8yzHmOPR+f4vbMOjn5y5yQz8/1y43VYpPPHlRrMyc36eje97MoN75VjHlYdruQPAjDsHY93ESwEAU8cMwo5JIzHn7gvw3OjeuOeyLmjfJB1bHrkMfx3eyfM1nJUCACz8y4Vh3/evwztj66Mjwu5z8VlNMfOPg3HzoDPR5wzt7MTasr28R3N0a1kfKXpQORDBaAGjDyISRsvksZ91x88swRmALe9vHZq66qFLcHmP5rhpYNuQ3L7xf2lQV/ufGH0e1s5fZ2dvu8y6+Gmv0L4R4+84dLwQczYcQN3keIgIVj54CdZMuBSd9Qr46f/rZY7ksHph7lZc8rT7ZRie/kVoyggA0lK0ykNEQlprgHbjduPz1sxxFnFJ16Zo6uhw796yPhLi41AnKR67j5w0A5ufQ8eLcCi/EAlxgnHDvc/E5m+yp26MfoO/fLQSN3nM2P3Va4vwwtwtmGdp0b74y7PN5WgO9XPrx/h+26GQdUbgnPTFBtv6gX+fiwGT5tjWbdynpch+PHTCNooq90RxRGeFv/zXItf1bjcHOmIZGfSSpeKZsmIvBj0+F0qpkDOPXL1CY8u9kp6w5HP9gntKYjxSk+wtvraZabbO1oT4uJDT2EH68MXZd1+Aj27tH/K6rRv6T7SKRIem6bhXb7UD2qn/538YiCX3DkO3luWjbqxD0LyCE1CxC3bt0tNbo/u1wYP6GH6DdZZuYnz5a9ZLScTz156NuDjBo1d2BwAsvW8YAODhK7rh2WtdaL40AAARlUlEQVR6ma2X50b3xvbHRphnRYD9/9WqQR3MvnuIbZTSuMs647Juzcz+hF2HT2L7wePmaJr6dRKRlpyAGXcOxo5JI1E/NdG8B22kruztPj7e2lKv43JGUzc5AWn62cPRE0UY2rmJua1Bamir/PMxAz1fK5xjJ4txIK8QjdOS0Tg99HW90oZGi9w6mseQZjnrWbPnGK63tGgzUpNwx9D2EEHIUL9fntvGXP7jsI6+Zf9F39aY+6chANwn7W1wGZ5s5OKNBo6VMafBYB351eWBGWbLuefEr1zPBgDgxXnll/wwRrU9fnUPc10kl+74cu3+kHVueXWjQkh0OduNtpgM7tYAkZ4SeqoeDW/d2A/bHh2BdplpnqmLqtK9Vf2wufp8n8sCTx0zEJ//YSC+vHMwJo/ujedG9w7Z576RXbDqwUvMx85K0jraxTnO3HDtuW2wY9JIs8XUumEqruhlPwNwVprWQO82CumnvVripV/1wRmNtP4It2vxODlbzJVlvZa+9X9uXKBNKWWmJL7Zcgj/tsyLMD6HxhndncM6mNu2uXR4uqW6DEt2HMHh40VolJaE1KQEiMDWl2LMgna67NmF+KdLumJIp0zb860dhA/+RGtY1E9Nch2lZe0X6tnafu+EjX8bbnscJ9pZYCM9/XRQ//+OvaiDOfS1bWZdeDHSjr86r43nPk6d7pthG3Xm5vEZG3H4eBH+tbD82Fx6VjN0baGd8b3lGIQwwdHQARAyIgpwT0UZ11YK9/+NlpgM7lbhguCpEBHXVvDS+4bh67+GT8lUtQSfD063lvXRvVV9dGqWjlE9W9jOUq7s3RLT7hiImwa1Dam0jC/y1DED8fZN5SNxjOuqDHKZjFVRdZLisey+YejQJA2rH9IqF+u8AGe6w/DnS73TZta00bXnhg8MRkfl/35/fsiktXMsOVtrK944g+rRKsMMQH+4sL3tuUanaeuGqdgxaSTutLRyrR1uj1/VA3dc1AG3DmkHL3+fsQFzNhwwW/zbHxuJmwa1xbZHR2DDw8ORmpRgO2uwemT6+pB1xwtLbJeHtjJa9F5nwNYJeBmpSXj/lvPMx8kJ8bbrOm1+ZATi4gSperk/1idsnZPVEG/d2A9nNEoNew2kg/mFOL9tIxzMC83Vf3Sr9/WjfhbBDXnGvv+DOe/g+v5ZqJ+aiGvO0c74Jjvu5tY8zLwNr9F5q/TP8ivztQokuZLzESoiZoP7svuG4dPbB4TtsKwKjdOS0apBdFIyFfHCteV50Ssd+fFIbHt0BJ69pheeuLoHurYIvXsVoF2wbfbdF6Bby/q203iDNTd7KhqlJWPmXReY/7tWDbSAuGPSSM/ndGwavpP7531aYXS/1maqyIvRcuxzRkNcaAmQn9zW33aMrWPr/3RJJ7x787no2ToDC/5yIabfMQh/0isbY6KR2/EyWDvCWzaog7su7oj9liA37Y6B+PV5Z+C7e4banrfUMQ47Lk7MCnnsRR0QqSU7juCqPu6pKKPcGZbgbg1g1j6cxHixpQoBoHfrBvjzpZ2w/P6LzdFpzsaHkdbLSE0K6XMxFBSXIievEJnpyZh0lfY/tA49dUvZhDNmaHtbB+vCzQfN5e7631Anyf1/1siSu7ee8dRJjMdDo7rid4Pb2vYf0b2ZWaEZnDPVq0LV5CxqgUZpybZ/Qqwb2aM5bn9XW65MT3xcnISkTJya1w/fGes1ias6+HUlWPthNj9yGbKPFmDwE9pp87fjhqK0TOGDJbs8g1zvNu7BY+qYgUiMjzNHQqUkxuOsFuUduBNGdcUNA7LCDj28Z0QX5OQXYtXuXJyvz4kY3DETH+gTXdplpuHhn3YL/wc6uN1e0svEK7p6pnLqGi13yygta3+StdLq2qK+2flpDAmNixPc7jiLcTpbD8wNwoxsO3pCu7RG47RkZKQmmRX9LW8txcH8QogIzj2zoXlBPT/rs4+Z1yNyMjr83TrNAXuqd0T35maL35iN+5OeLcx5AC//qg8u6JgZUqG5jRiLtpgN7qejy7o1wxdr9kU0hjnWuI1m8JIYH4c2jVIx664LkJacYKZ6/hQmtePF2VJ1iqSRkZmejP84Lh43skdzXNRlOHJPFnv26YQ7UzI+Ay3qp+D1G/qFvUFLl+b10DQ9BaN6tkC7zDTbxd+M9JM1iO/LPYnnr+2NklIFEcEdQ9tjaJem5vt+cMt5aJsZ/lo+VkbnonWs/C2D22LJjsO4vn8Wxr6/Au8t3on8whKUOK4v/epv+prL947sglHPf4Om9ZKx/1j4TtD2TdJxQcdM3D8l9IJ1xsxqazrvwZ+chQn6hC9r53ijtCTcMCALr3+zw1yXYBlgMLRzE9eRMVWVLrZicI8hk0f3DrmWR3WYffcFrhcTq2qLx1+Efo9q1xC/pGvo7FA/4SYNGT65rb/rBanGj+hszkytKimJ3vMMAKCFz7DWKbcPQMsGddA4LRm9WmdghaXTb3S/1qhXJxHzN+agW4v6iIsTTB7dGyeKyi+4l56SgO76GYC1tZqekojLe5T309x1ib1SPLet/7j4sRd1CLmQ3HJL3t+Y4/G1ni4x9g03s9NIEV3XPwu9WmXgWo9hjQDws7Nboln9FMzZcCDkWv8N9eBtTaVkNaqLqWMG2i4CeHmP5khOiMdNg9ragnunpun43QVtcWajup5DHpmWoQpJjI+rliFWTu0y09CuYtdgi4omllEwVfV3e6Vjbhns3eFZXfyGUPa0jGj69PYBKCguNSflPPYzbajfPZfZx8kbr9mrdQY+vb38GkjWlNsNA7JOqdwA8MeLO+Kl+Vtt8ydeuPZs3P7uctsVPJ0dufdffha8NEpLxtoJlyI1SZvzMPGKrujfrhGGPaWdtfzj5z3xp/9qt7BsVDcJ9VIS8foN/cxryRgauLTcB3ZobPuMbX7kMrPz3agMjHSoiIQcV0DLvTtnclclBneiAPnsDwMw6nnt4m4ZPrOvnVIS47H9sRFh03Yigs//MBBtHDNsrWmZaPWtbPrbZbbHI3s0x8ge9k5z59+Y1Sj8YIW6lnL+5vwsAMCKBy7GjkMn0Kt1BhLjBWPfX2FLlb12XV/89k1tUlfdpHjzLMV6eRJn48H6uE5SPO64qIPrtYWsXvxlH1zy9Hx0b+l90bxoYnCnQHvjhnN8b64SS3q0Kg8MlRm/H0l/THeXztj4OMHvh7TDsC7uQyyrSj1Hy70y/UkZqUnopbeur+jVMmTggNFB3KZhKha4zCzvHMHlRu662H8CF6BNMKuuPjEGdwq0IZ2aYEin6g04p6u/Dg+9R0BVq1dFkxDt76FVIOdk2S+S1y4zDV2a1zMnckVDdQ52YHAnolpLRDDn7gsw9En3u6NFQ7P6Kfjktv4h1yBKSYzHF2MHeTyr9vMN7iLSGsBbAJoBKAPwqlLqWZf9hgB4BkAigINKqQuiW1QiAqBd4bOmC1GNwk0AixavjvMgi+SolQC4Wym1XETSASwTkZlKKfMq/yKSAeBFAMOVUjtFhOfJRFXEej2X04HRget3EUCy8w3uSqlsANn6cp6IrAfQEsA6y27XAvhYKbVT3y/0VulERJVQJyke947o4nkPY3JXofMdEckC0BuAc3ZARwCJIjIPQDqAZ5VSb0WhfEREuNlxvRbyF3FwF5E0AP8DcKdSyjk1LwFAHwAXAagD4DsR+V4ptcnxGrcAuAUA2rSJ/LKdRERUMRFN6xORRGiB/R2l1Mcuu+wGMEMpdVwpdRDAAgAhd4xQSr2qlOqrlOqbmVkDUxqJiE4TvsFdtIGZrwFYr5R6ymO3KQAGiUiCiKQCOBdA6IWjiYioWkSSlhkA4NcAVouIcYfY8QDaAIBS6mWl1HoRmQFgFbThkv9SSq2pigITEZG/SEbLfA34D6tVSj0B4IloFIqIiE5NzN6JiYjodMbgTkQUgxjciYhikBj3PKz2NxbJAfBjJZ/eGMBB371qRm0tW20tF1B7y1ZbywXU3rKxXBVX0bKdoZTyHUteY8H9VIjIUqVUX/89q19tLVttLRdQe8tWW8sF1N6ysVwVV1VlY1qGiCgGMbgTEcWgoAb3V2u6AGHU1rLV1nIBtbdstbVcQO0tG8tVcVVStkDm3ImIKLygttyJiCiMwAV3ERkuIhtFZIuIjKuG92stInNFZL2IrBWRsfr6hiIyU0Q2678b6OtFRCbr5VslImdbXus6ff/NInJdlMoXLyI/iMhU/fGZIrJIf48PRCRJX5+sP96ib8+yvMY9+vqNInJplMqVISIficgG/didXxuOmYj8Uf8/rhGR90QkpaaOmYj8W0QOiMgay7qoHSMR6SMiq/XnTNYvAljZcj2h/y9Xicgnot19Leyx8Pqueh3vypbNsu1PIqJEpHFtOGb6+jH6MVgrIo9X6zFTSgXmB0A8gK0A2gJIArASwFlV/J7NAZytL6cD2ATgLACPAxinrx8H4O/68ggAX0C7Hs95ABbp6xsC2Kb/bqAvN4hC+e4C8C6AqfrjDwFcoy+/DOD3+vJtAF7Wl68B8IG+fJZ+HJMBnKkf3/golOtNADfpy0kAMmr6mEG7g9h2AHUsx+r6mjpmAAYDOBvAGsu6qB0jAIsBnK8/5wsAl51CuS4BkKAv/91SLtdjgTDfVa/jXdmy6etbA/gS2tyZxrXkmF0IYBaAZP1xk+o8ZlUWFKviRz/oX1oe3wPgnmouwxQAFwPYCKC5vq45gI368isARlv236hvHw3gFct6236VLEsrALMBDAUwVf9AHrR8Cc3jpX/wz9eXE/T9xHkMrfudQrnqQQui4lhfo8cMWnDfpX+pE/RjdmlNHjMAWY6AEJVjpG/bYFlv26+i5XJsuxLavR1CvoPGsYDHdzXcZ/RUygbgI2j3kNiB8uBeo8cMWkAe5rJftRyzoKVljC+nYbe+rlqI/TaDTZV2f1nov42bgnuVsSrK/gyAv0C7zDIANAJwVClV4vIe5vvr23P1/auiXG0B5AB4XbSU0b9EpC5q+JgppfYA+AeAndDuC5wLYBlqxzEzROsYtdSXq6KMN0Jr1VamXOE+o5UiIqMA7FFKrXRsqulj1hHafS4Wich8ETmnkuWq1DELWnB3y39Vy3AfCX+bQduuLutUmPWVLc/lAA4opZZF8N7VVi5dArRT1JeUUr0BHIeWYvBSXcesAYAroJ0KtwBQF8BlYd6jOo+Zn4qWpUrKKCL3AigB8E5tKJdoNwe6F8ADbptrsmzQvgcNoKWE/gzgQz2HXy3lClpw3w0tt2ZoBWBvVb+puN9mcL+INNe3NwdwwKeM0S77AACjRGQHgPehpWaeAZAhIsZ1+q3vYb6/vr0+gMNVUC7jvXYrpYwbqX8ELdjX9DEbBmC7UipHKVUM4GMA/VE7jpkhWsdot74ctTLqHY+XA/il0vMDlSjXQXgf78poB62yXql/F1oBWC4izSpRtmgfs90APlaaxdDOsBtXolyVO2aVyRPW1A+0mnAbtH+m0eHQtYrfUwC8BeAZx/onYO/4elxfHgl7J85ifX1DaHnoBvrPdgANo1TGISjvUP0v7B0vt+nLt8PeOfihvtwV9s6dbYhOh+pCAJ305Yf041Wjxwza7R/XAkjV3+tNAGNq8pghNE8btWMEYIm+r9E5OOIUyjUcwDoAmY79XI8FwnxXvY53Zcvm2LYD5Tn3mj5mtwKYqC93hJZykeo6ZlUWFKvqB1oP+CZovcr3VsP7DYR2CrQKwAr9ZwS0PNhsAJv138aHQwC8oJdvNYC+lte6EcAW/eeGKJZxCMqDe1toPf5b9A+E0VOfoj/eom9va3n+vXp5NyLC0QERlKkXgKX6cftU/xLV+DEDMAHABgBrAPxH/4LVyDED8B603H8xtFbbb6N5jAD01f/OrQCeh6ODu4Ll2gItOBnfgZf9jgU8vqtex7uyZXNs34Hy4F7TxywJwNv66y0HMLQ6jxlnqBIRxaCg5dyJiCgCDO5ERDGIwZ2IKAYxuBMRxSAGdyKiGMTgTkQUgxjciYhiEIM7EVEM+n/jcTScMREoPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, context_length, temp=1):\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = '\\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = word\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], max_len=500, GPU=False, context_length=20, beam_width=5, verbose=True, temp=1):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    temperature : float\n",
    "        Scales the logits before softmax. A higher temp (>1) increases variety whereas a low temp (<=1) will often result in a loop\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in range(max_len):\n",
    "        print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "            top_probabilities = np.argwhere(multinom_draw != 0).flatten()\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "        \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "#         np.random.shuffle(context_and_scores)\n",
    "\n",
    "        context_and_scores = context_and_scores[:15] #for now, only keep the top 15 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "    \n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word: 1 / 80\n",
      "Generating word: 2 / 80\n",
      "Generating word: 3 / 80\n",
      "Generating word: 4 / 80\n",
      "Generating word: 5 / 80\n",
      "Generating word: 6 / 80\n",
      "Generating word: 7 / 80\n",
      "Generating word: 8 / 80\n",
      "Generating word: 9 / 80\n",
      "Generating word: 10 / 80\n",
      "Generating word: 11 / 80\n",
      "Generating word: 12 / 80\n",
      "Generating word: 13 / 80\n",
      "Generating word: 14 / 80\n",
      "Generating word: 15 / 80\n",
      "Generating word: 16 / 80\n",
      "Generating word: 17 / 80\n",
      "Generating word: 18 / 80\n",
      "Generating word: 19 / 80\n",
      "Generating word: 20 / 80\n",
      "Generating word: 21 / 80\n",
      "Generating word: 22 / 80\n",
      "Generating word: 23 / 80\n",
      "Generating word: 24 / 80\n",
      "Generating word: 25 / 80\n",
      "Generating word: 26 / 80\n",
      "Generating word: 27 / 80\n",
      "Generating word: 28 / 80\n",
      "Generating word: 29 / 80\n",
      "Generating word: 30 / 80\n",
      "Generating word: 31 / 80\n",
      "Generating word: 32 / 80\n",
      "Generating word: 33 / 80\n",
      "Generating word: 34 / 80\n",
      "Generating word: 35 / 80\n",
      "Generating word: 36 / 80\n",
      "Generating word: 37 / 80\n",
      "Generating word: 38 / 80\n",
      "Generating word: 39 / 80\n",
      "Generating word: 40 / 80\n",
      "Generating word: 41 / 80\n",
      "Generating word: 42 / 80\n",
      "Generating word: 43 / 80\n",
      "Generating word: 44 / 80\n",
      "Generating word: 45 / 80\n",
      "Generating word: 46 / 80\n",
      "Generating word: 47 / 80\n",
      "Generating word: 48 / 80\n",
      "Generating word: 49 / 80\n",
      "Generating word: 50 / 80\n",
      "Generating word: 51 / 80\n",
      "Generating word: 52 / 80\n",
      "Generating word: 53 / 80\n",
      "Generating word: 54 / 80\n",
      "Generating word: 55 / 80\n",
      "Generating word: 56 / 80\n",
      "Generating word: 57 / 80\n",
      "Generating word: 58 / 80\n",
      "Generating word: 59 / 80\n",
      "Generating word: 60 / 80\n",
      "Generating word: 61 / 80\n",
      "Generating word: 62 / 80\n",
      "Generating word: 63 / 80\n",
      "Generating word: 64 / 80\n",
      "Generating word: 65 / 80\n",
      "Generating word: 66 / 80\n",
      "Generating word: 67 / 80\n",
      "Generating word: 68 / 80\n",
      "Generating word: 69 / 80\n",
      "Generating word: 70 / 80\n",
      "Generating word: 71 / 80\n",
      "Generating word: 72 / 80\n",
      "Generating word: 73 / 80\n",
      "Generating word: 74 / 80\n",
      "Generating word: 75 / 80\n",
      "Generating word: 76 / 80\n",
      "Generating word: 77 / 80\n",
      "Generating word: 78 / 80\n",
      "Generating word: 79 / 80\n",
      "Generating word: 80 / 80\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU, seed_text='xbos xbol-1', max_len=80, context_length=200, beam_width=3, verbose=False, temp=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me , won 't you come again ? \n",
      " xbol-9 won 't you come 162.0649492646885\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you love me too 163.1574106549538\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you tell me ? \n",
      " xbol-9 won 't you , won 't you tell me ? 163.78643405280954\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you stay \n",
      " xbol-10 164.69619024910764\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you love me any 165.50909424097892\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you be my baby 166.24423033963384\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me now ? \n",
      " xbol-9 won 't you come home and run ? \n",
      " 166.39008749899867\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me now ? \n",
      " xbol-9 won 't you come home for more ? \n",
      " 166.86390856304274\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me , won 't you come along ? \n",
      " xbol-9 hello , won 't 166.99393556100526\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you tell me ? \n",
      " xbol-9 won 't you , won 't you tell me what 167.15988073248593\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me now ? \n",
      " xbol-9 won 't you show me that our love is 167.63503517464915\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you tell me ? \n",
      " xbol-9 won 't you , won 't you say you can 168.2045994622638\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you stay warm ? 168.95684380668425\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you tell me ? \n",
      " xbol-9 won 't you , won 't you say you got 169.86026056289143\n",
      "\n",
      "\n",
      "xbos xbol-1 hello , baby , when your love is gone \n",
      " xbol-2 we can see that we 're all alone \n",
      " xbol-3 hello , baby , won 't you just let me be alone \n",
      " xbol-4 'cause i still love you \n",
      " xbol-5 \n",
      " xbol-6 won 't you stay ? \n",
      " xbol-7 won 't you love me until the end ? \n",
      " xbol-8 won 't you love me ? won 't you ? \n",
      " xbol-9 won 't you stay warm on 169.90565210180722\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "for song, score in final_scores:\n",
    "    print_words(song)\n",
    "    print(score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
