{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions\n",
    "Define this notebooks \"initializer model\" (pretrained parameters and itos mapping) and the output model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '4.0-LM-108k-lines'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "init_model_name = 'wt103'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "To create the model's tokens with the correct train-test split, run the code below. Only needed once on the notebook's first ever run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FIRST_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics, line_num=True):\n",
    "    '''\n",
    "    Tokenizes lyrics\n",
    "    '''\n",
    "    tk = nltk.tokenize.LineTokenizer(blanklines='keep')\n",
    "    tokd = tk.tokenize(lyrics)\n",
    "    \n",
    "    re_tk = nltk.tokenize.RegexpTokenizer(r'\\[[^\\]]+\\]|\\w+|[\\d\\.,]+|\\S+',\n",
    "                                          discard_empty=False)\n",
    "    re_tokd = re_tk.tokenize_sents(tokd)\n",
    "    \n",
    "    if line_num:\n",
    "        [s.insert(0, f'xBOL {line_num+1}') for line_num, s in enumerate(re_tokd)] # insert start token for each line\n",
    "    else:\n",
    "        [s.insert(0, f'xBOL') for s in re_tokd] # insert start token for each line\n",
    "\n",
    "    [s.append('xEOL') for s in re_tokd] # append end token for each line\n",
    "    \n",
    "    flat = list(itertools.chain(*re_tokd))\n",
    "    flat.insert(0, 'xBOS')\n",
    "    flat.append('xEOS')\n",
    "    # lower case and de-space\n",
    "    flat = [w.lower().replace(' ', '-') for w in flat]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tokens(model_path, small_corpus=False):\n",
    "    '''\n",
    "    500k link: https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv\n",
    "    108k link: https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv\n",
    "    '''\n",
    "    model_path = Path(model_path)\n",
    "    model_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    small_corpus_url = 'https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv'\n",
    "    large_corpus_url = 'https://storage.googleapis.com/capstone-deep-lyrics/lyrics-500k.csv'\n",
    "\n",
    "    # load scraped data\n",
    "    if small_corpus:\n",
    "        df = pd.read_csv(small_corpus_url,\n",
    "                     header=None, escapechar='\\\\',\n",
    "                     names=['msd_id', 'lyrics'])\n",
    "    \n",
    "    if not small_corpus:\n",
    "        df = pd.read_csv(large_corpus_url, index_col=[0])\n",
    "    \n",
    "    # only keep lyrics with length < 5000\n",
    "    df = df[df.lyrics.str.len() < 5000]\n",
    "    print('Tokenizing...')\n",
    "    df['tokd'] = df.lyrics.apply(tokenize_lyrics)\n",
    "    df['tokd_len'] = df.tokd.apply(len)\n",
    "\n",
    "    # split train/test\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=2018)\n",
    "    \n",
    "    # tokens\n",
    "    print('Saving...')\n",
    "    tokens = np.array(df_train.tokd)\n",
    "    np.save(model_path/'train_tok.npy', tokens)\n",
    "    \n",
    "    tokens = np.array(df_test.tokd)\n",
    "    np.save(model_path/'valid_tok.npy', tokens)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Saving...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    process_tokens(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                          bs=128,\n",
    "                                          max_vocab=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@classmethod\n",
    "def load(cls, path:PathOrStr, cache_name:PathOrStr='tmp', **kwargs):\n",
    "    \"Load a `TextDataBunch` from `path/cache_name`. `kwargs` are passed to the dataloader creation.\"\n",
    "    cache_path = Path(path)/cache_name\n",
    "    vocab = Vocab(pickle.load(open(cache_path/'itos.pkl','rb')))\n",
    "    train_ids,train_lbls = np.load(cache_path/f'train_ids.npy'), np.load(cache_path/f'train_lbl.npy')\n",
    "    valid_ids,valid_lbls = np.load(cache_path/f'valid_ids.npy'), np.load(cache_path/f'valid_lbl.npy')\n",
    "    test_ids = np.load(cache_path/f'test_ids.npy') if os.path.isfile(cache_path/f'test_ids.npy') else None\n",
    "    classes = loadtxt_str(cache_path/'classes.txt') if os.path.isfile(cache_path/'classes.txt') else None\n",
    "    return cls.from_ids(path, vocab, train_ids, valid_ids, test_ids, train_lbls, valid_lbls, classes, processor, **kwargs)\n",
    "\n",
    "setattr(TextDataBunch, 'load', load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    data_lm = TextLMDataBunch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "DOWNLOAD_INIT_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "# itos_url = 'https://storage.googleapis.com/capstone-deep-lyrics/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "# if DOWNLOAD_INIT_MODEL:\n",
    "#     Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/models/4.0-LM-108k-lines/pretrained')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untar_data('https://s3.amazonaws.com/fast-ai-modelzoo/wt103', dest=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FIRST_RUN:\n",
    "    learn.load_pretrained(MODEL_PATH/f'{init_model_name}/lstm_{init_model_name}.pth', \n",
    "                          MODEL_PATH/f'{init_model_name}/itos_{init_model_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_FIRST_RUN:\n",
    "    if not GPU:\n",
    "        learn.cpu_load(f'{model_name}_best')\n",
    "    else:\n",
    "        learn.load(f'{model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1230' class='' max='15352', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      8.01% [1230/15352 05:18<1:00:57 3.4926]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(10, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save_encoder(f'{model_name}_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, context_length, temp=1):\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = '\\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = word\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], max_len=500, GPU=False, context_length=20, beam_width=5, verbose=True, temp=1):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    temperature : float\n",
    "        Scales the logits before softmax. A higher temp (>1) increases variety whereas a low temp (<=1) will often result in a loop\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in range(max_len):\n",
    "        if verbose: print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "            top_probabilities = np.argwhere(multinom_draw != 0).flatten()\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "        \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "#         np.random.shuffle(context_and_scores)\n",
    "\n",
    "        context_and_scores = context_and_scores[:15] #for now, only keep the top 15 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "    \n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU, seed_text='xbos xbol-1', max_len=150, context_length=40, beam_width=3, verbose=False, temp=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else can you do ? \n",
      " xbol-19 tell me what do i do ? 235.67201448175786\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus : \n",
      " xbol-21 tell 236.1306052270622\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus : \n",
      " xbol-21 well 238.00573731657178\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else can you do ? \n",
      " xbol-19 tell me what do i see ? 238.40725094745343\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do to you ? \n",
      " xbol-18 [x2] \n",
      " xbol-19 tell me what do i have to do ? \n",
      " xbol-20 tell 238.94856781865926\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus : (4x) \n",
      " xbol-21 240.0321424632756\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus : \n",
      " xbol-21 up 240.20089340520823\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what i didn 't want you to do \n",
      " xbol-19 tell me what does it 240.51770517195263\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else can you do ? \n",
      " xbol-19 tell me what do he do ? 240.76705112365846\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else can you do ? \n",
      " xbol-19 tell me what do i do about 240.95873664301575\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus : (4x) \n",
      " xeos\n",
      "241.12400895792973\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else can you do ? \n",
      " xbol-19 tell me what i need to do 241.53678665098343\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what else do i do ? \n",
      " xbol-19 \n",
      " xbol-20 chorus \n",
      " xbol-21 look in 241.6718175824983\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do to you ? \n",
      " xbol-18 [x2] \n",
      " xbol-19 tell me what do i have to do to you \n",
      " xbol-20 241.89219633765143\n",
      "\n",
      "\n",
      "xbos xbol-1 ah , follows you \n",
      " xbol-2 yeah , makes me wonder \n",
      " xbol-3 \n",
      " xbol-4 what did i tell you \n",
      " xbol-5 tell me what could i tell \n",
      " xbol-6 ooh , tell me what \n",
      " xbol-7 oh , tell me what did i do \n",
      " xbol-8 (and what did you tell me ) \n",
      " xbol-9 tell me what \n",
      " xbol-10 tell me what ? \n",
      " xbol-11 tell me what did i tell you \n",
      " xbol-12 tell me what did i tell ya ? \n",
      " xbol-13 tell me what did i tell you , baby ? \n",
      " xbol-14 tell me what did i do ? \n",
      " xbol-15 tell me what in the world \n",
      " xbol-16 tell me what do i do ? \n",
      " xbol-17 tell me what did i do ? \n",
      " xbol-18 tell me what i didn 't want you to do \n",
      " xbol-19 tell me what does that 242.05454648308293\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "for song, score in final_scores:\n",
    "    print_words(song)\n",
    "    print(score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
