{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to analyze how multimodal learning has affected our weights. This is different than evaluation on the final generated lyrics. Instead, here we focus of if the features we implemented have \"moved the needle\" in terms of the distribution of the next word.\n",
    "\n",
    "This notebook is meant to be run after the model fitting notebooks. Thus, we will ignore any data collection processes, making the assumption that these have already been executed in the modeling notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.data_collection.multimodal_data import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Generate Text For Pure LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a `get_probs` option for text generation. For this method, generate a shorter sequence of text with a very wide beam. Then, will perform a bag of words analysis across different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, context_length, temp=1):\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "        \n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def get_word_from_index(idx):\n",
    "\n",
    "    return data_lm.valid_ds.vocab.textify([idx])\n",
    "\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = 'xeol \\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = word\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'],\n",
    "                  max_len=500, GPU=False, context_length=20,\n",
    "                  beam_width=5, temp=1, multinomial=True,\n",
    "                  verbose=True, graph=False, get_probs=False):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    if graph:\n",
    "        optimization_graph = Digraph()\n",
    "\n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in tqdm(range(max_len)):\n",
    "#         print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        next_word_probs = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            if multinomial:\n",
    "                multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "                top_probabilities = np.argwhere(multinom_draw != 0).flatten()                    \n",
    "                \n",
    "            # top-k from probabilities    \n",
    "            else:\n",
    "                top_probabilities = np.argsort(-probabilities)[:beam_width]\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "                if get_probs:\n",
    "                    next_word_prob = probabilities[next_word_idx]\n",
    "                    potential_next_word = get_word_from_index(next_word_idx)\n",
    "                    prior_context = [get_word_from_index(w) for w in context]\n",
    "                    next_word_probs.append((prior_context, potential_next_word, next_word_prob))\n",
    "                \n",
    "                if graph:\n",
    "                    optimization_graph.node(\"%d_%d\" % (word_number, next_word_idx), \"%s (%.2f)\" % (get_word_from_index(next_word_idx), candidate[1]))\n",
    "                    optimization_graph.edge(\"%d_%d\" % (word_number - 1, context[len(context) -1]), \"%d_%d\" % (word_number, next_word_idx))\n",
    "                \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "\n",
    "        context_and_scores = context_and_scores[:30] #for now, only keep the top 30 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "\n",
    "    if graph:\n",
    "        now = str(datetime.datetime.now())\n",
    "        optimization_graph.render(directory='graph_viz/', filename=now, cleanup=True)\n",
    "        \n",
    "    if get_probs:\n",
    "        next_word_probs = sorted(next_word_probs, key=lambda x: -x[2])\n",
    "        return next_word_probs\n",
    "        \n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import stopwords and add my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/syang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words.add(\"'t\")\n",
    "stop_words.add(\"'ll\")\n",
    "stop_words.add(\"’t\")\n",
    "stop_words.add(\"'ve\")\n",
    "stop_words.add(\",\")\n",
    "stop_words.add(\"'s\")\n",
    "stop_words.add(\"'re\")\n",
    "stop_words.add(\"'m\")\n",
    "stop_words.add(\"don\")\n",
    "stop_words.add(\"won\")\n",
    "stop_words.add(\"xbol\")\n",
    "stop_words.add(\"xbos\")\n",
    "stop_words.add(\"xeol\")\n",
    "stop_words.add(\"xeos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Language Model (3.2-ULMFiT-108k)\n",
    "* Transfer learning from wikitext-103 to 108k corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(f'../data/models/3.2-ULMFiT-108k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'xxpad', 'xbol', 'xeol', ',', 'i', 'the', 'you', 'to', 'and']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  pretrained_fnames=['3.2-ULMFiT-108k_best',\n",
    "                                                     '3.2-ULMFiT-108k_itos'],\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "next_word_probs = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol [verse-1] xeol xbol',\n",
    "                             max_len=2, context_length=200,\n",
    "                             beam_width=1000, verbose=False,\n",
    "                             temp=1, multinomial=False, graph=False, get_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_probs = [s for s in next_word_probs if s[1] not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>next_word</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, one]</td>\n",
       "      <td>day</td>\n",
       "      <td>0.290520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, no]</td>\n",
       "      <td>one</td>\n",
       "      <td>0.241687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, they]</td>\n",
       "      <td>say</td>\n",
       "      <td>0.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, here]</td>\n",
       "      <td>comes</td>\n",
       "      <td>0.165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, how]</td>\n",
       "      <td>many</td>\n",
       "      <td>0.128627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, my]</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.094780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, so]</td>\n",
       "      <td>many</td>\n",
       "      <td>0.085646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, how]</td>\n",
       "      <td>long</td>\n",
       "      <td>0.074577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, no]</td>\n",
       "      <td>matter</td>\n",
       "      <td>0.071768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[xbos, xbol, [verse-1], xeol, xbol, one]</td>\n",
       "      <td>night</td>\n",
       "      <td>0.071546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     context next_word  probability\n",
       "0   [xbos, xbol, [verse-1], xeol, xbol, one]       day     0.290520\n",
       "1    [xbos, xbol, [verse-1], xeol, xbol, no]       one     0.241687\n",
       "2  [xbos, xbol, [verse-1], xeol, xbol, they]       say     0.168200\n",
       "3  [xbos, xbol, [verse-1], xeol, xbol, here]     comes     0.165289\n",
       "4   [xbos, xbol, [verse-1], xeol, xbol, how]      many     0.128627\n",
       "5    [xbos, xbol, [verse-1], xeol, xbol, my]     heart     0.094780\n",
       "6    [xbos, xbol, [verse-1], xeol, xbol, so]      many     0.085646\n",
       "7   [xbos, xbol, [verse-1], xeol, xbol, how]      long     0.074577\n",
       "8    [xbos, xbol, [verse-1], xeol, xbol, no]    matter     0.071768\n",
       "9   [xbos, xbol, [verse-1], xeol, xbol, one]     night     0.071546"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(next_word_probs, columns=['context', 'next_word', 'probability'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>3.362332e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2.910156e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many</th>\n",
       "      <td>2.176971e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>2.010951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>2.009788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>1.932980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.732307e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1.673621e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart</th>\n",
       "      <td>1.511759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>1.465183e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>1.396111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>1.272330e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>1.248038e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>1.194325e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>1.101350e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.064807e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>1.041544e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>1.036580e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>7.674185e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matter</th>\n",
       "      <td>7.251915e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>came</th>\n",
       "      <td>7.071555e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>6.657870e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>6.636602e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>6.574491e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>6.539243e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took</th>\n",
       "      <td>6.441442e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>6.430798e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>6.378402e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>5.686991e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>5.429876e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>9.627701e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jazz</th>\n",
       "      <td>9.582232e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cream</th>\n",
       "      <td>9.480978e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'en</th>\n",
       "      <td>9.358466e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'l</th>\n",
       "      <td>9.308627e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ka</th>\n",
       "      <td>9.283582e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>1.964950e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leading</th>\n",
       "      <td>1.225776e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>1.173724e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>9.144422e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starting</th>\n",
       "      <td>8.829972e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8.732445e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becoming</th>\n",
       "      <td>8.534373e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>7.497474e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carrying</th>\n",
       "      <td>7.160597e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design</th>\n",
       "      <td>6.900913e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>towards</th>\n",
       "      <td>6.564782e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourteen</th>\n",
       "      <td>6.175258e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly</th>\n",
       "      <td>6.154774e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[verse]</th>\n",
       "      <td>5.842068e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eleven</th>\n",
       "      <td>5.779879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>5.758642e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backwards</th>\n",
       "      <td>5.567018e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refrain</th>\n",
       "      <td>5.471007e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.429788e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blowing</th>\n",
       "      <td>5.409609e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otherwise</th>\n",
       "      <td>5.299578e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5.256109e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>5.213993e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strip</th>\n",
       "      <td>5.193349e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4016 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            probability\n",
       "next_word              \n",
       "day        3.362332e-01\n",
       "one        2.910156e-01\n",
       "many       2.176971e-01\n",
       "say        2.010951e-01\n",
       "said       2.009788e-01\n",
       "comes      1.932980e-01\n",
       "love       1.732307e-01\n",
       "time       1.673621e-01\n",
       "heart      1.511759e-01\n",
       "got        1.465183e-01\n",
       "could      1.396111e-01\n",
       "long       1.272330e-01\n",
       "night      1.248038e-01\n",
       "know       1.194325e-01\n",
       "little     1.101350e-01\n",
       "man        1.064807e-01\n",
       "eyes       1.041544e-01\n",
       "baby       1.036580e-01\n",
       "come       7.674185e-02\n",
       "matter     7.251915e-02\n",
       "came       7.071555e-02\n",
       "girl       6.657870e-02\n",
       "used       6.636602e-02\n",
       "never      6.574491e-02\n",
       "life       6.539243e-02\n",
       "took       6.441442e-02\n",
       "!          6.430798e-02\n",
       "face       6.378402e-02\n",
       "world      5.686991e-02\n",
       "way        5.429876e-02\n",
       "...                 ...\n",
       "co         9.627701e-07\n",
       "jazz       9.582232e-07\n",
       "cream      9.480978e-07\n",
       "'en        9.358466e-07\n",
       "'l         9.308627e-07\n",
       "ka         9.283582e-07\n",
       "+          1.964950e-07\n",
       "leading    1.225776e-07\n",
       "following  1.173724e-07\n",
       "(          9.144422e-08\n",
       "starting   8.829972e-08\n",
       "30         8.732445e-08\n",
       "becoming   8.534373e-08\n",
       "using      7.497474e-08\n",
       "carrying   7.160597e-08\n",
       "design     6.900913e-08\n",
       "towards    6.564782e-08\n",
       "fourteen   6.175258e-08\n",
       "mostly     6.154774e-08\n",
       "[verse]    5.842068e-08\n",
       "eleven     5.779879e-08\n",
       "support    5.758642e-08\n",
       "backwards  5.567018e-08\n",
       "refrain    5.471007e-08\n",
       "100        5.429788e-08\n",
       "blowing    5.409609e-08\n",
       "otherwise  5.299578e-08\n",
       "2000       5.256109e-08\n",
       "version    5.213993e-08\n",
       "strip      5.193349e-08\n",
       "\n",
       "[4016 rows x 1 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('next_word').sum().sort_values(by='probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df['probability']).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol [verse-1] xeol xbol',\n",
    "                             max_len=50, context_length=200,\n",
    "                             beam_width=3, verbose=False,\n",
    "                             temp=1.4, multinomial=True, graph=False, get_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol [verse-1] xeol \n",
      " xbol inside my head there 's something unsaid xeol \n",
      " xbol i 'm down on my knees to keep someone next to me xeol \n",
      " xbol and i don 't know when or why xeol \n",
      " xbol i don 't care what it 's all about xeol \n",
      " xbol xeol \n",
      " xbol [pre-chorus] xeol \n",
      " xbol i 115.52940888716925\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "song, score = final_scores[0]\n",
    "print_words(song)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Language Model (3.3-ULMFiT-108k)\n",
    "* Transfer learning from model 3.2 to 500k corpus\n",
    "* Transfer learning from 500k corpus to 108k corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(f'../data/models/3.3-ULMFiT-108k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'xxpad', 'xeol', ',', 'i', 'the', 'you', 'to', 'and', 'a']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  pretrained_fnames=['3.3-ULMFiT-108k_best',\n",
    "                                                     '3.3-ULMFiT-108k_itos'],\n",
    "                                  drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "next_word_probs = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             max_len=2, context_length=200,\n",
    "                             beam_width=1000, verbose=False,\n",
    "                             temp=1, multinomial=False, graph=False, get_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_probs = [s for s in next_word_probs if s[1] not in stop_words]\n",
    "next_word_probs = [s for s in next_word_probs if 'xbol' not in s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>next_word</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, one]</td>\n",
       "      <td>day</td>\n",
       "      <td>0.251755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, no]</td>\n",
       "      <td>one</td>\n",
       "      <td>0.201328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, they]</td>\n",
       "      <td>say</td>\n",
       "      <td>0.191211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, so]</td>\n",
       "      <td>many</td>\n",
       "      <td>0.125984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, how]</td>\n",
       "      <td>many</td>\n",
       "      <td>0.116903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, here]</td>\n",
       "      <td>comes</td>\n",
       "      <td>0.109665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, how]</td>\n",
       "      <td>long</td>\n",
       "      <td>0.095326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, he]</td>\n",
       "      <td>said</td>\n",
       "      <td>0.078437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, she]</td>\n",
       "      <td>said</td>\n",
       "      <td>0.075234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[xbos, xbol-1, [verse-1], xeol, xbol-2, my]</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.071960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         context next_word  probability\n",
       "0   [xbos, xbol-1, [verse-1], xeol, xbol-2, one]       day     0.251755\n",
       "1    [xbos, xbol-1, [verse-1], xeol, xbol-2, no]       one     0.201328\n",
       "2  [xbos, xbol-1, [verse-1], xeol, xbol-2, they]       say     0.191211\n",
       "3    [xbos, xbol-1, [verse-1], xeol, xbol-2, so]      many     0.125984\n",
       "4   [xbos, xbol-1, [verse-1], xeol, xbol-2, how]      many     0.116903\n",
       "5  [xbos, xbol-1, [verse-1], xeol, xbol-2, here]     comes     0.109665\n",
       "6   [xbos, xbol-1, [verse-1], xeol, xbol-2, how]      long     0.095326\n",
       "7    [xbos, xbol-1, [verse-1], xeol, xbol-2, he]      said     0.078437\n",
       "8   [xbos, xbol-1, [verse-1], xeol, xbol-2, she]      said     0.075234\n",
       "9    [xbos, xbol-1, [verse-1], xeol, xbol-2, my]     heart     0.071960"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(next_word_probs, columns=['context', 'next_word', 'probability'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>2.964834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2.697427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many</th>\n",
       "      <td>2.458187e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>2.332541e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>2.107267e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>1.447440e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>1.430223e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comes</th>\n",
       "      <td>1.269305e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>1.262512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1.230618e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>1.203694e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby</th>\n",
       "      <td>1.192115e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>1.142660e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>1.135521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.044062e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.016951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart</th>\n",
       "      <td>8.617054e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’s</th>\n",
       "      <td>8.244108e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>7.583455e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>7.080959e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matter</th>\n",
       "      <td>6.708994e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>6.647583e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>6.340024e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>6.186431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>6.183985e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>6.076625e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took</th>\n",
       "      <td>6.055048e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>6.000242e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>5.891895e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>came</th>\n",
       "      <td>5.825580e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deutschland</th>\n",
       "      <td>8.156344e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uma</th>\n",
       "      <td>8.116661e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[post-chorus]</th>\n",
       "      <td>8.101195e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estas</th>\n",
       "      <td>8.077781e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>8.005202e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'?</th>\n",
       "      <td>8.002195e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nur</th>\n",
       "      <td>7.998235e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[pre-chorus]</th>\n",
       "      <td>7.940247e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sind</th>\n",
       "      <td>7.934244e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bom</th>\n",
       "      <td>7.918626e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>7.896357e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pai</th>\n",
       "      <td>7.787997e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auch</th>\n",
       "      <td>7.727170e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immer</th>\n",
       "      <td>7.711474e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pimp</th>\n",
       "      <td>7.709467e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ça</th>\n",
       "      <td>7.706586e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahí</th>\n",
       "      <td>7.675823e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tão</th>\n",
       "      <td>7.606595e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'!</th>\n",
       "      <td>7.603991e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoi</th>\n",
       "      <td>7.540845e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belle</th>\n",
       "      <td>7.537696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[verse-one]</th>\n",
       "      <td>7.527287e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doch</th>\n",
       "      <td>7.509262e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quanto</th>\n",
       "      <td>7.474481e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rely</th>\n",
       "      <td>7.444283e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nichts</th>\n",
       "      <td>7.417439e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nach</th>\n",
       "      <td>7.381386e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alla</th>\n",
       "      <td>7.360010e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eso</th>\n",
       "      <td>7.278101e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nena</th>\n",
       "      <td>7.239101e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4111 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                probability\n",
       "next_word                  \n",
       "day            2.964834e-01\n",
       "one            2.697427e-01\n",
       "many           2.458187e-01\n",
       "say            2.332541e-01\n",
       "said           2.107267e-01\n",
       "long           1.447440e-01\n",
       "got            1.430223e-01\n",
       "comes          1.269305e-01\n",
       "know           1.262512e-01\n",
       "time           1.230618e-01\n",
       "could          1.203694e-01\n",
       "baby           1.192115e-01\n",
       "come           1.142660e-01\n",
       "night          1.135521e-01\n",
       "man            1.044062e-01\n",
       "love           1.016951e-01\n",
       "heart          8.617054e-02\n",
       "’s             8.244108e-02\n",
       "little         7.583455e-02\n",
       "girl           7.080959e-02\n",
       "matter         6.708994e-02\n",
       "need           6.647583e-02\n",
       "never          6.340024e-02\n",
       "way            6.186431e-02\n",
       "look           6.183985e-02\n",
       "world          6.076625e-02\n",
       "took           6.055048e-02\n",
       "last           6.000242e-02\n",
       "!              5.891895e-02\n",
       "came           5.825580e-02\n",
       "...                     ...\n",
       "deutschland    8.156344e-07\n",
       "uma            8.116661e-07\n",
       "[post-chorus]  8.101195e-07\n",
       "estas          8.077781e-07\n",
       "eve            8.005202e-07\n",
       "'?             8.002195e-07\n",
       "nur            7.998235e-07\n",
       "[pre-chorus]   7.940247e-07\n",
       "sind           7.934244e-07\n",
       "bom            7.918626e-07\n",
       "abuse          7.896357e-07\n",
       "pai            7.787997e-07\n",
       "auch           7.727170e-07\n",
       "immer          7.711474e-07\n",
       "pimp           7.709467e-07\n",
       "ça             7.706586e-07\n",
       "ahí            7.675823e-07\n",
       "tão            7.606595e-07\n",
       "'!             7.603991e-07\n",
       "quoi           7.540845e-07\n",
       "belle          7.537696e-07\n",
       "[verse-one]    7.527287e-07\n",
       "doch           7.509262e-07\n",
       "quanto         7.474481e-07\n",
       "rely           7.444283e-07\n",
       "nichts         7.417439e-07\n",
       "nach           7.381386e-07\n",
       "alla           7.360010e-07\n",
       "eso            7.278101e-07\n",
       "nena           7.239101e-07\n",
       "\n",
       "[4111 rows x 1 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('next_word').sum().sort_values(by='probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGMlJREFUeJzt3X+Q1Pd93/HnKyKysGQLZFlbCjTg0cWN5ItV+YKUetKshA1ISg1tTQcPE51U2utksGtnyMSQTEosWRkcW6HRJFZ7Y2iR6xgTxSqMpVi9Ym8z6Qz6gSULIVnlLBFxhgg7INKzbGXOfveP/Zy9Od/efvfY2x98Xo8ZZr/fz/fz/Xzf32PvXrvf73f3q4jAzMzy81OdLsDMzDrDAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWVqXqcLmMmVV14Zy5Yta8lY3/3ud7n00ktbMlYn9HL9vVw7uP5O6uXaoXP1Hz58+DsR8dZG/bo6AJYtW8aTTz7ZkrEqlQrlcrklY3VCL9ffy7WD6++kXq4dOle/pL8q0s+HgMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMtXVnwS25izb+nDHtn18x20d27aZzY7fAZiZZapQAEj6dUlHJT0r6fOSLpG0XNJjko5J+oKki1PfN6T50bR8Wc0421L7C5JWz80umZlZEQ0DQNJi4D8AAxHxDuAiYAPwCWBnRPQBZ4FNaZVNwNmIuBrYmfoh6Zq03rXAGuDTki5q7e6YmVlRRQ8BzQPmS5oHvBE4BdwMPJiW7wHWpem1aZ60fKUkpfa9EfF6RLwEjAIrzn8XzMxsNhoGQER8C/gU8DLVP/zngMPAqxExkbqNAYvT9GLgRFp3IvV/S237NOuYmVmbNbwKSNJCqq/elwOvAn8K3DJN15hcpc6yeu1TtzcEDAGUSiUqlUqjEgsZHx9v2VidUKT+Lf0TMy6fSzPVlsPPvpv1cv29XDt0f/1FLgN9D/BSRHwbQNIXgX8KLJA0L73KXwKcTP3HgKXAWDpkdDlwpqZ9Uu06PxIRw8AwwMDAQLTqZgo53Fjijk5eBrqxXHdZDj/7btbL9fdy7dD99Rc5B/AycKOkN6Zj+SuB54CvAu9PfQaB/Wn6QJonLf9KRERq35CuEloO9AGPt2Y3zMysWQ3fAUTEY5IeBL4GTABPUX2F/jCwV9LHU9uutMou4LOSRqm+8t+QxjkqaR/V8JgANkfED1q8P2ZmVlChTwJHxHZg+5TmF5nmKp6I+D6wvs449wD3NFmjmZnNAX8S2MwsUw4AM7NMOQDMzDLlADAzy5QDwMwsU74fgLXETPci2NI/MWcfUvN9CMxmz+8AzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8tUwwCQ9HZJT9f8+1tJH5F0haQRScfS48LUX5LukzQq6RlJ19eMNZj6H5M0WH+rZmY21xoGQES8EBHXRcR1wLuA14CHgK3AwYjoAw6meYBbqN7vtw8YAu4HkHQF1buK3UD1TmLbJ0PDzMzar9lDQCuBb0bEXwFrgT2pfQ+wLk2vBR6IqkPAAkmLgNXASESciYizwAiw5rz3wMzMZqXZANgAfD5NlyLiFEB6vCq1LwZO1KwzltrqtZuZWQcU/jpoSRcD7wO2Neo6TVvM0D51O0NUDx1RKpWoVCpFS5zR+Ph4y8bqhCL1b+mfaE8xTSrNn7va2vF/msNzp1v1cu3Q/fU3cz+AW4CvRcQraf4VSYsi4lQ6xHM6tY8BS2vWWwKcTO3lKe2VqRuJiGFgGGBgYCDK5fLULrNSqVRo1VidUKT+ufrO/fO1pX+Ce4/Mza0njm8sz8m4tXJ47nSrXq4dur/+Zg4BfYAfH/4BOABMXskzCOyvab89XQ10I3AuHSJ6FFglaWE6+bsqtZmZWQcUelkm6Y3Ae4F/X9O8A9gnaRPwMrA+tT8C3AqMUr1i6E6AiDgj6W7gidTvrog4c957YGZms1IoACLiNeAtU9r+hupVQVP7BrC5zji7gd3Nl2lmZq3mTwKbmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZKhQAkhZIelDSNyQ9L+kXJV0haUTSsfS4MPWVpPskjUp6RtL1NeMMpv7HJA3W36KZmc21ou8A/hD4ckT8Y+CdwPPAVuBgRPQBB9M8VG8e35f+DQH3A0i6AtgO3ACsALZPhoaZmbVfwwCQ9GbgnwG7ACLi7yLiVWAtsCd12wOsS9NrgQei6hCwQNIiYDUwEhFnIuIsMAKsaenemJlZYUXeAbwN+DbwXyU9Jekzki4FShFxCiA9XpX6LwZO1Kw/ltrqtZuZWQcUuSn8POB64EMR8ZikP+THh3umo2naYob2v7+yNET10BGlUolKpVKgxMbGx8dbNlYnFKl/S/9Ee4ppUmn+3NXWjv/THJ473aqXa4fur79IAIwBYxHxWJp/kGoAvCJpUUScSod4Ttf0X1qz/hLgZGovT2mvTN1YRAwDwwADAwNRLpendpmVSqVCq8bqhCL137H14fYU06Qt/RPce6TIU615xzeW52TcWjk8d7pVL9cO3V9/w0NAEfHXwAlJb09NK4HngAPA5JU8g8D+NH0AuD1dDXQjcC4dInoUWCVpYTr5uyq1mZlZBxR9WfYh4HOSLgZeBO6kGh77JG0CXgbWp76PALcCo8BrqS8RcUbS3cATqd9dEXGmJXthZmZNKxQAEfE0MDDNopXT9A1gc51xdgO7mynQzMzmhj8JbGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWqUIBIOm4pCOSnpb0ZGq7QtKIpGPpcWFql6T7JI1KekbS9TXjDKb+xyQN1tuemZnNvWbeAdwUEddFxOStIbcCByOiDziY5gFuAfrSvyHgfqgGBrAduAFYAWyfDA0zM2u/8zkEtBbYk6b3AOtq2h+IqkPAAkmLgNXASESciYizwAiw5jy2b2Zm50HVe7g36CS9BJwFAvgvETEs6dWIWFDT52xELJT0JWBHRPxlaj8IfBQoA5dExMdT++8A34uIT03Z1hDVdw6USqV37d27twW7CePj41x22WUtGasTitR/5Fvn2lRNc0rz4ZXvzc3Y/Ysvn5uBa+Tw3OlWvVw7dK7+m2666XDN0Zq65hUc790RcVLSVcCIpG/M0FfTtMUM7X+/IWIYGAYYGBiIcrlcsMSZVSoVWjVWJxSp/46tD7enmCZt6Z/g3iNFn2rNOb6xPCfj1srhudOterl26P76Cx0CioiT6fE08BDVY/ivpEM7pMfTqfsYsLRm9SXAyRnazcysAxoGgKRLJb1pchpYBTwLHAAmr+QZBPan6QPA7elqoBuBcxFxCngUWCVpYTr5uyq1mZlZBxR5X14CHpI02f9PIuLLkp4A9knaBLwMrE/9HwFuBUaB14A7ASLijKS7gSdSv7si4kzL9sTMzJrSMAAi4kXgndO0/w2wcpr2ADbXGWs3sLv5Ms2mt6wN5z229E9Me37l+I7b5nzbZnPJnwQ2M8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwyVTgAJF0k6SlJX0rzyyU9JumYpC9Iuji1vyHNj6bly2rG2JbaX5C0utU7Y2ZmxTXzDuDDwPM1858AdkZEH3AW2JTaNwFnI+JqYGfqh6RrgA3AtcAa4NOSLjq/8s3MbLYKBYCkJcBtwGfSvICbgQdTlz3AujS9Ns2Tlq9M/dcCeyPi9Yh4ieo9g1e0YifMzKx5RW4KD/CfgN8E3pTm3wK8GhETaX4MWJymFwMnACJiQtK51H8xcKhmzNp1fkTSEDAEUCqVqFQqRfdlRuPj4y0bqxOK1L+lf2LG5Z1Smt+9tRVRr/5eeT718nO/l2uH7q+/YQBI+hXgdEQcllSebJ6mazRYNtM6P26IGAaGAQYGBqJcLk/tMiuVSoVWjdUJReqf7sbl3WBL/wT3Hin6WqP71Kv/+MZy+4uZhV5+7vdy7dD99Rf5rXw38D5JtwKXAG+m+o5ggaR56V3AEuBk6j8GLAXGJM0DLgfO1LRPql3HzMzarOE5gIjYFhFLImIZ1ZO4X4mIjcBXgfenboPA/jR9IM2Tln8lIiK1b0hXCS0H+oDHW7YnZmbWlPN5X/5RYK+kjwNPAbtS+y7gs5JGqb7y3wAQEUcl7QOeAyaAzRHxg/PYvpmZnYemAiAiKkAlTb/INFfxRMT3gfV11r8HuKfZIs3MrPX8SWAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDQNA0iWSHpf0dUlHJX0stS+X9JikY5K+IOni1P6GND+ali+rGWtban9B0uq52ikzM2usyDuA14GbI+KdwHXAGkk3Ap8AdkZEH3AW2JT6bwLORsTVwM7UD0nXUL095LXAGuDTki5q5c6YmVlxRW4KHxExnmZ/Ov0L4GbgwdS+B1iXptemedLylZKU2vdGxOsR8RIwyjS3lDQzs/ZQRDTuVH2lfhi4Gvhj4JPAofQqH0lLgT+PiHdIehZYExFjadk3gRuA303r/PfUviut8+CUbQ0BQwClUulde/fubcV+Mj4+zmWXXdaSsTqhSP1HvnWuTdU0pzQfXvlep6uYvXr19y++vP3FzEIvP/d7uXboXP033XTT4YgYaNSv0E3hI+IHwHWSFgAPAT83Xbf0qDrL6rVP3dYwMAwwMDAQ5XK5SIkNVSoVWjVWJxSp/46tD7enmCZt6Z/g3iOFnmpdqV79xzeW21/MLPTyc7+Xa4fur7+pq4Ai4lWgAtwILJA0+VuxBDiZpseApQBp+eXAmdr2adYxM7M2K3IV0FvTK38kzQfeAzwPfBV4f+o2COxP0wfSPGn5V6J6nOkAsCFdJbQc6AMeb9WOmJlZc4q8L18E7EnnAX4K2BcRX5L0HLBX0seBp4Bdqf8u4LOSRqm+8t8AEBFHJe0DngMmgM3p0JKZmXVAwwCIiGeAfzJN+4tMcxVPRHwfWF9nrHuAe5ov08zMWs2fBDYzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsU737+fwutmwOvpJhS/9E137Vg5n1Jr8DMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLVJFbQi6V9FVJz0s6KunDqf0KSSOSjqXHhaldku6TNCrpGUnX14w1mPofkzRYb5tmZjb3irwDmAC2RMTPUb0Z/GZJ1wBbgYMR0QccTPMAt1C9328fMATcD9XAALYDN1C9k9j2ydAwM7P2axgAEXEqIr6Wpv8f1RvCLwbWAntStz3AujS9Fnggqg4BCyQtAlYDIxFxJiLOAiPAmpbujZmZFdbUOQBJy6jeH/gxoBQRp6AaEsBVqdti4ETNamOprV67mZl1QOFvA5V0GfBnwEci4m8l1e06TVvM0D51O0NUDx1RKpWoVCpFS5zR+Ph4y8ZqZEv/RMvHLM2fm3HboZdrh/r1t+v5dL7a+dxvtV6uHbq//kIBIOmnqf7x/1xEfDE1vyJpUUScSod4Tqf2MWBpzepLgJOpvTylvTJ1WxExDAwDDAwMRLlcntplViqVCq0aq5G5+NrmLf0T3HukN7+9u5drh/r1H99Ybn8xs9DO536r9XLt0P31N/ytVPWl/i7g+Yj4g5pFB4BBYEd63F/T/kFJe6me8D2XQuJR4PdqTvyuAra1ZjfM2m8u7vtQxPEdt3Vku3bhKfKy7N3ArwJHJD2d2n6L6h/+fZI2AS8D69OyR4BbgVHgNeBOgIg4I+lu4InU766IONOSvTAzs6Y1DICI+EumP34PsHKa/gFsrjPWbmB3MwWamdnc8CeBzcwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDUMAEm7JZ2W9GxN2xWSRiQdS48LU7sk3SdpVNIzkq6vWWcw9T8maXBudsfMzIoq8g7gvwFrprRtBQ5GRB9wMM0D3AL0pX9DwP1QDQxgO9V7BK8AttfcG9jMzDqgYQBExF8AU+/duxbYk6b3AOtq2h+IqkPAAkmLgNXASESciYizwAg/GSpmZtZGsz0HUIqIUwDp8arUvhg4UdNvLLXVazczsw5peFP4Jk138/iYof0nB5CGqB4+olQqUalUWlLY+Ph4y8ZqZEv/RMvHLM2fm3HboZdrh+6rv9nncTuf+63Wy7VD99c/2wB4RdKiiDiVDvGcTu1jwNKafkuAk6m9PKW9Mt3AETEMDAMMDAxEuVyerlvTKpUKrRqrkTu2PtzyMbf0T3DvkVbndXv0cu3QffUf31huqn87n/ut1su1Q/fXP9tDQAeAySt5BoH9Ne23p6uBbgTOpUNEjwKrJC1MJ39XpTYzM+uQhi9rJH2e6qv3KyWNUb2aZwewT9Im4GVgfer+CHArMAq8BtwJEBFnJN0NPJH63RURU08sm5lZGzUMgIj4QJ1FK6fpG8DmOuPsBnY3VZ2Zmc0ZfxLYzCxTDgAzs0x1z6UNZlbIsiavMtvSP9GyK9OO77itJeNYd7igA6D2F6WVvwRmZhcCHwIyM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8uUA8DMLFMX9FdBmFlrNfs9ROdr8itc/B1Ec8PvAMzMMtX2AJC0RtILkkYlbW339s3MrKqtASDpIuCPgVuAa4APSLqmnTWYmVlVu98BrABGI+LFiPg7YC+wts01mJkZ7T8JvBg4UTM/BtzQ5hrMrMe0++TzpAv95LOq93Fv08ak9cDqiPi3af5XgRUR8aGaPkPAUJp9O/BCizZ/JfCdFo3VCb1cfy/XDq6/k3q5duhc/T8TEW9t1Knd7wDGgKU180uAk7UdImIYGG71hiU9GREDrR63XXq5/l6uHVx/J/Vy7dD99bf7HMATQJ+k5ZIuBjYAB9pcg5mZ0eZ3ABExIemDwKPARcDuiDjazhrMzKyq7Z8EjohHgEfavV3m4LBSm/Vy/b1cO7j+Turl2qHL62/rSWAzM+se/ioIM7NMXfABIGm9pKOSfijpJ87GS/pHksYl/UYn6ptJvdolvVfSYUlH0uPNnayznpl+9pK2pa8DeUHS6k7VWJSk6yQdkvS0pCclreh0Tc2Q9KH0sz4q6fc7Xc9sSPoNSSHpyk7X0gxJn5T0DUnPSHpI0oJO1zTpgg8A4FngXwJ/UWf5TuDP21dOU+rV/h3gn0dEPzAIfLbdhRU0bf3p6z82ANcCa4BPp68J6Wa/D3wsIq4D/mOa7wmSbqL6ifufj4hrgU91uKSmSVoKvBd4udO1zMII8I6I+Hng/wLbOlzPj1zwARARz0fEtB8mk7QOeBHoyiuR6tUeEU9FxOTnJ44Cl0h6Q3ura2yGn/1aYG9EvB4RLwGjVL8mpJsF8OY0fTlTPr/S5X4N2BERrwNExOkO1zMbO4HfpPr/0FMi4n9GxESaPUT1809d4YIPgHokXQp8FPhYp2s5T/8KeGryl7tHTPeVIIs7VEtRHwE+KekE1VfQXfMqroCfBX5J0mOS/rekX+h0Qc2Q9D7gWxHx9U7X0gL/hi464nBB3BBG0v8C/sE0i347IvbXWe1jwM6IGJc0d8U1MMvaJ9e9FvgEsGouaitilvVP9wPv+Cu7mfYFWAn8ekT8maR/DewC3tPO+mbSoPZ5wELgRuAXgH2S3hZddAlgg/p/iw4+x4so8nsg6beBCeBz7axtJhdEAETEbH4RbwDen06ILQB+KOn7EfFHra1uZrOsHUlLgIeA2yPim62tqrhZ1t/wK0E6YaZ9kfQA8OE0+6fAZ9pSVEENav814IvpD/7jkn5I9Ttqvt2u+hqpV7+kfmA58PX0Qm0J8DVJKyLir9tY4owa/R5IGgR+BVjZTcF7QQTAbETEL01OS/pdYLzdf/xnK11F8DCwLSL+T6frmYUDwJ9I+gPgHwJ9wOOdLamhk8AvAxXgZuBYR6tpzv+gWnNF0s8CF9MjX7AWEUeAqybnJR0HBiKiJ+qH6k2wqB5u/uWIeK3T9dS64M8BSPoXksaAXwQelvRop2sqaobaPwhcDfxOuizxaUlX1R2oQ+rVn77+Yx/wHPBlYHNE/KBzlRby74B7JX0d+D1+/I21vWA38DZJz1K9B8dgN70KzcAfAW8CRtLv6n/udEGT/ElgM7NMXfDvAMzMbHoOADOzTDkAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5QAwM8vU/wcO0VVSGqHN9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df['probability']).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             max_len=50, context_length=200,\n",
    "                             beam_width=3, verbose=False,\n",
    "                             temp=1.4, multinomial=True, graph=False, get_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol-1 [verse-1] xeol \n",
      " xbol-2 everything , everything across time xeol \n",
      " xbol-3 everything , everything , everything comes to nothing xeol \n",
      " xbol-4 everything and everything xeol \n",
      " xbol-5 everything is everything xeol \n",
      " xbol-6 xeol \n",
      " xbol-7 [chorus] xeol \n",
      " xbol-8 everything is everything xeol \n",
      " xbol-9 everything is everything xeol \n",
      " xbol-10 everything is everything xeol \n",
      " xbol-11 everything is everything 76.94984640800992\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "song, score = final_scores[0]\n",
    "print_words(song)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Model (3.4-ULMFiT-MM-108k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things get a bit trickier...\n",
    "Modify generate function to work with multimodal modeling\n",
    "\n",
    "This is the main analysis. We want to see if changing the audio features changes the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(f'../data/models/3.4-ULMFiT-MM-108k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = copy(data_lm.train_ds)\n",
    "valid_text = copy(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-train.csv')\n",
    "df_valid = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalRNN(\n",
       "  (encoder): Embedding(10002, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(10002, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): None\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       "  (multimode): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(434, 1150)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1150, 1150)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1150, 400)\n",
       "    )\n",
       "  )\n",
       "  (multidecoder): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=10002, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_sz = 34\n",
    "vocab_sz = 10002\n",
    "emb_sz = 400\n",
    "n_hid = 1150\n",
    "n_layers = 3\n",
    "pad_token = 1\n",
    "qrnn = False\n",
    "bidir = False\n",
    "drop_mult = 0.5\n",
    "dps = np.array([0.25, 0.1, 0.2, 0.02, 0.15]) * drop_mult\n",
    "hidden_p = dps[4]\n",
    "input_p = dps[0]\n",
    "embed_p = dps[3]\n",
    "weight_p = dps[2]\n",
    "tie_weights = True\n",
    "output_p = dps[1]\n",
    "bias = True\n",
    "\n",
    "class MultiModalRNN(RNNCore):\n",
    "    def __init__(self, audio_sz, output_p, bias, tie_encoder:bool=True, **kwargs):\n",
    "        super(MultiModalRNN, self).__init__(**kwargs)\n",
    "        self.rnns = None\n",
    "        self.audio_sz = audio_sz\n",
    "        self.multimode = [nn.LSTM(emb_sz + audio_sz if l == 0 else n_hid,\n",
    "                                  (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                                  1, bidirectional=bidir) for l in range(n_layers)]\n",
    "        self.multimode = [WeightDropout(rnn, weight_p) for rnn in self.multimode]\n",
    "        self.multimode = torch.nn.ModuleList(self.multimode)\n",
    "        \n",
    "        if tie_encoder:\n",
    "            enc = self.encoder\n",
    "        else:\n",
    "            enc = None\n",
    "        \n",
    "        self.multidecoder = LinearDecoder(vocab_sz,\n",
    "                                          emb_sz,\n",
    "                                          output_p,\n",
    "                                          tie_encoder=enc,\n",
    "                                          bias=bias)\n",
    "        \n",
    "    def forward(self, input:LongTensor, input_audio:Tensor)->Tuple[Tensor,Tensor,Tensor]:\n",
    "        sl,bs = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(self.encoder_dp(input))\n",
    "        raw_output = torch.cat([raw_output, input_audio], dim=2)\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.multimode, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = to_detach(new_hidden)\n",
    "        \n",
    "        output = self.multidecoder.output_dp(outputs[-1])\n",
    "        decoded = self.multidecoder.decoder(output.view(output.size(0)*output.size(1),\n",
    "                                                        output.size(2)))\n",
    "        \n",
    "        return decoded, raw_outputs, outputs\n",
    "    \n",
    "    def _one_hidden(self, l:int)->Tensor:\n",
    "        \"Return one hidden state.\"\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "        return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states.\"\n",
    "        [r.reset() for r in self.multimode if hasattr(r, 'reset')]\n",
    "        self.weights = next(self.parameters()).data\n",
    "        if self.qrnn: self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n",
    "        else: self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]\n",
    "    \n",
    "multimodal_rnn = MultiModalRNN(audio_sz=audio_sz,\n",
    "                              vocab_sz=vocab_sz,\n",
    "                              emb_sz=emb_sz,\n",
    "                              n_hid=n_hid,\n",
    "                              n_layers=n_layers,\n",
    "                              pad_token=pad_token,\n",
    "                              qrnn=qrnn,\n",
    "                              bidir=bidir,\n",
    "                              hidden_p=hidden_p,\n",
    "                              input_p=input_p,\n",
    "                              embed_p=embed_p,\n",
    "                              weight_p=weight_p,\n",
    "                              output_p=output_p,\n",
    "                              bias=bias,\n",
    "                              tie_encoder=tie_weights)\n",
    "\n",
    "multimodal_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't actually need any of this data, but the current state isn't modular enough to not include it...\n",
    "\n",
    "One major update we need is to decouple the model with `learner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "- scikit-learn version 0.20.0 is required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def log_features(X):\n",
    "    return np.log(X)\n",
    "log_feat = FunctionTransformer(log_features, validate=False)\n",
    "\n",
    "def bin_tempo(X):\n",
    "    '''\n",
    "    ref: https://en.wikipedia.org/wiki/Tempo#Italian_tempo_markings\n",
    "    These are rough loosely based on tempo markings above\n",
    "    Have considered both classical forms of music and popular\n",
    "    '''\n",
    "    assert X.shape[1] == 1, \"Only 1 column can be binned\"\n",
    "    bins = [0, 60, 76, 108, 120, 156, 176, 200, 500]\n",
    "    return pd.DataFrame(pd.cut(X.iloc[:,0], bins=bins))\n",
    "tempo_feat = FunctionTransformer(bin_tempo, validate=False)\n",
    "\n",
    "def bin_time_signature(X):\n",
    "    assert X.shape[1] == 1, \"Only 1 column can be binned\"\n",
    "    X['time_signature_bin'] = \"Other Signature\"\n",
    "    X.loc[X['time_signature'] == 4, 'time_signature_bin'] = '4/4 Signature'\n",
    "    X.loc[X['time_signature'] == 3, 'time_signature_bin'] = '3/4 Signature'\n",
    "    return X[['time_signature_bin']]\n",
    "time_feat = FunctionTransformer(bin_time_signature, validate=False)\n",
    "\n",
    "def to_string(X):\n",
    "    return X.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continous features\n",
    "numeric_features = ['artist_familiarity',\n",
    "                    'artist_hotttnesss',\n",
    "                    'loudness',\n",
    "                    'song_hotttnesss']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# log features\n",
    "log_features = ['duration']\n",
    "log_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log_feat', log_feat),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# categorical features\n",
    "categorical_features = ['key', 'mode']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('stringify', FunctionTransformer(to_string, validate=False)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# confidence features\n",
    "confidence_features = ['key_confidence',\n",
    "                       'mode_confidence',\n",
    "                       'time_signature_confidence'\n",
    "                      ]\n",
    "confidence_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "])\n",
    "\n",
    "# time signature feature\n",
    "time_feature = ['time_signature']\n",
    "time_transformer = Pipeline(steps=[\n",
    "    ('binner', time_feat),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('stringify', FunctionTransformer(to_string, validate=False)),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# tempo feature\n",
    "tempo_feature = ['tempo']\n",
    "tempo_transformer = Pipeline(steps=[\n",
    "    ('binner', tempo_feat),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('stringify', FunctionTransformer(to_string, validate=False)),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('log', log_transformer, log_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('con', confidence_transformer, confidence_features),\n",
    "        ('time', time_transformer, time_feature),\n",
    "        ('tempo', tempo_transformer, tempo_feature)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syang/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1)))]), ['artist_familiarity', 'artist_hotttnesss', 'loudness', 'song_hotttnes...=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True))]), ['tempo'])])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tfm = preprocessor.transform(df_train)\n",
    "df_valid_tfm = preprocessor.transform(df_valid)\n",
    "\n",
    "train_audio = AudioDataset(df_train_tfm, train_text)\n",
    "valid_audio = AudioDataset(df_valid_tfm, valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data = MultimodalDataLoader(audio_dataset=train_audio,\n",
    "                                  dataset=train_text)\n",
    "multi_data_valid = MultimodalDataLoader(audio_dataset=valid_audio,\n",
    "                                  dataset=valid_text)\n",
    "multi_db = DataBunch(multi_data, multi_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner(multi_db, multimodal_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('3.4-ULMFiT-MM-108k_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Generate Text For Pure LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, audio, context_length, temp=1):\n",
    "\n",
    "    # FIX THIS\n",
    "    audio_size = train_audio.feature_size\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "    \n",
    "    if audio is None:\n",
    "        audio_features = Tensor([0]*audio_size*len(context))\\\n",
    "        .view(-1, 1, audio_size).cuda()\n",
    "    else:\n",
    "        audio_features = np.tile(audio, len(context))\n",
    "        audio_features = Tensor(audio_features).view(-1, 1, len(audio)).cuda()\n",
    "        \n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context, audio_features)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def get_word_from_index(idx):\n",
    "\n",
    "    return data_lm.valid_ds.vocab.textify([idx])\n",
    "\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = 'xeol \\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = word\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], audio=None,\n",
    "                  max_len=500, GPU=False, context_length=20,\n",
    "                  beam_width=5, temp=1, multinomial=True,\n",
    "                  verbose=True, graph=False, get_probs=False):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    if graph:\n",
    "        optimization_graph = Digraph()\n",
    "\n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in tqdm(range(max_len)):\n",
    "#         print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        next_word_probs = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, audio, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            if multinomial:\n",
    "                multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "                top_probabilities = np.argwhere(multinom_draw != 0).flatten()                    \n",
    "                \n",
    "            # top-k from probabilities    \n",
    "            else:\n",
    "                top_probabilities = np.argsort(-probabilities)[:beam_width]\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "                if get_probs:\n",
    "                    next_word_prob = probabilities[next_word_idx]\n",
    "                    potential_next_word = get_word_from_index(next_word_idx)\n",
    "                    prior_context = [get_word_from_index(w) for w in context]\n",
    "                    next_word_probs.append((prior_context, potential_next_word, next_word_prob))\n",
    "                \n",
    "                if graph:\n",
    "                    optimization_graph.node(\"%d_%d\" % (word_number, next_word_idx), \"%s (%.2f)\" % (get_word_from_index(next_word_idx), candidate[1]))\n",
    "                    optimization_graph.edge(\"%d_%d\" % (word_number - 1, context[len(context) -1]), \"%d_%d\" % (word_number, next_word_idx))\n",
    "                \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "\n",
    "        context_and_scores = context_and_scores[:30] #for now, only keep the top 30 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "\n",
    "    if graph:\n",
    "        now = str(datetime.datetime.now())\n",
    "        optimization_graph.render(directory='graph_viz/', filename=now, cleanup=True)\n",
    "        \n",
    "    if get_probs:\n",
    "        next_word_probs = sorted(next_word_probs, key=lambda x: -x[2])\n",
    "        return next_word_probs\n",
    "        \n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features from validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode == 1, loudness == -2.3,\n",
    "# artist_hot == 0.57, artist_familiarity = 0.77, \n",
    "# song_hot == n/a\n",
    "xx = valid_audio[9126]\n",
    "\n",
    "# mode == 0, loudness == -15.5,\n",
    "# artist_hot == 0.36, artist_familiarity = 0.51, \n",
    "# song_hot == 0\n",
    "yy = valid_audio[7650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Artificial\" Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create artificial audio features\n",
    "# 0.9 for all continuous features\n",
    "# key = 0 (of 12)\n",
    "# mode = 1 (of 2)\n",
    "# time = 1 (of 3)\n",
    "# tempo = 7 (of 9)\n",
    "zz1 = np.array([0.9, 0.9, 0.9, 0.9, 0.9, \n",
    "                1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "                0., 1.,\n",
    "                0.9, 0.9, 0.9,\n",
    "                0., 1., 0.,\n",
    "                0., 0., 0., 0., 0., 0., 0., 1., 0.\n",
    "               ])\n",
    "# 0.2 for all continuous features\n",
    "# key = 0 (of 12)\n",
    "# mode = 0 (of 2)\n",
    "# time = 1 (of 3)\n",
    "# tempo = 2 (of 9)\n",
    "zz2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2, \n",
    "                1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "                1., 0.,\n",
    "                0.9, 0.9, 0.9,\n",
    "                0., 1., 0.,\n",
    "                0., 0., 1., 0., 0., 0., 0., 0., 0.\n",
    "               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature set #1\n",
    "These are features that appear to be more \"Pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "next_word_probs = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             audio=zz1,\n",
    "                             max_len=5, context_length=200,\n",
    "                             beam_width=1000, verbose=False,\n",
    "                             temp=1, multinomial=False, graph=False, get_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_probs = [s for s in next_word_probs if s[1] not in stop_words]\n",
    "next_word_probs = [s for s in next_word_probs if 'xbol' not in s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(next_word_probs, columns=['context', 'next_word', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keeper</th>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killed</th>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer</th>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fallin</th>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paralyzed</th>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route</th>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids</th>\n",
       "      <td>0.003421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colors</th>\n",
       "      <td>0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soda</th>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>village</th>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           probability\n",
       "next_word             \n",
       "keeper        0.000478\n",
       "killed        0.000333\n",
       "lawyer        0.000859\n",
       "fallin        0.000517\n",
       "paralyzed     0.000049\n",
       "route         0.000047\n",
       "kids          0.003421\n",
       "colors        0.001994\n",
       "soda          0.000029\n",
       "village       0.000167"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz1_words = df.groupby('next_word').sum().sort_values(by='probability', ascending=False)\n",
    "zz1_words.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df['probability']).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             audio=zz1,\n",
    "                             max_len=50, context_length=200,\n",
    "                             beam_width=3, verbose=False,\n",
    "                             temp=1.4, multinomial=True, graph=False, get_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol-1 [verse-1] xeol \n",
      " xbol-2 like dream forever xeol \n",
      " xbol-3 but i close my eyes xeol \n",
      " xbol-4 whenever i need you xeol \n",
      " xbol-5 close the door xeol \n",
      " xbol-6 xeol \n",
      " xbol-7 [pre-chorus] xeol \n",
      " xbol-8 la la la la xeol \n",
      " xbol-9 la la la la xeol \n",
      " xbol-10 la la la la xeol \n",
      " xbol-11 xeol \n",
      " xbol-12 [chorus] xeol \n",
      " 89.24331739598868\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "song, score = final_scores[0]\n",
    "print_words(song)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features set #2\n",
    "These are features that are less \"Pop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "next_word_probs = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             audio=zz2,\n",
    "                             max_len=5, context_length=200,\n",
    "                             beam_width=1000, verbose=False,\n",
    "                             temp=1, multinomial=False, graph=False, get_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_probs = [s for s in next_word_probs if s[1] not in stop_words]\n",
    "next_word_probs = [s for s in next_word_probs if 'xbol' not in s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(next_word_probs, columns=['context', 'next_word', 'probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maniac</th>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laughing</th>\n",
       "      <td>0.003271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whiskey</th>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colour</th>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweep</th>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reality</th>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(get</th>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hill</th>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cock</th>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           probability\n",
       "next_word             \n",
       "maniac        0.000118\n",
       "laughing      0.003271\n",
       "whiskey       0.000730\n",
       "colour        0.001337\n",
       "sweep         0.000291\n",
       "reality       0.000291\n",
       "(get          0.000044\n",
       "milk          0.000484\n",
       "hill          0.000706\n",
       "cock          0.000311"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz2_words = df.groupby('next_word').sum().sort_values(by='probability', ascending=False)\n",
    "zz2_words.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_x</th>\n",
       "      <th>probability_y</th>\n",
       "      <th>diff</th>\n",
       "      <th>diff_abs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>0.046421</td>\n",
       "      <td>0.079122</td>\n",
       "      <td>-0.032701</td>\n",
       "      <td>0.032701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.056982</td>\n",
       "      <td>-0.029789</td>\n",
       "      <td>0.029789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'bout</th>\n",
       "      <td>0.166847</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.018456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>0.315469</td>\n",
       "      <td>0.298075</td>\n",
       "      <td>0.017394</td>\n",
       "      <td>0.017394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.228762</td>\n",
       "      <td>0.244625</td>\n",
       "      <td>-0.015863</td>\n",
       "      <td>0.015863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>0.015821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>0.028418</td>\n",
       "      <td>0.043850</td>\n",
       "      <td>-0.015432</td>\n",
       "      <td>0.015432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>0.034909</td>\n",
       "      <td>0.048830</td>\n",
       "      <td>-0.013921</td>\n",
       "      <td>0.013921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <td>0.146258</td>\n",
       "      <td>0.154520</td>\n",
       "      <td>-0.008262</td>\n",
       "      <td>0.008262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inside</th>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.029641</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.007727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>0.096081</td>\n",
       "      <td>0.088526</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.007555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.216158</td>\n",
       "      <td>0.223621</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.044712</td>\n",
       "      <td>0.050892</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>0.006180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>0.250654</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>0.684277</td>\n",
       "      <td>0.678388</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.005889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.170217</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell</th>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.074335</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.128020</td>\n",
       "      <td>0.122778</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stranger</th>\n",
       "      <td>0.038418</td>\n",
       "      <td>0.033370</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.005048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.067837</td>\n",
       "      <td>0.072801</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.070412</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired</th>\n",
       "      <td>0.050677</td>\n",
       "      <td>0.046010</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.004668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.004156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.037898</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <td>0.117138</td>\n",
       "      <td>0.113143</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.034596</td>\n",
       "      <td>0.030650</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.071241</td>\n",
       "      <td>0.067502</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.122563</td>\n",
       "      <td>0.125909</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>0.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.060021</td>\n",
       "      <td>0.062977</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.104701</td>\n",
       "      <td>0.101773</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.002928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smaller</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smells</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sow</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spittin</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweetly</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swell</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanto</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tar</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tattooed</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tek</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>todos</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tons</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>torch</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trough</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tus</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tú</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unable</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unity</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unlike</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unreal</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valentine</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verse</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ville</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weapons</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderland</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            probability_x  probability_y      diff  diff_abs\n",
       "next_word                                                   \n",
       "much             0.046421       0.079122 -0.032701  0.032701\n",
       "time             0.027193       0.056982 -0.029789  0.029789\n",
       "'bout            0.166847       0.148392  0.018456  0.018456\n",
       "little           0.315469       0.298075  0.017394  0.017394\n",
       "one              0.228762       0.244625 -0.015863  0.015863\n",
       "around           0.030326       0.014506  0.015821  0.015821\n",
       "nothing          0.028418       0.043850 -0.015432  0.015432\n",
       "anything         0.034909       0.048830 -0.013921  0.013921\n",
       "child            0.146258       0.154520 -0.008262  0.008262\n",
       "inside           0.037367       0.029641  0.007727  0.007727\n",
       "type             0.096081       0.088526  0.007555  0.007555\n",
       "get              0.216158       0.223621 -0.007463  0.007463\n",
       "fool             0.044712       0.050892 -0.006180  0.006180\n",
       "young            0.250654       0.244724  0.005930  0.005930\n",
       "long             0.684277       0.678388  0.005889  0.005889\n",
       "man              0.176016       0.170217  0.005799  0.005799\n",
       "tell             0.079632       0.074335  0.005296  0.005296\n",
       "boy              0.128020       0.122778  0.005242  0.005242\n",
       "stranger         0.038418       0.033370  0.005048  0.005048\n",
       "way              0.067837       0.072801 -0.004963  0.004963\n",
       "world            0.075353       0.070412  0.004941  0.004941\n",
       "tired            0.050677       0.046010  0.004668  0.004668\n",
       "back             0.019264       0.015107  0.004156  0.004156\n",
       "another          0.037898       0.042033 -0.004135  0.004135\n",
       "feeling          0.117138       0.113143  0.003995  0.003995\n",
       "good             0.034596       0.030650  0.003946  0.003946\n",
       "new              0.071241       0.067502  0.003739  0.003739\n",
       "girl             0.122563       0.125909 -0.003346  0.003346\n",
       "love             0.060021       0.062977 -0.002956  0.002956\n",
       "go               0.104701       0.101773  0.002928  0.002928\n",
       "...                   ...            ...       ...       ...\n",
       "skills                NaN       0.000030       NaN       NaN\n",
       "slightly         0.000006            NaN       NaN       NaN\n",
       "smaller          0.000005            NaN       NaN       NaN\n",
       "smells           0.000004            NaN       NaN       NaN\n",
       "sow                   NaN       0.000040       NaN       NaN\n",
       "spittin          0.000035            NaN       NaN       NaN\n",
       "sweetly          0.000004            NaN       NaN       NaN\n",
       "swell            0.000019            NaN       NaN       NaN\n",
       "tanto            0.000017            NaN       NaN       NaN\n",
       "tar              0.000018            NaN       NaN       NaN\n",
       "tattooed         0.000081            NaN       NaN       NaN\n",
       "tek                   NaN       0.000037       NaN       NaN\n",
       "todos                 NaN       0.000018       NaN       NaN\n",
       "tons                  NaN       0.000018       NaN       NaN\n",
       "torch                 NaN       0.000102       NaN       NaN\n",
       "tour                  NaN       0.000036       NaN       NaN\n",
       "trough           0.000003            NaN       NaN       NaN\n",
       "tus              0.000016            NaN       NaN       NaN\n",
       "tú                    NaN       0.000018       NaN       NaN\n",
       "unable                NaN       0.000035       NaN       NaN\n",
       "unity                 NaN       0.000021       NaN       NaN\n",
       "unlike           0.000002            NaN       NaN       NaN\n",
       "unreal           0.000004            NaN       NaN       NaN\n",
       "valentine        0.000007            NaN       NaN       NaN\n",
       "value                 NaN       0.000016       NaN       NaN\n",
       "verse            0.000006            NaN       NaN       NaN\n",
       "ville            0.000016            NaN       NaN       NaN\n",
       "w                     NaN       0.000017       NaN       NaN\n",
       "weapons               NaN       0.000018       NaN       NaN\n",
       "wonderland            NaN       0.000019       NaN       NaN\n",
       "\n",
       "[4546 rows x 4 columns]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.merge(zz1_words, zz2_words, how='outer', left_index=True, right_index=True)\n",
    "df_combined['diff'] = df_combined['probability_x'] - df_combined['probability_y']\n",
    "df_combined['diff_abs'] = np.abs(df_combined['diff'])\n",
    "df_combined.sort_values(by='diff_abs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df['probability']).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol-1 [verse-1] xeol xbol-2',\n",
    "                             audio=zz2,\n",
    "                             max_len=50, context_length=200,\n",
    "                             beam_width=3, verbose=False,\n",
    "                             temp=1.4, multinomial=True, graph=False, get_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xbol-1 [verse-1] xeol \n",
      " xbol-2 stories what they mean to me xeol \n",
      " xbol-3 all i can do , don 't turn away from me xeol \n",
      " xbol-4 i don 't care , don 't care if you care xeol \n",
      " xbol-5 don 't care who i love , don 't care about me xeol \n",
      " xbol-6 xeol \n",
      " xbol-7 104.83641201184396\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "song, score = final_scores[0]\n",
    "print_words(song)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
