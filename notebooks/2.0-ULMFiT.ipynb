{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.tokenize\n",
    "import itertools\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msd_id</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAADJU128F92F58E1</td>\n",
       "      <td>I hear you praying with your hands clasped ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAADQX128F422B4CF</td>\n",
       "      <td>If you ever make it back to Nashville\\nRemembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAFTE128F429545F</td>\n",
       "      <td>Just when I thought I was safe\\nYou found me i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAKAG128F4275D2A</td>\n",
       "      <td>Paroles de la chanson Sultao Das Matas :\\nSult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAMRO128F92F20D7</td>\n",
       "      <td>From What You Whispered\\n........................</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msd_id                                             lyrics\n",
       "0  TRAADJU128F92F58E1  I hear you praying with your hands clasped ove...\n",
       "1  TRAADQX128F422B4CF  If you ever make it back to Nashville\\nRemembe...\n",
       "2  TRAAFTE128F429545F  Just when I thought I was safe\\nYou found me i...\n",
       "3  TRAAKAG128F4275D2A  Paroles de la chanson Sultao Das Matas :\\nSult...\n",
       "4  TRAAMRO128F92F20D7  From What You Whispered\\n........................"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/w210-capstone/data/lyrics-valid.csv', header=None, escapechar='\\\\', names=['msd_id', 'lyrics'])\n",
    "# drop lyrics >5000\n",
    "df = df[df.lyrics.str.len() < 5000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "1. First consider each line its own \"sentence\", keeping track of blanklines\n",
    "2. Regexp Tokenizer with the following:  \n",
    " - Bracket enclosed texts (usually song part header)\n",
    " - All words\n",
    " - Any numeric -- keep commas and periods together\n",
    " - All other non-whitespace characters\n",
    "3. Wrap each line with `<s>` and `</s>` tokens\n",
    "4. Wrap each song with `<d>` and `</d>` tokens (documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics):\n",
    "    tk = nltk.tokenize.LineTokenizer(blanklines='keep')\n",
    "    tokd = tk.tokenize(lyrics)\n",
    "    \n",
    "    re_tk = nltk.tokenize.RegexpTokenizer(r'\\[[^\\]]+\\]|\\w+|[\\d\\.,]+|\\S+',\n",
    "                                          discard_empty=False)\n",
    "    re_tokd = re_tk.tokenize_sents(tokd)\n",
    "    \n",
    "    [s.insert(0, f'xBOL') for s in re_tokd] # insert start token for each line\n",
    "    [s.append('xEOL') for s in re_tokd] # append end token for each line\n",
    "    \n",
    "    flat = list(itertools.chain(*re_tokd))\n",
    "    flat.insert(0, 'xBOS')\n",
    "    flat.append('xEOS')\n",
    "    # lower case and de-space\n",
    "    flat = [w.lower().replace(' ', '-') for w in flat]\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msd_id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>tokd</th>\n",
       "      <th>tokd_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAADJU128F92F58E1</td>\n",
       "      <td>I hear you praying with your hands clasped ove...</td>\n",
       "      <td>[xbos, xbol, i, hear, you, praying, with, your...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAADQX128F422B4CF</td>\n",
       "      <td>If you ever make it back to Nashville\\nRemembe...</td>\n",
       "      <td>[xbos, xbol, if, you, ever, make, it, back, to...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAFTE128F429545F</td>\n",
       "      <td>Just when I thought I was safe\\nYou found me i...</td>\n",
       "      <td>[xbos, xbol, just, when, i, thought, i, was, s...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAKAG128F4275D2A</td>\n",
       "      <td>Paroles de la chanson Sultao Das Matas :\\nSult...</td>\n",
       "      <td>[xbos, xbol, paroles, de, la, chanson, sultao,...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAMRO128F92F20D7</td>\n",
       "      <td>From What You Whispered\\n........................</td>\n",
       "      <td>[xbos, xbol, from, what, you, whispered, xeol,...</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               msd_id                                             lyrics  \\\n",
       "0  TRAADJU128F92F58E1  I hear you praying with your hands clasped ove...   \n",
       "1  TRAADQX128F422B4CF  If you ever make it back to Nashville\\nRemembe...   \n",
       "2  TRAAFTE128F429545F  Just when I thought I was safe\\nYou found me i...   \n",
       "3  TRAAKAG128F4275D2A  Paroles de la chanson Sultao Das Matas :\\nSult...   \n",
       "4  TRAAMRO128F92F20D7  From What You Whispered\\n........................   \n",
       "\n",
       "                                                tokd  tokd_len  \n",
       "0  [xbos, xbol, i, hear, you, praying, with, your...       215  \n",
       "1  [xbos, xbol, if, you, ever, make, it, back, to...       196  \n",
       "2  [xbos, xbol, just, when, i, thought, i, was, s...       186  \n",
       "3  [xbos, xbol, paroles, de, la, chanson, sultao,...        58  \n",
       "4  [xbos, xbol, from, what, you, whispered, xeol,...       310  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokd'] = df.lyrics.apply(tokenize_lyrics)\n",
    "df['tokd_len'] = df.tokd.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, just save both as both train and valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model file prep\n",
    "\n",
    "In general, you need train tokens, validation tokens, an int-to-string (itos) mapping, and your state dict (i.e. weights, parameters, .pth file; these three are all the same thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TOKENS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = '2.0-ULMFiT'\n",
    "MODEL_PATH = Path(f'../data/models/{model_title}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_TOKENS:\n",
    "    tokens = np.array(df.tokd)\n",
    "    \n",
    "    np.save(MODEL_PATH/'train_tok.npy', tokens)\n",
    "    np.save(MODEL_PATH/'valid_tok.npy', tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ULMFiT Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_WIKITEXT = False\n",
    "DOWNLOAD_PRETRAINED_LYRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_WIKITEXT:\n",
    "    url = 'http://files.fast.ai/models/wt103_v1/'\n",
    "    download_url(f'{url}lstm_wt103.pth', MODEL_PATH/'models/lstm_wt103.pth')\n",
    "    download_url(f'{url}itos_wt103.pkl', MODEL_PATH/'models/itos_wt103.pkl')\n",
    "    \n",
    "if DOWNLOAD_PRETRAINED_LYRICS:\n",
    "    url = 'https://storage.googleapis.com/capstone-deep-lyrics/'\n",
    "    download_url(f'{url}2.0-ULMFiT.pth', MODEL_PATH/'models/2.0-ULMFiT.pth')\n",
    "    download_url(f'{url}itos.pkl', MODEL_PATH/'models/itos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_tokens(MODEL_PATH,\n",
    "                                      bs=128,\n",
    "                                      max_vocab=10000)\n",
    "\n",
    "print(data_lm.train_ds.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 128]) torch.Size([12160])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xbos</td>\n",
       "      <td>xeol</td>\n",
       "      <td>'s</td>\n",
       "      <td>[outro]</td>\n",
       "      <td>will</td>\n",
       "      <td>xeol</td>\n",
       "      <td>so</td>\n",
       "      <td>xbol</td>\n",
       "      <td>won</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xbol</td>\n",
       "      <td>xbol</td>\n",
       "      <td>sad</td>\n",
       "      <td>xeol</td>\n",
       "      <td>destroy</td>\n",
       "      <td>xbol</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>'t</td>\n",
       "      <td>soul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>but</td>\n",
       "      <td>xbol</td>\n",
       "      <td>her</td>\n",
       "      <td>i</td>\n",
       "      <td>fight</td>\n",
       "      <td>said</td>\n",
       "      <td>deal</td>\n",
       "      <td>xeol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hear</td>\n",
       "      <td>'ll</td>\n",
       "      <td>you</td>\n",
       "      <td>i</td>\n",
       "      <td>xeol</td>\n",
       "      <td>'ve</td>\n",
       "      <td>xeol</td>\n",
       "      <td>,</td>\n",
       "      <td>xeol</td>\n",
       "      <td>xeos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>do</td>\n",
       "      <td>seem</td>\n",
       "      <td>'ll</td>\n",
       "      <td>xbol</td>\n",
       "      <td>been</td>\n",
       "      <td>xbol</td>\n",
       "      <td>it</td>\n",
       "      <td>xbol</td>\n",
       "      <td>xbos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>praying</td>\n",
       "      <td>anything</td>\n",
       "      <td>better</td>\n",
       "      <td>never</td>\n",
       "      <td>so</td>\n",
       "      <td>takin</td>\n",
       "      <td>i</td>\n",
       "      <td>'s</td>\n",
       "      <td>i</td>\n",
       "      <td>xbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with</td>\n",
       "      <td>for</td>\n",
       "      <td>when</td>\n",
       "      <td>know</td>\n",
       "      <td>i</td>\n",
       "      <td>'</td>\n",
       "      <td>cannot</td>\n",
       "      <td>my</td>\n",
       "      <td>won</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your</td>\n",
       "      <td>you</td>\n",
       "      <td>i</td>\n",
       "      <td>xeol</td>\n",
       "      <td>'m</td>\n",
       "      <td>all</td>\n",
       "      <td>shake</td>\n",
       "      <td>life</td>\n",
       "      <td>'t</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hands</td>\n",
       "      <td>,</td>\n",
       "      <td>'m</td>\n",
       "      <td>xbol</td>\n",
       "      <td>giving</td>\n",
       "      <td>the</td>\n",
       "      <td>from</td>\n",
       "      <td>xeol</td>\n",
       "      <td>change</td>\n",
       "      <td>em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xxunk</td>\n",
       "      <td>show</td>\n",
       "      <td>gone</td>\n",
       "      <td>i</td>\n",
       "      <td>up</td>\n",
       "      <td>blame</td>\n",
       "      <td>my</td>\n",
       "      <td>xbol</td>\n",
       "      <td>,</td>\n",
       "      <td>busca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>over</td>\n",
       "      <td>me</td>\n",
       "      <td>xeol</td>\n",
       "      <td>'ll</td>\n",
       "      <td>,</td>\n",
       "      <td>but</td>\n",
       "      <td>brain</td>\n",
       "      <td>you</td>\n",
       "      <td>i</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>your</td>\n",
       "      <td>xeol</td>\n",
       "      <td>xbol</td>\n",
       "      <td>never</td>\n",
       "      <td>giving</td>\n",
       "      <td>xeol</td>\n",
       "      <td>what</td>\n",
       "      <td>ain</td>\n",
       "      <td>'ll</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chest</td>\n",
       "      <td>xbol</td>\n",
       "      <td>xeol</td>\n",
       "      <td>know</td>\n",
       "      <td>up</td>\n",
       "      <td>xbol</td>\n",
       "      <td>i</td>\n",
       "      <td>'t</td>\n",
       "      <td>tough</td>\n",
       "      <td>xeol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xeol</td>\n",
       "      <td>xeol</td>\n",
       "      <td>xbol</td>\n",
       "      <td>xeol</td>\n",
       "      <td>xeol</td>\n",
       "      <td>i</td>\n",
       "      <td>saw</td>\n",
       "      <td>gonna</td>\n",
       "      <td>it</td>\n",
       "      <td>xbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xbol</td>\n",
       "      <td>xbol</td>\n",
       "      <td>and</td>\n",
       "      <td>xeos</td>\n",
       "      <td>xbol</td>\n",
       "      <td>'ll</td>\n",
       "      <td>in</td>\n",
       "      <td>change</td>\n",
       "      <td>out</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i</td>\n",
       "      <td>oh</td>\n",
       "      <td>all</td>\n",
       "      <td>xbos</td>\n",
       "      <td>my</td>\n",
       "      <td>never</td>\n",
       "      <td>his</td>\n",
       "      <td>my</td>\n",
       "      <td>xeol</td>\n",
       "      <td>sua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hear</td>\n",
       "      <td>baby</td>\n",
       "      <td>of</td>\n",
       "      <td>xbol</td>\n",
       "      <td>pride</td>\n",
       "      <td>make</td>\n",
       "      <td>eyes</td>\n",
       "      <td>life</td>\n",
       "      <td>xbol</td>\n",
       "      <td>banda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>men</td>\n",
       "      <td>,</td>\n",
       "      <td>these</td>\n",
       "      <td>well</td>\n",
       "      <td>for</td>\n",
       "      <td>the</td>\n",
       "      <td>xeol</td>\n",
       "      <td>,</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xxunk</td>\n",
       "      <td>come</td>\n",
       "      <td>words</td>\n",
       "      <td>,</td>\n",
       "      <td>you</td>\n",
       "      <td>same</td>\n",
       "      <td>xbol</td>\n",
       "      <td>oh</td>\n",
       "      <td>it</td>\n",
       "      <td>rio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>while</td>\n",
       "      <td>on</td>\n",
       "      <td>i</td>\n",
       "      <td>you</td>\n",
       "      <td>xeol</td>\n",
       "      <td>mistake</td>\n",
       "      <td>in</td>\n",
       "      <td>no</td>\n",
       "      <td>out</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1       2        3        4        5       6       7  \\\n",
       "0      xbos      xeol      's  [outro]     will     xeol      so    xbol   \n",
       "1      xbol      xbol     sad     xeol  destroy     xbol       i       i   \n",
       "2         i         i     but     xbol      her        i   fight    said   \n",
       "3      hear       'll     you        i     xeol      've    xeol       ,   \n",
       "4       you        do    seem      'll     xbol     been    xbol      it   \n",
       "5   praying  anything  better    never       so    takin       i      's   \n",
       "6      with       for    when     know        i        '  cannot      my   \n",
       "7      your       you       i     xeol       'm      all   shake    life   \n",
       "8     hands         ,      'm     xbol   giving      the    from    xeol   \n",
       "9     xxunk      show    gone        i       up    blame      my    xbol   \n",
       "10     over        me    xeol      'll        ,      but   brain     you   \n",
       "11     your      xeol    xbol    never   giving     xeol    what     ain   \n",
       "12    chest      xbol    xeol     know       up     xbol       i      't   \n",
       "13     xeol      xeol    xbol     xeol     xeol        i     saw   gonna   \n",
       "14     xbol      xbol     and     xeos     xbol      'll      in  change   \n",
       "15        i        oh     all     xbos       my    never     his      my   \n",
       "16     hear      baby      of     xbol    pride     make    eyes    life   \n",
       "17      men         ,   these     well      for      the    xeol       ,   \n",
       "18    xxunk      come   words        ,      you     same    xbol      oh   \n",
       "19    while        on       i      you     xeol  mistake      in      no   \n",
       "\n",
       "         8      9  \n",
       "0      won     my  \n",
       "1       't   soul  \n",
       "2     deal   xeol  \n",
       "3     xeol   xeos  \n",
       "4     xbol   xbos  \n",
       "5        i   xbol  \n",
       "6      won  xxunk  \n",
       "7       't  xxunk  \n",
       "8   change     em  \n",
       "9        ,  busca  \n",
       "10       i     de  \n",
       "11     'll  xxunk  \n",
       "12   tough   xeol  \n",
       "13      it   xbol  \n",
       "14     out  xxunk  \n",
       "15    xeol    sua  \n",
       "16    xbol  banda  \n",
       "17   xxunk    pro  \n",
       "18      it    rio  \n",
       "19     out     de  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(data_lm.train_dl))\n",
    "example = x[:20,:10].cpu()\n",
    "texts = pd.DataFrame([data_lm.train_ds.vocab.textify(l).split(' ') for l in example])\n",
    "print(x.shape, y.shape)\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a few basic training/saving parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "SAVE = False\n",
    "GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ULMFiT Model architecture and create and embedding matrix that includes the new words. The new words are initialized to the mean value of all prior vocab..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(10002, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(10002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=10002, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = RNNLearner.language_model(data_lm,\n",
    "                                  pretrained_fnames=['2.0-ULMFiT', 'itos'],\n",
    "                                  drop_mult=0.5)\n",
    "\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit one cycle, but keep all layers frozen except the linear encoder and decoder. Start with a realtively low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN and SAVE:\n",
    "    learn.save(f'{model_title}') #WARNING: STATIC TITLE...DONT OVERWRITE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load(self, name:PathOrStr):\n",
    "    \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "       We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "    self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GPU:\n",
    "    learn.cpu_load(f'{model_title}')\n",
    "else:\n",
    "    learn.load(f'{model_title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(learner, seed_text=['xbos'], max_len=500, GPU=False, context_length=20):\n",
    "    \"\"\"Generates text with a given learner and prints string to console.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None : NoneType\n",
    "        Doesn't return anything, prints string to console\n",
    "    \"\"\"\n",
    "        \n",
    "    model = learner.model\n",
    "    \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = seed_text.split(' ')\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(data_lm.train_ds.vocab.numericalize(seed_text)).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(data_lm.train_ds.vocab.numericalize(seed_text)).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    # reset model's hidden state\n",
    "    # we don't want to carry over old contexts\n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    #loop over max length of words\n",
    "    for _ in range(max_len):\n",
    "        # forward pass the \"context\" into the model\n",
    "        result, *_ = model(context[-context_length:])\n",
    "        result = result[-1]\n",
    "\n",
    "        # set unk and pad to 0 prob\n",
    "        # i.e. never pick unknown or pad\n",
    "        result[0] = -np.inf\n",
    "        result[1] = -np.inf\n",
    "\n",
    "        # softmax and normalize\n",
    "        probabilities = F.softmax(result, dim=0)\n",
    "        probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "        probabilities /= np.sum(probabilities) # solve rounding issues for multinom function\n",
    "\n",
    "        # draw multinom and add to context\n",
    "        token_index = np.argmax(np.random.multinomial(1, probabilities))\n",
    "        \n",
    "        if GPU:\n",
    "            token_index = LongTensor([token_index]).view(-1, 1).cuda()\n",
    "        else:\n",
    "            token_index = LongTensor([token_index]).view(-1, 1).cpu()\n",
    "\n",
    "        context = torch.cat((context, token_index))    \n",
    "        \n",
    "        # print word\n",
    "        word = data_lm.valid_ds.vocab.textify([token_index])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = '\\n'\n",
    "        elif 'xbol' in word:\n",
    "            continue\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " there 's a baby lust within my veins \n",
      " of a man like me she takes a chasing ' flame \n",
      " she 's got a better life that hell would bring \n",
      " she 'd take me to evil place \n",
      " but gonna live with her mama \n",
      " comin ' to hell , i went out for my wife \n",
      " \n",
      " [chorus] \n",
      " and time goes on like a mother 's love \n",
      " god 's got a son but she ain 't afraid \n",
      " time ain 't working on a mother 's son \n",
      " well , she ain 't wanna wife but a shooting star \n",
      " 'cause a woman 's man ain 't an property man \n",
      " and her ain 't gonna pay no mind \n",
      " \n",
      " [outro] \n",
      " what 's your heart \n",
      " what 's your soul \n",
      " what 's your life \n",
      " what 's your life \n",
      " xeos\n"
     ]
    }
   ],
   "source": [
    "generate_text(learn, GPU=GPU, seed_text='xbos xbol [verse-1]', max_len=1200, context_length=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7749771e-05,  6.8505716e-01, -2.0456196e-01, ...,\n",
       "         5.7345431e-02,  1.7560309e-01, -6.9935806e-02],\n",
       "       [ 1.7684676e-01,  7.5929588e-01, -8.8490233e-02, ...,\n",
       "        -3.9831889e-01, -4.3732692e-02, -2.3929070e-01],\n",
       "       [ 2.9668090e-01,  9.6345782e-01,  5.6869864e-01, ...,\n",
       "        -9.5396101e-01,  6.0601085e-01, -4.6033749e-01],\n",
       "       ...,\n",
       "       [-2.5833974e-02,  4.6223259e-01,  1.9239992e-01, ...,\n",
       "        -5.3919351e-01, -3.0052951e-01, -4.8572969e-01],\n",
       "       [-2.4416618e-01,  6.6907865e-01,  2.3509252e-01, ...,\n",
       "        -1.8074957e-01,  1.2514262e-01, -3.6873725e-01],\n",
       "       [-3.6761138e-01,  7.0088875e-01,  1.4120845e-01, ...,\n",
       "        -2.5032681e-01,  2.5526062e-01,  2.9174709e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = learn.model.state_dict().get('0.encoder.weight').cpu().numpy()\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embed = pd.DataFrame(data=embed,\n",
    "                        index=data_lm.train_ds.vocab.itos)\n",
    "\n",
    "df_embed.to_csv('../data/models/embeddings.csv',\n",
    "                sep='\\t',\n",
    "                index=False,\n",
    "                header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.DataFrame(data=data_lm.train_ds.vocab.itos,\n",
    "                       columns=['token'])\n",
    "\n",
    "df_meta.to_csv('../data/models/embeddings_meta.csv',\n",
    "               sep='\\t',\n",
    "               header=False,\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Embedding Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire semantic and contextual representations that the model truly learns cannot be visualized quite to the mindblowing extent that might be warranted. In order to make this figure, we collapse 400 dimensions of \"information\" into 3 dimensions so that we can view it in 3 dimensional space. In the process of reducing our dimensionalitye, we lose ~X% of our data's variance. Even with this loss of interpretability, very clear semantic understandings of the language model emerge in the 3D space below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
    "#trans_data = tsne.fit_transform(embed).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = go.Scatter3d(x=trans_data[0], y=trans_data[1], z=trans_data[2],\n",
    "#                   mode='markers', \n",
    "#                   marker=dict(color=x, \n",
    "#                               colorscale=cmap,\n",
    "#                               showscale=False,\n",
    "#                               line=dict(color='black', width=1)))\n",
    "\n",
    "# layout=dict(margin=dict(l=10, r=10,\n",
    "#                         t=30, b=10)\n",
    "#            )\n",
    "\n",
    "# fig = go.Figure(data=[p1], layout=layout)\n",
    "\n",
    "# py.iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
