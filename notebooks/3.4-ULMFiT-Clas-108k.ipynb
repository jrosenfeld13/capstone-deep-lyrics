{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk.tokenize\n",
    "import itertools\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from enum import Enum\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Lyrics Generator - ULMFiT\n",
    "\n",
    "## Set up instructions\n",
    "\n",
    "### Create VM Instance\n",
    "\n",
    "- Go to cloud.google.com, and create a new VM instance\n",
    "- Disk size: 100GB or more\n",
    "- CPUs + Memory: 2vCPUs, 7.5 GB Memory\n",
    "- GPU: K80 (cheaper, less power) or P100 (2.5x more expensive, more power)\n",
    "- Enable http, https traffic\n",
    "- Boot: Deep learning pytorch instance\n",
    "\n",
    "### Network configuration\n",
    "\n",
    "In Google cloud platform:\n",
    "\n",
    "- Go to Networking -> VPC Network, External IP addresses\n",
    "- Select your VM instance and change the external address type from Ephemeral to Static\n",
    "- Go to Networking -> VPC Network, Firewall Rules\n",
    "- Add a new Rule, called Jupyter, ip ranges 0.0.0.0/0, protocols and ports tcp:8888, apply to all targets\n",
    "\n",
    "### VM + Jupyter Setup\n",
    "\n",
    "- SSH to VM\n",
    "- Enlist into Github repo\n",
    "- Run src/setup.sh\n",
    "- Run jupyter notebook\n",
    "- Open a google cloud shell\n",
    "- Run gcloud init and answer the questions\n",
    "- To set up a tunnel and run jupyter locally, run ```gcloud compute --project \"<your project>\" ssh --zone \"<your zone>\" \"<your instance name>\" -- -L 8888:localhost:8888```\n",
    "- Open jupyter notebook in your local computer and have fun\n",
    "\n",
    "### Notebook first run\n",
    "Here are some steps to run the first time you use the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokens\n",
    "To create the model's tokens with the correct train-test split, run ```src/data_collection/lm_data_lyrics.py -o path/to/save```. \n",
    "We recommend saving in data/models/{MODEL_NAME}. Alternatively, run the magic command below and replace the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing train.\n",
      "Numericalizing valid.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/data_collection/lm_data_lyrics.py -o ../data/models/3.4-ULMFiT-Clas-108k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Audio Features\n",
    "\n",
    "To create the model's audio features with the same train-test split as the language models, run `src/data/lm_data_audio.py -o path/to/save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/data_collection/lm_data_audio.py -o ../data/interim/msd-aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data for label encoding\n",
    "\n",
    "We'll have to save the labels in a form that fastai likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created the tokens, let's load them into a `DataBunch` to train our LM further or generate text with a pre-trained LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model_name = '3.3-ULMFiT-108k'\n",
    "INIT_MODEL_PATH = Path(f'../data/models/{init_model_name}')\n",
    "\n",
    "\n",
    "model_name = '3.4-ULMFiT-Clas-108k'\n",
    "MODEL_PATH = Path(f'../data/models/{model_name}')\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-train.csv')\n",
    "df_valid = pd.read_csv('../data/interim/msd-aggregate/msd-aggregate-valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'analysis_sample_rate', 'audio_md5', 'danceability',\n",
       "       'duration', 'end_of_fade_in', 'energy', 'key', 'key_confidence',\n",
       "       'loudness', 'mode', 'mode_confidence', 'start_of_fade_out', 'tempo',\n",
       "       'time_signature', 'time_signature_confidence', 'analyzer_version',\n",
       "       'artist_7digitalid', 'artist_familiarity', 'artist_hotttnesss',\n",
       "       'artist_id', 'artist_latitude', 'artist_location', 'artist_longitude',\n",
       "       'artist_mbid', 'artist_name', 'artist_playmeid', 'genre', 'release',\n",
       "       'release_7digitalid', 'song_hotttnesss', 'song_id', 'title',\n",
       "       'track_7digitalid', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = df_train['key']\n",
    "valid_feature = df_valid['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(MODEL_PATH/'train_lbl.npy', train_feature.values)\n",
    "np.save(MODEL_PATH/'valid_lbl.npy', valid_feature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_tokens(MODEL_PATH,\n",
    "                                        bs=128,\n",
    "                                        max_vocab=10000)\n",
    "\n",
    "print(data_clas.train_ds.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.677112485459927"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.cumsum().iloc[-1]/len(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "5     1\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     0\n",
       "10    1\n",
       "11    1\n",
       "12    0\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "Name: mode, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86829"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.data.train_ds.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier_learner(data:DataBunch, bptt:int=70, emb_sz:int=400, nh:int=1150, nl:int=3, pad_token:int=1,\n",
    "               drop_mult:float=1., qrnn:bool=False,max_len:int=10*70, lin_ftrs:Collection[int]=None,\n",
    "               ps:Collection[float]=None, **kwargs) -> 'TextClassifierLearner':\n",
    "    \"Create a RNN classifier.\"\n",
    "    dps = default_dropout['classifier'] * drop_mult\n",
    "    if lin_ftrs is None: lin_ftrs = [50]\n",
    "    if ps is None:  ps = [0.1]\n",
    "    ds = data.train_ds\n",
    "    vocab_size, n_class = len(data.vocab.itos), len(np.unique(data.train_ds.labels))\n",
    "    layers = [emb_sz*3] + lin_ftrs + [n_class]\n",
    "    ps = [dps[4]] + ps\n",
    "    model = get_rnn_classifier(bptt, max_len, n_class, vocab_size, emb_sz, nh, nl, pad_token,\n",
    "                layers, ps, input_p=dps[0], weight_p=dps[1], embed_p=dps[2], hidden_p=dps[3], qrnn=qrnn)\n",
    "    learn = RNNLearner(data, model, bptt, split_func=rnn_classifier_split, **kwargs)\n",
    "    return learn\n",
    "\n",
    "default_dropout = {'language': np.array([0.25, 0.1, 0.2, 0.02, 0.15]),\n",
    "                   'classifier': np.array([0.4,0.5,0.05,0.3,0.4])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True) -> Rank0Tensor:\n",
    "    \"Computes the f_beta between preds and targets\"\n",
    "    beta2 = beta**2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.5, metrics=[fbeta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load_encoder(f'{model_name}_encoder_initializer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD_MODEL_WEIGHTS = False\n",
    "# weights_url = 'https://storage.googleapis.com/w210-capstone/3.2-ULMFiT-108k_best.pth'\n",
    "\n",
    "# if DOWNLOAD_MODEL_WEIGHTS:\n",
    "#     Path(MODEL_PATH/'models').mkdir(exist_ok=True)\n",
    "#     download_url(weights_url, MODEL_PATH/f'models/{model_name}_best.pth', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cpu_load(self, name:PathOrStr):\n",
    "#     \"\"\"Load model onto CPU that was trained on a GPU `name` from `self.model_dir`.\n",
    "#        We need these because the fastai load function doesn't allow for a remapping of the storage location.\"\"\"\n",
    "#     self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=lambda storage, loc: storage))\n",
    "\n",
    "# setattr(RNNLearner, 'cpu_load', cpu_load) #monkey patch onto our RNNLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not GPU:\n",
    "#     learn.cpu_load(f'{init_model_name}_best')\n",
    "# else:\n",
    "#     learn.load(f'{init_model_name}_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaveModel(LearnerCallback):\n",
    "    \"\"\"Save Latest Model\"\"\"\n",
    "    def __init__(self, learn:Learner, model_name='saved_model'):\n",
    "        super().__init__(learn)\n",
    "        self.model_name = model_name\n",
    "        self.model_date = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "        self.best_loss = None\n",
    "        self.perplexity = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch:int, metrics, last_metrics, **kwargs):\n",
    "        loss, *_ = last_metrics\n",
    "        perp = np.exp(loss)\n",
    "        self.perplexity.append(perp)\n",
    "        if self.best_loss == None or loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.learn.save(f'{self.model_name}_best')\n",
    "        return False\n",
    "    \n",
    "    def on_train_end(self, epoch:int, **kwargs):\n",
    "        self.learn.save(f'{self.model_name}_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = SaveModel(learn, model_name=f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 06:26\n",
      "epoch  train_loss  valid_loss  accuracy\n",
      "1      2.415628    2.412177    0.129353  (06:26)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [2/5 30:04<45:07]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.413364</th>\n",
       "    <th>2.411640</th>\n",
       "    <th>0.132025</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2.408372</th>\n",
       "    <th>2.414418</th>\n",
       "    <th>0.132578</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1337' class='' max='1357', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      98.53% [1337/1357 14:09<00:12 2.4057]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.unfreeze()\n",
    "    learn.fit(5, 1e-3, callbacks=[save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation loss:  0.62105566\n"
     ]
    }
   ],
   "source": [
    "print(\"best validation loss: \", learn.save_model.best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path = Path(MODEL_PATH)\n",
    "learn.save(f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation (to delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j_rosen_1392/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1120: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6655, 0.7991])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(Tensor([0.6878, 1.3804]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(10002, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(10002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.reset()\n",
    "learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.reset()\n",
    "context = [1002,5000,2,2333]\n",
    "context = LongTensor(context).view(-1,1).cuda()\n",
    "#context = torch.autograd.Variable(context)\n",
    "\n",
    "\n",
    "# forward pass the \"context\" into the model\n",
    "result, *_ = learn.model(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j_rosen_1392/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2537, 0.7463]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_step(learner, context, audio, context_length, temp=1):\n",
    "    \n",
    "    # FIX THIS\n",
    "    audio_size = train_audio.feature_size\n",
    "\n",
    "    model = learner.model\n",
    "    \n",
    "    if GPU:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cuda()\n",
    "    else:\n",
    "        context = LongTensor(context[-context_length:]).view(-1,1).cpu()\n",
    "    \n",
    "    context = torch.autograd.Variable(context)\n",
    "    \n",
    "    model.reset()\n",
    "    model.eval()\n",
    "\n",
    "    if audio is None:\n",
    "        audio_features = Tensor([0]*audio_size*len(context))\\\n",
    "        .view(-1, 1, audio_size).cuda()\n",
    "    else:\n",
    "        audio_features = np.tile(audio, len(context))\n",
    "        audio_features = Tensor(audio_features).view(-1, 1, len(audio)).cuda()\n",
    "        \n",
    "    # forward pass the \"context\" into the model\n",
    "    result, *_ = model(context, audio_features)\n",
    "    result = result[-1]\n",
    "\n",
    "    # set unk and pad to 0 prob\n",
    "    # i.e. never pick unknown or pad\n",
    "    result[0] = -np.inf\n",
    "    result[1] = -np.inf\n",
    "\n",
    "    # softmax and normalize\n",
    "    probabilities = F.softmax(result/temp, dim=0)\n",
    "    probabilities = np.asarray(probabilities.detach().cpu(), dtype=np.float)\n",
    "    probabilities /= np.sum(probabilities) \n",
    "    return probabilities\n",
    "\n",
    "def get_word_from_index(idx):\n",
    "\n",
    "    return data_lm.valid_ds.vocab.textify([idx])\n",
    "\n",
    "\n",
    "def print_words(context):\n",
    "    for i in range(len(context)):\n",
    "        \n",
    "        step = context[i]\n",
    "\n",
    "        word = data_lm.valid_ds.vocab.textify([step])\n",
    "\n",
    "        if word == 'xeol':\n",
    "            word = 'xeol \\n'\n",
    "        elif 'xbol' in word:\n",
    "            word = 'xbol'\n",
    "        elif word == 'xeos': \n",
    "            print(word)\n",
    "            break\n",
    "            \n",
    "        print(word, end=' ')   \n",
    "\n",
    "def generate_text(learner, seed_text=['xbos'], audio=None, max_len=500, GPU=False, context_length=20, beam_width=5, temp=1, verbose=True, graph=False):\n",
    "    \"\"\"Generates text with a given learner and returns best options.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learner : RNNLearner Language Model (RNNLearner.language_model())\n",
    "        Fastai RNNLearner with tokenized language model data already loaded \n",
    "        \n",
    "    seed_text : list or str\n",
    "        List of strings where each item is a token. (e.g. ['the', 'cat']) or string that is split on white space\n",
    "\n",
    "    max_len : int\n",
    "        Number of words in generated sequence\n",
    "        \n",
    "    gpu : bool\n",
    "        If you're using a GPU or not...\n",
    "    \n",
    "    context_length : int\n",
    "        Amount of words that get input as \"context\" into the model. Set to 0 for no limit   \n",
    "        \n",
    "    beam_width : int\n",
    "        How many new word indices to try out...computationally expensive\n",
    "    \n",
    "    verbose : bool\n",
    "        If True, prints every possible context for a given word cycle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    context_and_scores : list of lists\n",
    "        Returns a sorted list of the entire tree search of contexts and their respective scores in the form:\n",
    "        [[context, score], [context, score], ..., [context, score]]\n",
    "    \"\"\"\n",
    "        \n",
    "    if isinstance(seed_text, str):\n",
    "        seed_text = data_lm.train_ds.vocab.numericalize(seed_text.split(' '))\n",
    "    \n",
    "    \n",
    "    # Width for the beam search, to be externalized along with general decoding\n",
    "    beam_width = beam_width\n",
    "    \n",
    "    if graph:\n",
    "        optimization_graph = Digraph()\n",
    "\n",
    "    # List of candidate word sequence. We'll maintain #beam_width top sequences here.\n",
    "    # The context is a list of words, the scores are the sum of the log probabilities of each word\n",
    "    context_and_scores = [[seed_text, 0.0]]\n",
    "    \n",
    "    # Loop over max number of words\n",
    "    for word_number in range(max_len):\n",
    "        print(f'Generating word: {word_number+1} / {max_len}')\n",
    "\n",
    "        candidates = []\n",
    "        \n",
    "        # For each possible context that we've generated so far, generate new probabilities, \n",
    "        # and pick an additional #beam_width next candidates\n",
    "        for i in range(len(context_and_scores)):\n",
    "            # Get a new sequence of word indices and log-probability\n",
    "            # Example: [[2, 138, 661], 23.181717]\n",
    "            context, score = context_and_scores[i]\n",
    "            \n",
    "            # Obtain probabilities for next word given the context \n",
    "            probabilities = generate_step(learner, context, audio, context_length, temp)\n",
    "\n",
    "            # Multinomial draw from the probabilities\n",
    "            multinom_draw = np.random.multinomial(beam_width, probabilities)\n",
    "            top_probabilities = np.argwhere(multinom_draw != 0).flatten()\n",
    "                        \n",
    "            #For each possible new candidate, update the context and scores\n",
    "            for j in range(len(top_probabilities)):\n",
    "                next_word_idx = top_probabilities[j]\n",
    "                new_context = context + [next_word_idx]\n",
    "                candidate = [new_context, (score - np.log(probabilities[next_word_idx]))]\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "                if graph:\n",
    "                    optimization_graph.node(\"%d_%d\" % (word_number, next_word_idx), \"%s (%.2f)\" % (get_word_from_index(next_word_idx), candidate[1]))\n",
    "                    optimization_graph.edge(\"%d_%d\" % (word_number - 1, context[len(context) -1]), \"%d_%d\" % (word_number, next_word_idx))\n",
    "                \n",
    "        #update the running tally of context and scores and sort by probability of each entry\n",
    "        context_and_scores = candidates\n",
    "        context_and_scores = sorted(context_and_scores, key = lambda x: x[1]) #sort by top entries\n",
    "\n",
    "        context_and_scores = context_and_scores[:15] #for now, only keep the top 15 to speed things up but we can/should change this to beam_width or something else\n",
    "        \n",
    "        if verbose:\n",
    "            for context, score in context_and_scores:\n",
    "                print_words(context)\n",
    "                print('\\n')\n",
    "\n",
    "    if graph:\n",
    "        now = str(datetime.now())\n",
    "        optimization_graph.render(directory='graph_viz/', filename=now, cleanup=True)\n",
    "    return context_and_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>analysis_sample_rate</th>\n",
       "      <th>audio_md5</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_of_fade_in</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>...</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_playmeid</th>\n",
       "      <th>genre</th>\n",
       "      <th>release</th>\n",
       "      <th>release_7digitalid</th>\n",
       "      <th>song_hotttnesss</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>track_7digitalid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15330</th>\n",
       "      <td>TRGSQDW12903D0DCEB</td>\n",
       "      <td>22050</td>\n",
       "      <td>8a69bdfdc85ee52fbe5fa3be5a04f18f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.28118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-10.260</td>\n",
       "      <td>...</td>\n",
       "      <td>The Constructus Corporation</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Ziggurat</td>\n",
       "      <td>699902</td>\n",
       "      <td>0.440794</td>\n",
       "      <td>SOEPWKZ12A58A7F478</td>\n",
       "      <td>choose your own adventure</td>\n",
       "      <td>7764309</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>TRMJWEF128F9341FD3</td>\n",
       "      <td>22050</td>\n",
       "      <td>ecf2f9fd715ae282b91d78f4a081dadf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.60771</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-11.809</td>\n",
       "      <td>...</td>\n",
       "      <td>Oasis</td>\n",
       "      <td>1196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Live Lounge</td>\n",
       "      <td>557045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOJBRZM12AB01891B6</td>\n",
       "      <td>Songbird</td>\n",
       "      <td>6161500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15660</th>\n",
       "      <td>TRAONKD12903CF239C</td>\n",
       "      <td>22050</td>\n",
       "      <td>bfffef67050ac8ad1154d2fa76b79f52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.31955</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.234</td>\n",
       "      <td>-5.468</td>\n",
       "      <td>...</td>\n",
       "      <td>Paperboys</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Cure For Life</td>\n",
       "      <td>689392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOEMTQZ12AC468B402</td>\n",
       "      <td>In Between (Duets)</td>\n",
       "      <td>7651007</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>TRATYKV12903CF956E</td>\n",
       "      <td>22050</td>\n",
       "      <td>af3f6e2b2ebb66b0726ee857d41f3836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.49342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-3.673</td>\n",
       "      <td>...</td>\n",
       "      <td>French Horn Rebellion</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Up All Night EP</td>\n",
       "      <td>603749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOHNFYO12AC3DF9DD7</td>\n",
       "      <td>Up All Night</td>\n",
       "      <td>6706053</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>TRFQNIS128F14809B7</td>\n",
       "      <td>22050</td>\n",
       "      <td>76b4db78cc8b0eacc77bf6a73b53a64f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.30077</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-15.471</td>\n",
       "      <td>...</td>\n",
       "      <td>Andrew Lloyd Webber</td>\n",
       "      <td>8487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Likes Of Us</td>\n",
       "      <td>41256</td>\n",
       "      <td>0.215080</td>\n",
       "      <td>SOLTUMH12A6D4F8518</td>\n",
       "      <td>This Is My Time</td>\n",
       "      <td>438688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id  analysis_sample_rate  \\\n",
       "15330  TRGSQDW12903D0DCEB                 22050   \n",
       "15650  TRMJWEF128F9341FD3                 22050   \n",
       "15660  TRAONKD12903CF239C                 22050   \n",
       "9493   TRATYKV12903CF956E                 22050   \n",
       "11817  TRFQNIS128F14809B7                 22050   \n",
       "\n",
       "                              audio_md5  danceability   duration  \\\n",
       "15330  8a69bdfdc85ee52fbe5fa3be5a04f18f           0.0  111.28118   \n",
       "15650  ecf2f9fd715ae282b91d78f4a081dadf           0.0  127.60771   \n",
       "15660  bfffef67050ac8ad1154d2fa76b79f52           0.0  184.31955   \n",
       "9493   af3f6e2b2ebb66b0726ee857d41f3836           0.0  299.49342   \n",
       "11817  76b4db78cc8b0eacc77bf6a73b53a64f           0.0  215.30077   \n",
       "\n",
       "       end_of_fade_in  energy  key  key_confidence  loudness  ...   \\\n",
       "15330           0.000     0.0   10           0.480   -10.260  ...    \n",
       "15650           0.202     0.0    2           0.016   -11.809  ...    \n",
       "15660           0.148     0.0    5           0.234    -5.468  ...    \n",
       "9493            0.000     0.0    7           0.379    -3.673  ...    \n",
       "11817           0.222     0.0    2           0.718   -15.471  ...    \n",
       "\n",
       "                       artist_name  artist_playmeid  genre           release  \\\n",
       "15330  The Constructus Corporation               -1    NaN      The Ziggurat   \n",
       "15650                        Oasis             1196    NaN       Live Lounge   \n",
       "15660                    Paperboys               -1    NaN  No Cure For Life   \n",
       "9493         French Horn Rebellion               -1    NaN   Up All Night EP   \n",
       "11817          Andrew Lloyd Webber             8487    NaN   The Likes Of Us   \n",
       "\n",
       "       release_7digitalid  song_hotttnesss             song_id  \\\n",
       "15330              699902         0.440794  SOEPWKZ12A58A7F478   \n",
       "15650              557045              NaN  SOJBRZM12AB01891B6   \n",
       "15660              689392              NaN  SOEMTQZ12AC468B402   \n",
       "9493               603749              NaN  SOHNFYO12AC3DF9DD7   \n",
       "11817               41256         0.215080  SOLTUMH12A6D4F8518   \n",
       "\n",
       "                           title  track_7digitalid  year  \n",
       "15330  choose your own adventure           7764309  2002  \n",
       "15650                   Songbird           6161500     0  \n",
       "15660         In Between (Duets)           7651007  2002  \n",
       "9493                Up All Night           6706053  2009  \n",
       "11817            This Is My Time            438688     0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id                                       TRCNUVO128F92E7CB7\n",
       "analysis_sample_rate                                        22050\n",
       "audio_md5                        f6ef05f8d81ec7bccffc081de3ca3ea7\n",
       "danceability                                                    0\n",
       "duration                                                  258.351\n",
       "end_of_fade_in                                              0.996\n",
       "energy                                                          0\n",
       "key                                                             9\n",
       "key_confidence                                              0.764\n",
       "loudness                                                  -15.523\n",
       "mode                                                            0\n",
       "mode_confidence                                               0.7\n",
       "start_of_fade_out                                         242.857\n",
       "tempo                                                      78.805\n",
       "time_signature                                                  4\n",
       "time_signature_confidence                                   0.709\n",
       "analyzer_version                                              NaN\n",
       "artist_7digitalid                                           32117\n",
       "artist_familiarity                                       0.514884\n",
       "artist_hotttnesss                                        0.364356\n",
       "artist_id                                      ARGI6UK1187B99ADF2\n",
       "artist_latitude                                           40.6551\n",
       "artist_location                                      Brooklyn, NY\n",
       "artist_longitude                                         -73.9489\n",
       "artist_mbid                  4981fd19-16b6-4393-ae72-3f6e427ed677\n",
       "artist_name                                         Robbie Dupree\n",
       "artist_playmeid                                             42407\n",
       "genre                                                         NaN\n",
       "release                         Robbie Dupree with David Sancious\n",
       "release_7digitalid                                         329960\n",
       "song_hotttnesss                                                 0\n",
       "song_id                                        SONQXGD12AB017D094\n",
       "title                                                 Desperation\n",
       "track_7digitalid                                          3707416\n",
       "year                                                         1981\n",
       "Name: 7650, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.iloc[7650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode == 1, loudness == -2.3,\n",
    "# artist_hot == 0.57, artist_familiarity = 0.77, \n",
    "# song_hot == n/a\n",
    "xx = valid_audio[9126]\n",
    "# mode == 0, loudness == -15.5,\n",
    "# artist_hot == 0.36, artist_familiarity = 0.51, \n",
    "# song_hot == 0\n",
    "yy = valid_audio[7650] # mode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating word: 1 / 80\n",
      "Generating word: 2 / 80\n",
      "Generating word: 3 / 80\n",
      "Generating word: 4 / 80\n",
      "Generating word: 5 / 80\n",
      "Generating word: 6 / 80\n",
      "Generating word: 7 / 80\n",
      "Generating word: 8 / 80\n",
      "Generating word: 9 / 80\n",
      "Generating word: 10 / 80\n",
      "Generating word: 11 / 80\n",
      "Generating word: 12 / 80\n",
      "Generating word: 13 / 80\n",
      "Generating word: 14 / 80\n",
      "Generating word: 15 / 80\n",
      "Generating word: 16 / 80\n",
      "Generating word: 17 / 80\n",
      "Generating word: 18 / 80\n",
      "Generating word: 19 / 80\n",
      "Generating word: 20 / 80\n",
      "Generating word: 21 / 80\n",
      "Generating word: 22 / 80\n",
      "Generating word: 23 / 80\n",
      "Generating word: 24 / 80\n",
      "Generating word: 25 / 80\n",
      "Generating word: 26 / 80\n",
      "Generating word: 27 / 80\n",
      "Generating word: 28 / 80\n",
      "Generating word: 29 / 80\n",
      "Generating word: 30 / 80\n",
      "Generating word: 31 / 80\n",
      "Generating word: 32 / 80\n",
      "Generating word: 33 / 80\n",
      "Generating word: 34 / 80\n",
      "Generating word: 35 / 80\n",
      "Generating word: 36 / 80\n",
      "Generating word: 37 / 80\n",
      "Generating word: 38 / 80\n",
      "Generating word: 39 / 80\n",
      "Generating word: 40 / 80\n",
      "Generating word: 41 / 80\n",
      "Generating word: 42 / 80\n",
      "Generating word: 43 / 80\n",
      "Generating word: 44 / 80\n",
      "Generating word: 45 / 80\n",
      "Generating word: 46 / 80\n",
      "Generating word: 47 / 80\n",
      "Generating word: 48 / 80\n",
      "Generating word: 49 / 80\n",
      "Generating word: 50 / 80\n",
      "Generating word: 51 / 80\n",
      "Generating word: 52 / 80\n",
      "Generating word: 53 / 80\n",
      "Generating word: 54 / 80\n",
      "Generating word: 55 / 80\n",
      "Generating word: 56 / 80\n",
      "Generating word: 57 / 80\n",
      "Generating word: 58 / 80\n",
      "Generating word: 59 / 80\n",
      "Generating word: 60 / 80\n",
      "Generating word: 61 / 80\n",
      "Generating word: 62 / 80\n",
      "Generating word: 63 / 80\n",
      "Generating word: 64 / 80\n",
      "Generating word: 65 / 80\n",
      "Generating word: 66 / 80\n",
      "Generating word: 67 / 80\n",
      "Generating word: 68 / 80\n",
      "Generating word: 69 / 80\n",
      "Generating word: 70 / 80\n",
      "Generating word: 71 / 80\n",
      "Generating word: 72 / 80\n",
      "Generating word: 73 / 80\n",
      "Generating word: 74 / 80\n",
      "Generating word: 75 / 80\n",
      "Generating word: 76 / 80\n",
      "Generating word: 77 / 80\n",
      "Generating word: 78 / 80\n",
      "Generating word: 79 / 80\n",
      "Generating word: 80 / 80\n"
     ]
    }
   ],
   "source": [
    "final_scores = generate_text(learn, GPU=GPU,\n",
    "                             seed_text='xbos xbol [verse-1]',\n",
    "                             audio=xx,\n",
    "                             max_len=80, context_length=200,\n",
    "                             beam_width=3, verbose=False,\n",
    "                             temp=1.5, graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish i could 193.78870414374862\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish that i 193.80404884464744\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish i was 195.19425226415203\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were here xeol \n",
      " xbol xeol \n",
      " xbol i wish i 195.22330376954403\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were here xeol \n",
      " xbol xeol \n",
      " xbol i wish that 195.61832422095154\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish that you 195.69494664704695\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish you were 196.07586007511586\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were gone xeol \n",
      " xbol i wish you were here 196.35336157400377\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go away xeol \n",
      " xbol i wish you loved 199.09497232860096\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go back where i belong xeol \n",
      " xbol i 199.22117042958834\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were here xeol \n",
      " xbol wish i could have loved 199.2517252487672\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were gone xeol \n",
      " xbol i wish i had you 199.61630879238356\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were here xeol \n",
      " xbol xeol \n",
      " xbol i long to 199.6215368622202\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that you were here xeol \n",
      " xbol wish i could write you 199.89808182834935\n",
      "\n",
      "\n",
      "xbos xxunk [verse-1] crave requiem xeol \n",
      " xbol xeol \n",
      " xbol so far away , i wish you were here today xeol \n",
      " xbol and most of all i wish there was another way xeol \n",
      " xbol i wish i could do this to me xeol \n",
      " xbol xeol \n",
      " xbol so you could leave here with me xeol \n",
      " xbol much more than anything you meant to me xeol \n",
      " xbol i wish i was dead xeol \n",
      " xbol wish that i could go back where i belong xeol \n",
      " xbol wish 199.93559081212405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print all of the final options of songs\n",
    "for song, score in final_scores:\n",
    "    print_words(song)\n",
    "    print(score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
